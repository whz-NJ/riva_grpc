// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: riva_asr.proto

package nvidia.riva.asr;

public final class RivaAsr {
  private RivaAsr() {}
  public static void registerAllExtensions(
      com.google.protobuf.ExtensionRegistryLite registry) {
  }

  public static void registerAllExtensions(
      com.google.protobuf.ExtensionRegistry registry) {
    registerAllExtensions(
        (com.google.protobuf.ExtensionRegistryLite) registry);
  }
  public interface RecognizeRequestOrBuilder extends
      // @@protoc_insertion_point(interface_extends:nvidia.riva.asr.RecognizeRequest)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * Provides information to recognizer that specifies how to process the request.
     * </pre>
     *
     * <code>optional .nvidia.riva.asr.RecognitionConfig config = 1;</code>
     */
    boolean hasConfig();
    /**
     * <pre>
     * Provides information to recognizer that specifies how to process the request.
     * </pre>
     *
     * <code>optional .nvidia.riva.asr.RecognitionConfig config = 1;</code>
     */
    nvidia.riva.asr.RivaAsr.RecognitionConfig getConfig();
    /**
     * <pre>
     * Provides information to recognizer that specifies how to process the request.
     * </pre>
     *
     * <code>optional .nvidia.riva.asr.RecognitionConfig config = 1;</code>
     */
    nvidia.riva.asr.RivaAsr.RecognitionConfigOrBuilder getConfigOrBuilder();

    /**
     * <pre>
     * The raw audio data to be processed. The audio bytes must be encoded as specified in
     * `RecognitionConfig`.
     * </pre>
     *
     * <code>optional bytes audio = 2;</code>
     */
    com.google.protobuf.ByteString getAudio();
  }
  /**
   * <pre>
   * RecognizeRequest is used for batch processing of a single audio recording.
   * </pre>
   *
   * Protobuf type {@code nvidia.riva.asr.RecognizeRequest}
   */
  public  static final class RecognizeRequest extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:nvidia.riva.asr.RecognizeRequest)
      RecognizeRequestOrBuilder {
    // Use RecognizeRequest.newBuilder() to construct.
    private RecognizeRequest(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private RecognizeRequest() {
      audio_ = com.google.protobuf.ByteString.EMPTY;
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return com.google.protobuf.UnknownFieldSet.getDefaultInstance();
    }
    private RecognizeRequest(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!input.skipField(tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              nvidia.riva.asr.RivaAsr.RecognitionConfig.Builder subBuilder = null;
              if (config_ != null) {
                subBuilder = config_.toBuilder();
              }
              config_ = input.readMessage(nvidia.riva.asr.RivaAsr.RecognitionConfig.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(config_);
                config_ = subBuilder.buildPartial();
              }

              break;
            }
            case 18: {

              audio_ = input.readBytes();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return nvidia.riva.asr.RivaAsr.internal_static_nvidia_riva_asr_RecognizeRequest_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return nvidia.riva.asr.RivaAsr.internal_static_nvidia_riva_asr_RecognizeRequest_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              nvidia.riva.asr.RivaAsr.RecognizeRequest.class, nvidia.riva.asr.RivaAsr.RecognizeRequest.Builder.class);
    }

    public static final int CONFIG_FIELD_NUMBER = 1;
    private nvidia.riva.asr.RivaAsr.RecognitionConfig config_;
    /**
     * <pre>
     * Provides information to recognizer that specifies how to process the request.
     * </pre>
     *
     * <code>optional .nvidia.riva.asr.RecognitionConfig config = 1;</code>
     */
    public boolean hasConfig() {
      return config_ != null;
    }
    /**
     * <pre>
     * Provides information to recognizer that specifies how to process the request.
     * </pre>
     *
     * <code>optional .nvidia.riva.asr.RecognitionConfig config = 1;</code>
     */
    public nvidia.riva.asr.RivaAsr.RecognitionConfig getConfig() {
      return config_ == null ? nvidia.riva.asr.RivaAsr.RecognitionConfig.getDefaultInstance() : config_;
    }
    /**
     * <pre>
     * Provides information to recognizer that specifies how to process the request.
     * </pre>
     *
     * <code>optional .nvidia.riva.asr.RecognitionConfig config = 1;</code>
     */
    public nvidia.riva.asr.RivaAsr.RecognitionConfigOrBuilder getConfigOrBuilder() {
      return getConfig();
    }

    public static final int AUDIO_FIELD_NUMBER = 2;
    private com.google.protobuf.ByteString audio_;
    /**
     * <pre>
     * The raw audio data to be processed. The audio bytes must be encoded as specified in
     * `RecognitionConfig`.
     * </pre>
     *
     * <code>optional bytes audio = 2;</code>
     */
    public com.google.protobuf.ByteString getAudio() {
      return audio_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (config_ != null) {
        output.writeMessage(1, getConfig());
      }
      if (!audio_.isEmpty()) {
        output.writeBytes(2, audio_);
      }
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (config_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getConfig());
      }
      if (!audio_.isEmpty()) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(2, audio_);
      }
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof nvidia.riva.asr.RivaAsr.RecognizeRequest)) {
        return super.equals(obj);
      }
      nvidia.riva.asr.RivaAsr.RecognizeRequest other = (nvidia.riva.asr.RivaAsr.RecognizeRequest) obj;

      boolean result = true;
      result = result && (hasConfig() == other.hasConfig());
      if (hasConfig()) {
        result = result && getConfig()
            .equals(other.getConfig());
      }
      result = result && getAudio()
          .equals(other.getAudio());
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasConfig()) {
        hash = (37 * hash) + CONFIG_FIELD_NUMBER;
        hash = (53 * hash) + getConfig().hashCode();
      }
      hash = (37 * hash) + AUDIO_FIELD_NUMBER;
      hash = (53 * hash) + getAudio().hashCode();
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static nvidia.riva.asr.RivaAsr.RecognizeRequest parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static nvidia.riva.asr.RivaAsr.RecognizeRequest parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static nvidia.riva.asr.RivaAsr.RecognizeRequest parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static nvidia.riva.asr.RivaAsr.RecognizeRequest parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static nvidia.riva.asr.RivaAsr.RecognizeRequest parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static nvidia.riva.asr.RivaAsr.RecognizeRequest parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static nvidia.riva.asr.RivaAsr.RecognizeRequest parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static nvidia.riva.asr.RivaAsr.RecognizeRequest parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static nvidia.riva.asr.RivaAsr.RecognizeRequest parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static nvidia.riva.asr.RivaAsr.RecognizeRequest parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(nvidia.riva.asr.RivaAsr.RecognizeRequest prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     * RecognizeRequest is used for batch processing of a single audio recording.
     * </pre>
     *
     * Protobuf type {@code nvidia.riva.asr.RecognizeRequest}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:nvidia.riva.asr.RecognizeRequest)
        nvidia.riva.asr.RivaAsr.RecognizeRequestOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return nvidia.riva.asr.RivaAsr.internal_static_nvidia_riva_asr_RecognizeRequest_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return nvidia.riva.asr.RivaAsr.internal_static_nvidia_riva_asr_RecognizeRequest_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                nvidia.riva.asr.RivaAsr.RecognizeRequest.class, nvidia.riva.asr.RivaAsr.RecognizeRequest.Builder.class);
      }

      // Construct using nvidia.riva.asr.RivaAsr.RecognizeRequest.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      public Builder clear() {
        super.clear();
        if (configBuilder_ == null) {
          config_ = null;
        } else {
          config_ = null;
          configBuilder_ = null;
        }
        audio_ = com.google.protobuf.ByteString.EMPTY;

        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return nvidia.riva.asr.RivaAsr.internal_static_nvidia_riva_asr_RecognizeRequest_descriptor;
      }

      public nvidia.riva.asr.RivaAsr.RecognizeRequest getDefaultInstanceForType() {
        return nvidia.riva.asr.RivaAsr.RecognizeRequest.getDefaultInstance();
      }

      public nvidia.riva.asr.RivaAsr.RecognizeRequest build() {
        nvidia.riva.asr.RivaAsr.RecognizeRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public nvidia.riva.asr.RivaAsr.RecognizeRequest buildPartial() {
        nvidia.riva.asr.RivaAsr.RecognizeRequest result = new nvidia.riva.asr.RivaAsr.RecognizeRequest(this);
        if (configBuilder_ == null) {
          result.config_ = config_;
        } else {
          result.config_ = configBuilder_.build();
        }
        result.audio_ = audio_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof nvidia.riva.asr.RivaAsr.RecognizeRequest) {
          return mergeFrom((nvidia.riva.asr.RivaAsr.RecognizeRequest)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(nvidia.riva.asr.RivaAsr.RecognizeRequest other) {
        if (other == nvidia.riva.asr.RivaAsr.RecognizeRequest.getDefaultInstance()) return this;
        if (other.hasConfig()) {
          mergeConfig(other.getConfig());
        }
        if (other.getAudio() != com.google.protobuf.ByteString.EMPTY) {
          setAudio(other.getAudio());
        }
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        nvidia.riva.asr.RivaAsr.RecognizeRequest parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (nvidia.riva.asr.RivaAsr.RecognizeRequest) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }

      private nvidia.riva.asr.RivaAsr.RecognitionConfig config_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          nvidia.riva.asr.RivaAsr.RecognitionConfig, nvidia.riva.asr.RivaAsr.RecognitionConfig.Builder, nvidia.riva.asr.RivaAsr.RecognitionConfigOrBuilder> configBuilder_;
      /**
       * <pre>
       * Provides information to recognizer that specifies how to process the request.
       * </pre>
       *
       * <code>optional .nvidia.riva.asr.RecognitionConfig config = 1;</code>
       */
      public boolean hasConfig() {
        return configBuilder_ != null || config_ != null;
      }
      /**
       * <pre>
       * Provides information to recognizer that specifies how to process the request.
       * </pre>
       *
       * <code>optional .nvidia.riva.asr.RecognitionConfig config = 1;</code>
       */
      public nvidia.riva.asr.RivaAsr.RecognitionConfig getConfig() {
        if (configBuilder_ == null) {
          return config_ == null ? nvidia.riva.asr.RivaAsr.RecognitionConfig.getDefaultInstance() : config_;
        } else {
          return configBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * Provides information to recognizer that specifies how to process the request.
       * </pre>
       *
       * <code>optional .nvidia.riva.asr.RecognitionConfig config = 1;</code>
       */
      public Builder setConfig(nvidia.riva.asr.RivaAsr.RecognitionConfig value) {
        if (configBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          config_ = value;
          onChanged();
        } else {
          configBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * Provides information to recognizer that specifies how to process the request.
       * </pre>
       *
       * <code>optional .nvidia.riva.asr.RecognitionConfig config = 1;</code>
       */
      public Builder setConfig(
          nvidia.riva.asr.RivaAsr.RecognitionConfig.Builder builderForValue) {
        if (configBuilder_ == null) {
          config_ = builderForValue.build();
          onChanged();
        } else {
          configBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * Provides information to recognizer that specifies how to process the request.
       * </pre>
       *
       * <code>optional .nvidia.riva.asr.RecognitionConfig config = 1;</code>
       */
      public Builder mergeConfig(nvidia.riva.asr.RivaAsr.RecognitionConfig value) {
        if (configBuilder_ == null) {
          if (config_ != null) {
            config_ =
              nvidia.riva.asr.RivaAsr.RecognitionConfig.newBuilder(config_).mergeFrom(value).buildPartial();
          } else {
            config_ = value;
          }
          onChanged();
        } else {
          configBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * Provides information to recognizer that specifies how to process the request.
       * </pre>
       *
       * <code>optional .nvidia.riva.asr.RecognitionConfig config = 1;</code>
       */
      public Builder clearConfig() {
        if (configBuilder_ == null) {
          config_ = null;
          onChanged();
        } else {
          config_ = null;
          configBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * Provides information to recognizer that specifies how to process the request.
       * </pre>
       *
       * <code>optional .nvidia.riva.asr.RecognitionConfig config = 1;</code>
       */
      public nvidia.riva.asr.RivaAsr.RecognitionConfig.Builder getConfigBuilder() {
        
        onChanged();
        return getConfigFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * Provides information to recognizer that specifies how to process the request.
       * </pre>
       *
       * <code>optional .nvidia.riva.asr.RecognitionConfig config = 1;</code>
       */
      public nvidia.riva.asr.RivaAsr.RecognitionConfigOrBuilder getConfigOrBuilder() {
        if (configBuilder_ != null) {
          return configBuilder_.getMessageOrBuilder();
        } else {
          return config_ == null ?
              nvidia.riva.asr.RivaAsr.RecognitionConfig.getDefaultInstance() : config_;
        }
      }
      /**
       * <pre>
       * Provides information to recognizer that specifies how to process the request.
       * </pre>
       *
       * <code>optional .nvidia.riva.asr.RecognitionConfig config = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          nvidia.riva.asr.RivaAsr.RecognitionConfig, nvidia.riva.asr.RivaAsr.RecognitionConfig.Builder, nvidia.riva.asr.RivaAsr.RecognitionConfigOrBuilder> 
          getConfigFieldBuilder() {
        if (configBuilder_ == null) {
          configBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              nvidia.riva.asr.RivaAsr.RecognitionConfig, nvidia.riva.asr.RivaAsr.RecognitionConfig.Builder, nvidia.riva.asr.RivaAsr.RecognitionConfigOrBuilder>(
                  getConfig(),
                  getParentForChildren(),
                  isClean());
          config_ = null;
        }
        return configBuilder_;
      }

      private com.google.protobuf.ByteString audio_ = com.google.protobuf.ByteString.EMPTY;
      /**
       * <pre>
       * The raw audio data to be processed. The audio bytes must be encoded as specified in
       * `RecognitionConfig`.
       * </pre>
       *
       * <code>optional bytes audio = 2;</code>
       */
      public com.google.protobuf.ByteString getAudio() {
        return audio_;
      }
      /**
       * <pre>
       * The raw audio data to be processed. The audio bytes must be encoded as specified in
       * `RecognitionConfig`.
       * </pre>
       *
       * <code>optional bytes audio = 2;</code>
       */
      public Builder setAudio(com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  
        audio_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The raw audio data to be processed. The audio bytes must be encoded as specified in
       * `RecognitionConfig`.
       * </pre>
       *
       * <code>optional bytes audio = 2;</code>
       */
      public Builder clearAudio() {
        
        audio_ = getDefaultInstance().getAudio();
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return this;
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return this;
      }


      // @@protoc_insertion_point(builder_scope:nvidia.riva.asr.RecognizeRequest)
    }

    // @@protoc_insertion_point(class_scope:nvidia.riva.asr.RecognizeRequest)
    private static final nvidia.riva.asr.RivaAsr.RecognizeRequest DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new nvidia.riva.asr.RivaAsr.RecognizeRequest();
    }

    public static nvidia.riva.asr.RivaAsr.RecognizeRequest getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<RecognizeRequest>
        PARSER = new com.google.protobuf.AbstractParser<RecognizeRequest>() {
      public RecognizeRequest parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new RecognizeRequest(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<RecognizeRequest> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<RecognizeRequest> getParserForType() {
      return PARSER;
    }

    public nvidia.riva.asr.RivaAsr.RecognizeRequest getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface StreamingRecognizeRequestOrBuilder extends
      // @@protoc_insertion_point(interface_extends:nvidia.riva.asr.StreamingRecognizeRequest)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * Provides information to the recognizer that specifies how to process the
     * request. The first `StreamingRecognizeRequest` message must contain a
     * `streaming_config`  message.
     * </pre>
     *
     * <code>optional .nvidia.riva.asr.StreamingRecognitionConfig streaming_config = 1;</code>
     */
    nvidia.riva.asr.RivaAsr.StreamingRecognitionConfig getStreamingConfig();
    /**
     * <pre>
     * Provides information to the recognizer that specifies how to process the
     * request. The first `StreamingRecognizeRequest` message must contain a
     * `streaming_config`  message.
     * </pre>
     *
     * <code>optional .nvidia.riva.asr.StreamingRecognitionConfig streaming_config = 1;</code>
     */
    nvidia.riva.asr.RivaAsr.StreamingRecognitionConfigOrBuilder getStreamingConfigOrBuilder();

    /**
     * <pre>
     * The audio data to be recognized. Sequential chunks of audio data are sent
     * in sequential `StreamingRecognizeRequest` messages. The first
     * `StreamingRecognizeRequest` message must not contain `audio` data
     * and all subsequent `StreamingRecognizeRequest` messages must contain
     * `audio` data. The audio bytes must be encoded as specified in
     * `RecognitionConfig`.
     * </pre>
     *
     * <code>optional bytes audio_content = 2;</code>
     */
    com.google.protobuf.ByteString getAudioContent();

    public nvidia.riva.asr.RivaAsr.StreamingRecognizeRequest.StreamingRequestCase getStreamingRequestCase();
  }
  /**
   * <pre>
   * A StreamingRecognizeRequest is used to configure and stream audio content to the
   * Riva ASR Service. The first message sent must include only a StreamingRecognitionConfig.
   * Subsequent messages sent in the stream must contain only raw bytes of the audio
   * to be recognized.
   * </pre>
   *
   * Protobuf type {@code nvidia.riva.asr.StreamingRecognizeRequest}
   */
  public  static final class StreamingRecognizeRequest extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:nvidia.riva.asr.StreamingRecognizeRequest)
      StreamingRecognizeRequestOrBuilder {
    // Use StreamingRecognizeRequest.newBuilder() to construct.
    private StreamingRecognizeRequest(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private StreamingRecognizeRequest() {
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return com.google.protobuf.UnknownFieldSet.getDefaultInstance();
    }
    private StreamingRecognizeRequest(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!input.skipField(tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              nvidia.riva.asr.RivaAsr.StreamingRecognitionConfig.Builder subBuilder = null;
              if (streamingRequestCase_ == 1) {
                subBuilder = ((nvidia.riva.asr.RivaAsr.StreamingRecognitionConfig) streamingRequest_).toBuilder();
              }
              streamingRequest_ =
                  input.readMessage(nvidia.riva.asr.RivaAsr.StreamingRecognitionConfig.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom((nvidia.riva.asr.RivaAsr.StreamingRecognitionConfig) streamingRequest_);
                streamingRequest_ = subBuilder.buildPartial();
              }
              streamingRequestCase_ = 1;
              break;
            }
            case 18: {
              streamingRequestCase_ = 2;
              streamingRequest_ = input.readBytes();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return nvidia.riva.asr.RivaAsr.internal_static_nvidia_riva_asr_StreamingRecognizeRequest_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return nvidia.riva.asr.RivaAsr.internal_static_nvidia_riva_asr_StreamingRecognizeRequest_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              nvidia.riva.asr.RivaAsr.StreamingRecognizeRequest.class, nvidia.riva.asr.RivaAsr.StreamingRecognizeRequest.Builder.class);
    }

    private int streamingRequestCase_ = 0;
    private java.lang.Object streamingRequest_;
    public enum StreamingRequestCase
        implements com.google.protobuf.Internal.EnumLite {
      STREAMING_CONFIG(1),
      AUDIO_CONTENT(2),
      STREAMINGREQUEST_NOT_SET(0);
      private final int value;
      private StreamingRequestCase(int value) {
        this.value = value;
      }
      /**
       * @deprecated Use {@link #forNumber(int)} instead.
       */
      @java.lang.Deprecated
      public static StreamingRequestCase valueOf(int value) {
        return forNumber(value);
      }

      public static StreamingRequestCase forNumber(int value) {
        switch (value) {
          case 1: return STREAMING_CONFIG;
          case 2: return AUDIO_CONTENT;
          case 0: return STREAMINGREQUEST_NOT_SET;
          default: return null;
        }
      }
      public int getNumber() {
        return this.value;
      }
    };

    public StreamingRequestCase
    getStreamingRequestCase() {
      return StreamingRequestCase.forNumber(
          streamingRequestCase_);
    }

    public static final int STREAMING_CONFIG_FIELD_NUMBER = 1;
    /**
     * <pre>
     * Provides information to the recognizer that specifies how to process the
     * request. The first `StreamingRecognizeRequest` message must contain a
     * `streaming_config`  message.
     * </pre>
     *
     * <code>optional .nvidia.riva.asr.StreamingRecognitionConfig streaming_config = 1;</code>
     */
    public nvidia.riva.asr.RivaAsr.StreamingRecognitionConfig getStreamingConfig() {
      if (streamingRequestCase_ == 1) {
         return (nvidia.riva.asr.RivaAsr.StreamingRecognitionConfig) streamingRequest_;
      }
      return nvidia.riva.asr.RivaAsr.StreamingRecognitionConfig.getDefaultInstance();
    }
    /**
     * <pre>
     * Provides information to the recognizer that specifies how to process the
     * request. The first `StreamingRecognizeRequest` message must contain a
     * `streaming_config`  message.
     * </pre>
     *
     * <code>optional .nvidia.riva.asr.StreamingRecognitionConfig streaming_config = 1;</code>
     */
    public nvidia.riva.asr.RivaAsr.StreamingRecognitionConfigOrBuilder getStreamingConfigOrBuilder() {
      if (streamingRequestCase_ == 1) {
         return (nvidia.riva.asr.RivaAsr.StreamingRecognitionConfig) streamingRequest_;
      }
      return nvidia.riva.asr.RivaAsr.StreamingRecognitionConfig.getDefaultInstance();
    }

    public static final int AUDIO_CONTENT_FIELD_NUMBER = 2;
    /**
     * <pre>
     * The audio data to be recognized. Sequential chunks of audio data are sent
     * in sequential `StreamingRecognizeRequest` messages. The first
     * `StreamingRecognizeRequest` message must not contain `audio` data
     * and all subsequent `StreamingRecognizeRequest` messages must contain
     * `audio` data. The audio bytes must be encoded as specified in
     * `RecognitionConfig`.
     * </pre>
     *
     * <code>optional bytes audio_content = 2;</code>
     */
    public com.google.protobuf.ByteString getAudioContent() {
      if (streamingRequestCase_ == 2) {
        return (com.google.protobuf.ByteString) streamingRequest_;
      }
      return com.google.protobuf.ByteString.EMPTY;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (streamingRequestCase_ == 1) {
        output.writeMessage(1, (nvidia.riva.asr.RivaAsr.StreamingRecognitionConfig) streamingRequest_);
      }
      if (streamingRequestCase_ == 2) {
        output.writeBytes(
            2, (com.google.protobuf.ByteString)((com.google.protobuf.ByteString) streamingRequest_));
      }
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (streamingRequestCase_ == 1) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, (nvidia.riva.asr.RivaAsr.StreamingRecognitionConfig) streamingRequest_);
      }
      if (streamingRequestCase_ == 2) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(
              2, (com.google.protobuf.ByteString)((com.google.protobuf.ByteString) streamingRequest_));
      }
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof nvidia.riva.asr.RivaAsr.StreamingRecognizeRequest)) {
        return super.equals(obj);
      }
      nvidia.riva.asr.RivaAsr.StreamingRecognizeRequest other = (nvidia.riva.asr.RivaAsr.StreamingRecognizeRequest) obj;

      boolean result = true;
      result = result && getStreamingRequestCase().equals(
          other.getStreamingRequestCase());
      if (!result) return false;
      switch (streamingRequestCase_) {
        case 1:
          result = result && getStreamingConfig()
              .equals(other.getStreamingConfig());
          break;
        case 2:
          result = result && getAudioContent()
              .equals(other.getAudioContent());
          break;
        case 0:
        default:
      }
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      switch (streamingRequestCase_) {
        case 1:
          hash = (37 * hash) + STREAMING_CONFIG_FIELD_NUMBER;
          hash = (53 * hash) + getStreamingConfig().hashCode();
          break;
        case 2:
          hash = (37 * hash) + AUDIO_CONTENT_FIELD_NUMBER;
          hash = (53 * hash) + getAudioContent().hashCode();
          break;
        case 0:
        default:
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static nvidia.riva.asr.RivaAsr.StreamingRecognizeRequest parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static nvidia.riva.asr.RivaAsr.StreamingRecognizeRequest parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static nvidia.riva.asr.RivaAsr.StreamingRecognizeRequest parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static nvidia.riva.asr.RivaAsr.StreamingRecognizeRequest parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static nvidia.riva.asr.RivaAsr.StreamingRecognizeRequest parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static nvidia.riva.asr.RivaAsr.StreamingRecognizeRequest parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static nvidia.riva.asr.RivaAsr.StreamingRecognizeRequest parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static nvidia.riva.asr.RivaAsr.StreamingRecognizeRequest parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static nvidia.riva.asr.RivaAsr.StreamingRecognizeRequest parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static nvidia.riva.asr.RivaAsr.StreamingRecognizeRequest parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(nvidia.riva.asr.RivaAsr.StreamingRecognizeRequest prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     * A StreamingRecognizeRequest is used to configure and stream audio content to the
     * Riva ASR Service. The first message sent must include only a StreamingRecognitionConfig.
     * Subsequent messages sent in the stream must contain only raw bytes of the audio
     * to be recognized.
     * </pre>
     *
     * Protobuf type {@code nvidia.riva.asr.StreamingRecognizeRequest}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:nvidia.riva.asr.StreamingRecognizeRequest)
        nvidia.riva.asr.RivaAsr.StreamingRecognizeRequestOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return nvidia.riva.asr.RivaAsr.internal_static_nvidia_riva_asr_StreamingRecognizeRequest_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return nvidia.riva.asr.RivaAsr.internal_static_nvidia_riva_asr_StreamingRecognizeRequest_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                nvidia.riva.asr.RivaAsr.StreamingRecognizeRequest.class, nvidia.riva.asr.RivaAsr.StreamingRecognizeRequest.Builder.class);
      }

      // Construct using nvidia.riva.asr.RivaAsr.StreamingRecognizeRequest.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      public Builder clear() {
        super.clear();
        streamingRequestCase_ = 0;
        streamingRequest_ = null;
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return nvidia.riva.asr.RivaAsr.internal_static_nvidia_riva_asr_StreamingRecognizeRequest_descriptor;
      }

      public nvidia.riva.asr.RivaAsr.StreamingRecognizeRequest getDefaultInstanceForType() {
        return nvidia.riva.asr.RivaAsr.StreamingRecognizeRequest.getDefaultInstance();
      }

      public nvidia.riva.asr.RivaAsr.StreamingRecognizeRequest build() {
        nvidia.riva.asr.RivaAsr.StreamingRecognizeRequest result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public nvidia.riva.asr.RivaAsr.StreamingRecognizeRequest buildPartial() {
        nvidia.riva.asr.RivaAsr.StreamingRecognizeRequest result = new nvidia.riva.asr.RivaAsr.StreamingRecognizeRequest(this);
        if (streamingRequestCase_ == 1) {
          if (streamingConfigBuilder_ == null) {
            result.streamingRequest_ = streamingRequest_;
          } else {
            result.streamingRequest_ = streamingConfigBuilder_.build();
          }
        }
        if (streamingRequestCase_ == 2) {
          result.streamingRequest_ = streamingRequest_;
        }
        result.streamingRequestCase_ = streamingRequestCase_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof nvidia.riva.asr.RivaAsr.StreamingRecognizeRequest) {
          return mergeFrom((nvidia.riva.asr.RivaAsr.StreamingRecognizeRequest)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(nvidia.riva.asr.RivaAsr.StreamingRecognizeRequest other) {
        if (other == nvidia.riva.asr.RivaAsr.StreamingRecognizeRequest.getDefaultInstance()) return this;
        switch (other.getStreamingRequestCase()) {
          case STREAMING_CONFIG: {
            mergeStreamingConfig(other.getStreamingConfig());
            break;
          }
          case AUDIO_CONTENT: {
            setAudioContent(other.getAudioContent());
            break;
          }
          case STREAMINGREQUEST_NOT_SET: {
            break;
          }
        }
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        nvidia.riva.asr.RivaAsr.StreamingRecognizeRequest parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (nvidia.riva.asr.RivaAsr.StreamingRecognizeRequest) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int streamingRequestCase_ = 0;
      private java.lang.Object streamingRequest_;
      public StreamingRequestCase
          getStreamingRequestCase() {
        return StreamingRequestCase.forNumber(
            streamingRequestCase_);
      }

      public Builder clearStreamingRequest() {
        streamingRequestCase_ = 0;
        streamingRequest_ = null;
        onChanged();
        return this;
      }


      private com.google.protobuf.SingleFieldBuilderV3<
          nvidia.riva.asr.RivaAsr.StreamingRecognitionConfig, nvidia.riva.asr.RivaAsr.StreamingRecognitionConfig.Builder, nvidia.riva.asr.RivaAsr.StreamingRecognitionConfigOrBuilder> streamingConfigBuilder_;
      /**
       * <pre>
       * Provides information to the recognizer that specifies how to process the
       * request. The first `StreamingRecognizeRequest` message must contain a
       * `streaming_config`  message.
       * </pre>
       *
       * <code>optional .nvidia.riva.asr.StreamingRecognitionConfig streaming_config = 1;</code>
       */
      public nvidia.riva.asr.RivaAsr.StreamingRecognitionConfig getStreamingConfig() {
        if (streamingConfigBuilder_ == null) {
          if (streamingRequestCase_ == 1) {
            return (nvidia.riva.asr.RivaAsr.StreamingRecognitionConfig) streamingRequest_;
          }
          return nvidia.riva.asr.RivaAsr.StreamingRecognitionConfig.getDefaultInstance();
        } else {
          if (streamingRequestCase_ == 1) {
            return streamingConfigBuilder_.getMessage();
          }
          return nvidia.riva.asr.RivaAsr.StreamingRecognitionConfig.getDefaultInstance();
        }
      }
      /**
       * <pre>
       * Provides information to the recognizer that specifies how to process the
       * request. The first `StreamingRecognizeRequest` message must contain a
       * `streaming_config`  message.
       * </pre>
       *
       * <code>optional .nvidia.riva.asr.StreamingRecognitionConfig streaming_config = 1;</code>
       */
      public Builder setStreamingConfig(nvidia.riva.asr.RivaAsr.StreamingRecognitionConfig value) {
        if (streamingConfigBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          streamingRequest_ = value;
          onChanged();
        } else {
          streamingConfigBuilder_.setMessage(value);
        }
        streamingRequestCase_ = 1;
        return this;
      }
      /**
       * <pre>
       * Provides information to the recognizer that specifies how to process the
       * request. The first `StreamingRecognizeRequest` message must contain a
       * `streaming_config`  message.
       * </pre>
       *
       * <code>optional .nvidia.riva.asr.StreamingRecognitionConfig streaming_config = 1;</code>
       */
      public Builder setStreamingConfig(
          nvidia.riva.asr.RivaAsr.StreamingRecognitionConfig.Builder builderForValue) {
        if (streamingConfigBuilder_ == null) {
          streamingRequest_ = builderForValue.build();
          onChanged();
        } else {
          streamingConfigBuilder_.setMessage(builderForValue.build());
        }
        streamingRequestCase_ = 1;
        return this;
      }
      /**
       * <pre>
       * Provides information to the recognizer that specifies how to process the
       * request. The first `StreamingRecognizeRequest` message must contain a
       * `streaming_config`  message.
       * </pre>
       *
       * <code>optional .nvidia.riva.asr.StreamingRecognitionConfig streaming_config = 1;</code>
       */
      public Builder mergeStreamingConfig(nvidia.riva.asr.RivaAsr.StreamingRecognitionConfig value) {
        if (streamingConfigBuilder_ == null) {
          if (streamingRequestCase_ == 1 &&
              streamingRequest_ != nvidia.riva.asr.RivaAsr.StreamingRecognitionConfig.getDefaultInstance()) {
            streamingRequest_ = nvidia.riva.asr.RivaAsr.StreamingRecognitionConfig.newBuilder((nvidia.riva.asr.RivaAsr.StreamingRecognitionConfig) streamingRequest_)
                .mergeFrom(value).buildPartial();
          } else {
            streamingRequest_ = value;
          }
          onChanged();
        } else {
          if (streamingRequestCase_ == 1) {
            streamingConfigBuilder_.mergeFrom(value);
          }
          streamingConfigBuilder_.setMessage(value);
        }
        streamingRequestCase_ = 1;
        return this;
      }
      /**
       * <pre>
       * Provides information to the recognizer that specifies how to process the
       * request. The first `StreamingRecognizeRequest` message must contain a
       * `streaming_config`  message.
       * </pre>
       *
       * <code>optional .nvidia.riva.asr.StreamingRecognitionConfig streaming_config = 1;</code>
       */
      public Builder clearStreamingConfig() {
        if (streamingConfigBuilder_ == null) {
          if (streamingRequestCase_ == 1) {
            streamingRequestCase_ = 0;
            streamingRequest_ = null;
            onChanged();
          }
        } else {
          if (streamingRequestCase_ == 1) {
            streamingRequestCase_ = 0;
            streamingRequest_ = null;
          }
          streamingConfigBuilder_.clear();
        }
        return this;
      }
      /**
       * <pre>
       * Provides information to the recognizer that specifies how to process the
       * request. The first `StreamingRecognizeRequest` message must contain a
       * `streaming_config`  message.
       * </pre>
       *
       * <code>optional .nvidia.riva.asr.StreamingRecognitionConfig streaming_config = 1;</code>
       */
      public nvidia.riva.asr.RivaAsr.StreamingRecognitionConfig.Builder getStreamingConfigBuilder() {
        return getStreamingConfigFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * Provides information to the recognizer that specifies how to process the
       * request. The first `StreamingRecognizeRequest` message must contain a
       * `streaming_config`  message.
       * </pre>
       *
       * <code>optional .nvidia.riva.asr.StreamingRecognitionConfig streaming_config = 1;</code>
       */
      public nvidia.riva.asr.RivaAsr.StreamingRecognitionConfigOrBuilder getStreamingConfigOrBuilder() {
        if ((streamingRequestCase_ == 1) && (streamingConfigBuilder_ != null)) {
          return streamingConfigBuilder_.getMessageOrBuilder();
        } else {
          if (streamingRequestCase_ == 1) {
            return (nvidia.riva.asr.RivaAsr.StreamingRecognitionConfig) streamingRequest_;
          }
          return nvidia.riva.asr.RivaAsr.StreamingRecognitionConfig.getDefaultInstance();
        }
      }
      /**
       * <pre>
       * Provides information to the recognizer that specifies how to process the
       * request. The first `StreamingRecognizeRequest` message must contain a
       * `streaming_config`  message.
       * </pre>
       *
       * <code>optional .nvidia.riva.asr.StreamingRecognitionConfig streaming_config = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          nvidia.riva.asr.RivaAsr.StreamingRecognitionConfig, nvidia.riva.asr.RivaAsr.StreamingRecognitionConfig.Builder, nvidia.riva.asr.RivaAsr.StreamingRecognitionConfigOrBuilder> 
          getStreamingConfigFieldBuilder() {
        if (streamingConfigBuilder_ == null) {
          if (!(streamingRequestCase_ == 1)) {
            streamingRequest_ = nvidia.riva.asr.RivaAsr.StreamingRecognitionConfig.getDefaultInstance();
          }
          streamingConfigBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              nvidia.riva.asr.RivaAsr.StreamingRecognitionConfig, nvidia.riva.asr.RivaAsr.StreamingRecognitionConfig.Builder, nvidia.riva.asr.RivaAsr.StreamingRecognitionConfigOrBuilder>(
                  (nvidia.riva.asr.RivaAsr.StreamingRecognitionConfig) streamingRequest_,
                  getParentForChildren(),
                  isClean());
          streamingRequest_ = null;
        }
        streamingRequestCase_ = 1;
        onChanged();;
        return streamingConfigBuilder_;
      }

      /**
       * <pre>
       * The audio data to be recognized. Sequential chunks of audio data are sent
       * in sequential `StreamingRecognizeRequest` messages. The first
       * `StreamingRecognizeRequest` message must not contain `audio` data
       * and all subsequent `StreamingRecognizeRequest` messages must contain
       * `audio` data. The audio bytes must be encoded as specified in
       * `RecognitionConfig`.
       * </pre>
       *
       * <code>optional bytes audio_content = 2;</code>
       */
      public com.google.protobuf.ByteString getAudioContent() {
        if (streamingRequestCase_ == 2) {
          return (com.google.protobuf.ByteString) streamingRequest_;
        }
        return com.google.protobuf.ByteString.EMPTY;
      }
      /**
       * <pre>
       * The audio data to be recognized. Sequential chunks of audio data are sent
       * in sequential `StreamingRecognizeRequest` messages. The first
       * `StreamingRecognizeRequest` message must not contain `audio` data
       * and all subsequent `StreamingRecognizeRequest` messages must contain
       * `audio` data. The audio bytes must be encoded as specified in
       * `RecognitionConfig`.
       * </pre>
       *
       * <code>optional bytes audio_content = 2;</code>
       */
      public Builder setAudioContent(com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  streamingRequestCase_ = 2;
        streamingRequest_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The audio data to be recognized. Sequential chunks of audio data are sent
       * in sequential `StreamingRecognizeRequest` messages. The first
       * `StreamingRecognizeRequest` message must not contain `audio` data
       * and all subsequent `StreamingRecognizeRequest` messages must contain
       * `audio` data. The audio bytes must be encoded as specified in
       * `RecognitionConfig`.
       * </pre>
       *
       * <code>optional bytes audio_content = 2;</code>
       */
      public Builder clearAudioContent() {
        if (streamingRequestCase_ == 2) {
          streamingRequestCase_ = 0;
          streamingRequest_ = null;
          onChanged();
        }
        return this;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return this;
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return this;
      }


      // @@protoc_insertion_point(builder_scope:nvidia.riva.asr.StreamingRecognizeRequest)
    }

    // @@protoc_insertion_point(class_scope:nvidia.riva.asr.StreamingRecognizeRequest)
    private static final nvidia.riva.asr.RivaAsr.StreamingRecognizeRequest DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new nvidia.riva.asr.RivaAsr.StreamingRecognizeRequest();
    }

    public static nvidia.riva.asr.RivaAsr.StreamingRecognizeRequest getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<StreamingRecognizeRequest>
        PARSER = new com.google.protobuf.AbstractParser<StreamingRecognizeRequest>() {
      public StreamingRecognizeRequest parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new StreamingRecognizeRequest(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<StreamingRecognizeRequest> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<StreamingRecognizeRequest> getParserForType() {
      return PARSER;
    }

    public nvidia.riva.asr.RivaAsr.StreamingRecognizeRequest getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface RecognitionConfigOrBuilder extends
      // @@protoc_insertion_point(interface_extends:nvidia.riva.asr.RecognitionConfig)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * The encoding of the audio data sent in the request.
     * All encodings support only 1 channel (mono) audio.
     * </pre>
     *
     * <code>optional .nvidia.riva.AudioEncoding encoding = 1;</code>
     */
    int getEncodingValue();
    /**
     * <pre>
     * The encoding of the audio data sent in the request.
     * All encodings support only 1 channel (mono) audio.
     * </pre>
     *
     * <code>optional .nvidia.riva.AudioEncoding encoding = 1;</code>
     */
    nvidia.riva.RivaAudio.AudioEncoding getEncoding();

    /**
     * <pre>
     *  Sample rate in Hertz of the audio data sent in all
     * `RecognizeAudio` messages.
     * </pre>
     *
     * <code>optional int32 sample_rate_hertz = 2;</code>
     */
    int getSampleRateHertz();

    /**
     * <pre>
     * Required. The language of the supplied audio as a
     * [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt) language tag.
     * Example: "en-US".
     * Currently only en-US is supported
     * </pre>
     *
     * <code>optional string language_code = 3;</code>
     */
    java.lang.String getLanguageCode();
    /**
     * <pre>
     * Required. The language of the supplied audio as a
     * [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt) language tag.
     * Example: "en-US".
     * Currently only en-US is supported
     * </pre>
     *
     * <code>optional string language_code = 3;</code>
     */
    com.google.protobuf.ByteString
        getLanguageCodeBytes();

    /**
     * <pre>
     * Maximum number of recognition hypotheses to be returned.
     * Specifically, the maximum number of `SpeechRecognizeAlternative` messages
     * within each `SpeechRecognizeResult`.
     * The server may return fewer than `max_alternatives`.
     * If omitted, will return a maximum of one.
     * </pre>
     *
     * <code>optional int32 max_alternatives = 4;</code>
     */
    int getMaxAlternatives();

    /**
     * <pre>
     * The number of channels in the input audio data.
     * ONLY set this for MULTI-CHANNEL recognition.
     * Valid values for LINEAR16 and FLAC are `1`-`8`.
     * Valid values for OGG_OPUS are '1'-'254'.
     * Valid value for MULAW, AMR, AMR_WB and SPEEX_WITH_HEADER_BYTE is only `1`.
     * If `0` or omitted, defaults to one channel (mono).
     * Note: We only recognize the first channel by default.
     * To perform independent recognition on each channel set
     * `enable_separate_recognition_per_channel` to 'true'.
     * </pre>
     *
     * <code>optional int32 audio_channel_count = 7;</code>
     */
    int getAudioChannelCount();

    /**
     * <pre>
     * If `true`, the top result includes a list of words and
     * the start and end time offsets (timestamps) for those words. If
     * `false`, no word-level time offset information is returned. The default is
     * `false`.
     * </pre>
     *
     * <code>optional bool enable_word_time_offsets = 8;</code>
     */
    boolean getEnableWordTimeOffsets();

    /**
     * <pre>
     * If 'true', adds punctuation to recognition result hypotheses.
     * The default 'false' value does not add punctuation to result hypotheses.
     * </pre>
     *
     * <code>optional bool enable_automatic_punctuation = 11;</code>
     */
    boolean getEnableAutomaticPunctuation();

    /**
     * <pre>
     * This needs to be set to `true` explicitly and `audio_channel_count` &gt; 1
     * to get each channel recognized separately. The recognition result will
     * contain a `channel_tag` field to state which channel that result belongs
     * to. If this is not true, we will only recognize the first channel. The
     * request is billed cumulatively for all channels recognized:
     * `audio_channel_count` multiplied by the length of the audio.
     * </pre>
     *
     * <code>optional bool enable_separate_recognition_per_channel = 12;</code>
     */
    boolean getEnableSeparateRecognitionPerChannel();

    /**
     * <pre>
     * Which model to select for the given request. Valid choices: Jasper, Quartznet
     * </pre>
     *
     * <code>optional string model = 13;</code>
     */
    java.lang.String getModel();
    /**
     * <pre>
     * Which model to select for the given request. Valid choices: Jasper, Quartznet
     * </pre>
     *
     * <code>optional string model = 13;</code>
     */
    com.google.protobuf.ByteString
        getModelBytes();

    /**
     * <pre>
     * The verbatim_transcripts flag enables or disable inverse text normalization.
     * 'true' returns exactly what was said, with no denormalization.
     * 'false' applies inverse text normalization, also this is the default
     * </pre>
     *
     * <code>optional bool verbatim_transcripts = 14;</code>
     */
    boolean getVerbatimTranscripts();

    /**
     * <pre>
     * Custom fields for passing request-level
     * configuration options to plugins used in the
     * model pipeline.
     * </pre>
     *
     * <code>map&lt;string, string&gt; custom_configuration = 24;</code>
     */
    int getCustomConfigurationCount();
    /**
     * <pre>
     * Custom fields for passing request-level
     * configuration options to plugins used in the
     * model pipeline.
     * </pre>
     *
     * <code>map&lt;string, string&gt; custom_configuration = 24;</code>
     */
    boolean containsCustomConfiguration(
        java.lang.String key);
    /**
     * Use {@link #getCustomConfigurationMap()} instead.
     */
    @java.lang.Deprecated
    java.util.Map<java.lang.String, java.lang.String>
    getCustomConfiguration();
    /**
     * <pre>
     * Custom fields for passing request-level
     * configuration options to plugins used in the
     * model pipeline.
     * </pre>
     *
     * <code>map&lt;string, string&gt; custom_configuration = 24;</code>
     */
    java.util.Map<java.lang.String, java.lang.String>
    getCustomConfigurationMap();
    /**
     * <pre>
     * Custom fields for passing request-level
     * configuration options to plugins used in the
     * model pipeline.
     * </pre>
     *
     * <code>map&lt;string, string&gt; custom_configuration = 24;</code>
     */

    java.lang.String getCustomConfigurationOrDefault(
        java.lang.String key,
        java.lang.String defaultValue);
    /**
     * <pre>
     * Custom fields for passing request-level
     * configuration options to plugins used in the
     * model pipeline.
     * </pre>
     *
     * <code>map&lt;string, string&gt; custom_configuration = 24;</code>
     */

    java.lang.String getCustomConfigurationOrThrow(
        java.lang.String key);
  }
  /**
   * <pre>
   * Provides information to the recognizer that specifies how to process the request
   * </pre>
   *
   * Protobuf type {@code nvidia.riva.asr.RecognitionConfig}
   */
  public  static final class RecognitionConfig extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:nvidia.riva.asr.RecognitionConfig)
      RecognitionConfigOrBuilder {
    // Use RecognitionConfig.newBuilder() to construct.
    private RecognitionConfig(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private RecognitionConfig() {
      encoding_ = 0;
      sampleRateHertz_ = 0;
      languageCode_ = "";
      maxAlternatives_ = 0;
      audioChannelCount_ = 0;
      enableWordTimeOffsets_ = false;
      enableAutomaticPunctuation_ = false;
      enableSeparateRecognitionPerChannel_ = false;
      model_ = "";
      verbatimTranscripts_ = false;
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return com.google.protobuf.UnknownFieldSet.getDefaultInstance();
    }
    private RecognitionConfig(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!input.skipField(tag)) {
                done = true;
              }
              break;
            }
            case 8: {
              int rawValue = input.readEnum();

              encoding_ = rawValue;
              break;
            }
            case 16: {

              sampleRateHertz_ = input.readInt32();
              break;
            }
            case 26: {
              java.lang.String s = input.readStringRequireUtf8();

              languageCode_ = s;
              break;
            }
            case 32: {

              maxAlternatives_ = input.readInt32();
              break;
            }
            case 56: {

              audioChannelCount_ = input.readInt32();
              break;
            }
            case 64: {

              enableWordTimeOffsets_ = input.readBool();
              break;
            }
            case 88: {

              enableAutomaticPunctuation_ = input.readBool();
              break;
            }
            case 96: {

              enableSeparateRecognitionPerChannel_ = input.readBool();
              break;
            }
            case 106: {
              java.lang.String s = input.readStringRequireUtf8();

              model_ = s;
              break;
            }
            case 112: {

              verbatimTranscripts_ = input.readBool();
              break;
            }
            case 194: {
              if (!((mutable_bitField0_ & 0x00000400) == 0x00000400)) {
                customConfiguration_ = com.google.protobuf.MapField.newMapField(
                    CustomConfigurationDefaultEntryHolder.defaultEntry);
                mutable_bitField0_ |= 0x00000400;
              }
              com.google.protobuf.MapEntry<java.lang.String, java.lang.String>
              customConfiguration__ = input.readMessage(
                  CustomConfigurationDefaultEntryHolder.defaultEntry.getParserForType(), extensionRegistry);
              customConfiguration_.getMutableMap().put(
                  customConfiguration__.getKey(), customConfiguration__.getValue());
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return nvidia.riva.asr.RivaAsr.internal_static_nvidia_riva_asr_RecognitionConfig_descriptor;
    }

    @SuppressWarnings({"rawtypes"})
    protected com.google.protobuf.MapField internalGetMapField(
        int number) {
      switch (number) {
        case 24:
          return internalGetCustomConfiguration();
        default:
          throw new RuntimeException(
              "Invalid map field number: " + number);
      }
    }
    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return nvidia.riva.asr.RivaAsr.internal_static_nvidia_riva_asr_RecognitionConfig_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              nvidia.riva.asr.RivaAsr.RecognitionConfig.class, nvidia.riva.asr.RivaAsr.RecognitionConfig.Builder.class);
    }

    private int bitField0_;
    public static final int ENCODING_FIELD_NUMBER = 1;
    private int encoding_;
    /**
     * <pre>
     * The encoding of the audio data sent in the request.
     * All encodings support only 1 channel (mono) audio.
     * </pre>
     *
     * <code>optional .nvidia.riva.AudioEncoding encoding = 1;</code>
     */
    public int getEncodingValue() {
      return encoding_;
    }
    /**
     * <pre>
     * The encoding of the audio data sent in the request.
     * All encodings support only 1 channel (mono) audio.
     * </pre>
     *
     * <code>optional .nvidia.riva.AudioEncoding encoding = 1;</code>
     */
    public nvidia.riva.RivaAudio.AudioEncoding getEncoding() {
      nvidia.riva.RivaAudio.AudioEncoding result = nvidia.riva.RivaAudio.AudioEncoding.valueOf(encoding_);
      return result == null ? nvidia.riva.RivaAudio.AudioEncoding.UNRECOGNIZED : result;
    }

    public static final int SAMPLE_RATE_HERTZ_FIELD_NUMBER = 2;
    private int sampleRateHertz_;
    /**
     * <pre>
     *  Sample rate in Hertz of the audio data sent in all
     * `RecognizeAudio` messages.
     * </pre>
     *
     * <code>optional int32 sample_rate_hertz = 2;</code>
     */
    public int getSampleRateHertz() {
      return sampleRateHertz_;
    }

    public static final int LANGUAGE_CODE_FIELD_NUMBER = 3;
    private volatile java.lang.Object languageCode_;
    /**
     * <pre>
     * Required. The language of the supplied audio as a
     * [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt) language tag.
     * Example: "en-US".
     * Currently only en-US is supported
     * </pre>
     *
     * <code>optional string language_code = 3;</code>
     */
    public java.lang.String getLanguageCode() {
      java.lang.Object ref = languageCode_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        languageCode_ = s;
        return s;
      }
    }
    /**
     * <pre>
     * Required. The language of the supplied audio as a
     * [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt) language tag.
     * Example: "en-US".
     * Currently only en-US is supported
     * </pre>
     *
     * <code>optional string language_code = 3;</code>
     */
    public com.google.protobuf.ByteString
        getLanguageCodeBytes() {
      java.lang.Object ref = languageCode_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        languageCode_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int MAX_ALTERNATIVES_FIELD_NUMBER = 4;
    private int maxAlternatives_;
    /**
     * <pre>
     * Maximum number of recognition hypotheses to be returned.
     * Specifically, the maximum number of `SpeechRecognizeAlternative` messages
     * within each `SpeechRecognizeResult`.
     * The server may return fewer than `max_alternatives`.
     * If omitted, will return a maximum of one.
     * </pre>
     *
     * <code>optional int32 max_alternatives = 4;</code>
     */
    public int getMaxAlternatives() {
      return maxAlternatives_;
    }

    public static final int AUDIO_CHANNEL_COUNT_FIELD_NUMBER = 7;
    private int audioChannelCount_;
    /**
     * <pre>
     * The number of channels in the input audio data.
     * ONLY set this for MULTI-CHANNEL recognition.
     * Valid values for LINEAR16 and FLAC are `1`-`8`.
     * Valid values for OGG_OPUS are '1'-'254'.
     * Valid value for MULAW, AMR, AMR_WB and SPEEX_WITH_HEADER_BYTE is only `1`.
     * If `0` or omitted, defaults to one channel (mono).
     * Note: We only recognize the first channel by default.
     * To perform independent recognition on each channel set
     * `enable_separate_recognition_per_channel` to 'true'.
     * </pre>
     *
     * <code>optional int32 audio_channel_count = 7;</code>
     */
    public int getAudioChannelCount() {
      return audioChannelCount_;
    }

    public static final int ENABLE_WORD_TIME_OFFSETS_FIELD_NUMBER = 8;
    private boolean enableWordTimeOffsets_;
    /**
     * <pre>
     * If `true`, the top result includes a list of words and
     * the start and end time offsets (timestamps) for those words. If
     * `false`, no word-level time offset information is returned. The default is
     * `false`.
     * </pre>
     *
     * <code>optional bool enable_word_time_offsets = 8;</code>
     */
    public boolean getEnableWordTimeOffsets() {
      return enableWordTimeOffsets_;
    }

    public static final int ENABLE_AUTOMATIC_PUNCTUATION_FIELD_NUMBER = 11;
    private boolean enableAutomaticPunctuation_;
    /**
     * <pre>
     * If 'true', adds punctuation to recognition result hypotheses.
     * The default 'false' value does not add punctuation to result hypotheses.
     * </pre>
     *
     * <code>optional bool enable_automatic_punctuation = 11;</code>
     */
    public boolean getEnableAutomaticPunctuation() {
      return enableAutomaticPunctuation_;
    }

    public static final int ENABLE_SEPARATE_RECOGNITION_PER_CHANNEL_FIELD_NUMBER = 12;
    private boolean enableSeparateRecognitionPerChannel_;
    /**
     * <pre>
     * This needs to be set to `true` explicitly and `audio_channel_count` &gt; 1
     * to get each channel recognized separately. The recognition result will
     * contain a `channel_tag` field to state which channel that result belongs
     * to. If this is not true, we will only recognize the first channel. The
     * request is billed cumulatively for all channels recognized:
     * `audio_channel_count` multiplied by the length of the audio.
     * </pre>
     *
     * <code>optional bool enable_separate_recognition_per_channel = 12;</code>
     */
    public boolean getEnableSeparateRecognitionPerChannel() {
      return enableSeparateRecognitionPerChannel_;
    }

    public static final int MODEL_FIELD_NUMBER = 13;
    private volatile java.lang.Object model_;
    /**
     * <pre>
     * Which model to select for the given request. Valid choices: Jasper, Quartznet
     * </pre>
     *
     * <code>optional string model = 13;</code>
     */
    public java.lang.String getModel() {
      java.lang.Object ref = model_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        model_ = s;
        return s;
      }
    }
    /**
     * <pre>
     * Which model to select for the given request. Valid choices: Jasper, Quartznet
     * </pre>
     *
     * <code>optional string model = 13;</code>
     */
    public com.google.protobuf.ByteString
        getModelBytes() {
      java.lang.Object ref = model_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        model_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int VERBATIM_TRANSCRIPTS_FIELD_NUMBER = 14;
    private boolean verbatimTranscripts_;
    /**
     * <pre>
     * The verbatim_transcripts flag enables or disable inverse text normalization.
     * 'true' returns exactly what was said, with no denormalization.
     * 'false' applies inverse text normalization, also this is the default
     * </pre>
     *
     * <code>optional bool verbatim_transcripts = 14;</code>
     */
    public boolean getVerbatimTranscripts() {
      return verbatimTranscripts_;
    }

    public static final int CUSTOM_CONFIGURATION_FIELD_NUMBER = 24;
    private static final class CustomConfigurationDefaultEntryHolder {
      static final com.google.protobuf.MapEntry<
          java.lang.String, java.lang.String> defaultEntry =
              com.google.protobuf.MapEntry
              .<java.lang.String, java.lang.String>newDefaultInstance(
                  nvidia.riva.asr.RivaAsr.internal_static_nvidia_riva_asr_RecognitionConfig_CustomConfigurationEntry_descriptor, 
                  com.google.protobuf.WireFormat.FieldType.STRING,
                  "",
                  com.google.protobuf.WireFormat.FieldType.STRING,
                  "");
    }
    private com.google.protobuf.MapField<
        java.lang.String, java.lang.String> customConfiguration_;
    private com.google.protobuf.MapField<java.lang.String, java.lang.String>
    internalGetCustomConfiguration() {
      if (customConfiguration_ == null) {
        return com.google.protobuf.MapField.emptyMapField(
            CustomConfigurationDefaultEntryHolder.defaultEntry);
      }
      return customConfiguration_;
    }

    public int getCustomConfigurationCount() {
      return internalGetCustomConfiguration().getMap().size();
    }
    /**
     * <pre>
     * Custom fields for passing request-level
     * configuration options to plugins used in the
     * model pipeline.
     * </pre>
     *
     * <code>map&lt;string, string&gt; custom_configuration = 24;</code>
     */

    public boolean containsCustomConfiguration(
        java.lang.String key) {
      if (key == null) { throw new java.lang.NullPointerException(); }
      return internalGetCustomConfiguration().getMap().containsKey(key);
    }
    /**
     * Use {@link #getCustomConfigurationMap()} instead.
     */
    @java.lang.Deprecated
    public java.util.Map<java.lang.String, java.lang.String> getCustomConfiguration() {
      return getCustomConfigurationMap();
    }
    /**
     * <pre>
     * Custom fields for passing request-level
     * configuration options to plugins used in the
     * model pipeline.
     * </pre>
     *
     * <code>map&lt;string, string&gt; custom_configuration = 24;</code>
     */

    public java.util.Map<java.lang.String, java.lang.String> getCustomConfigurationMap() {
      return internalGetCustomConfiguration().getMap();
    }
    /**
     * <pre>
     * Custom fields for passing request-level
     * configuration options to plugins used in the
     * model pipeline.
     * </pre>
     *
     * <code>map&lt;string, string&gt; custom_configuration = 24;</code>
     */

    public java.lang.String getCustomConfigurationOrDefault(
        java.lang.String key,
        java.lang.String defaultValue) {
      if (key == null) { throw new java.lang.NullPointerException(); }
      java.util.Map<java.lang.String, java.lang.String> map =
          internalGetCustomConfiguration().getMap();
      return map.containsKey(key) ? map.get(key) : defaultValue;
    }
    /**
     * <pre>
     * Custom fields for passing request-level
     * configuration options to plugins used in the
     * model pipeline.
     * </pre>
     *
     * <code>map&lt;string, string&gt; custom_configuration = 24;</code>
     */

    public java.lang.String getCustomConfigurationOrThrow(
        java.lang.String key) {
      if (key == null) { throw new java.lang.NullPointerException(); }
      java.util.Map<java.lang.String, java.lang.String> map =
          internalGetCustomConfiguration().getMap();
      if (!map.containsKey(key)) {
        throw new java.lang.IllegalArgumentException();
      }
      return map.get(key);
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (encoding_ != nvidia.riva.RivaAudio.AudioEncoding.ENCODING_UNSPECIFIED.getNumber()) {
        output.writeEnum(1, encoding_);
      }
      if (sampleRateHertz_ != 0) {
        output.writeInt32(2, sampleRateHertz_);
      }
      if (!getLanguageCodeBytes().isEmpty()) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 3, languageCode_);
      }
      if (maxAlternatives_ != 0) {
        output.writeInt32(4, maxAlternatives_);
      }
      if (audioChannelCount_ != 0) {
        output.writeInt32(7, audioChannelCount_);
      }
      if (enableWordTimeOffsets_ != false) {
        output.writeBool(8, enableWordTimeOffsets_);
      }
      if (enableAutomaticPunctuation_ != false) {
        output.writeBool(11, enableAutomaticPunctuation_);
      }
      if (enableSeparateRecognitionPerChannel_ != false) {
        output.writeBool(12, enableSeparateRecognitionPerChannel_);
      }
      if (!getModelBytes().isEmpty()) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 13, model_);
      }
      if (verbatimTranscripts_ != false) {
        output.writeBool(14, verbatimTranscripts_);
      }
      com.google.protobuf.GeneratedMessageV3
        .serializeStringMapTo(
          output,
          internalGetCustomConfiguration(),
          CustomConfigurationDefaultEntryHolder.defaultEntry,
          24);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (encoding_ != nvidia.riva.RivaAudio.AudioEncoding.ENCODING_UNSPECIFIED.getNumber()) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(1, encoding_);
      }
      if (sampleRateHertz_ != 0) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(2, sampleRateHertz_);
      }
      if (!getLanguageCodeBytes().isEmpty()) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(3, languageCode_);
      }
      if (maxAlternatives_ != 0) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(4, maxAlternatives_);
      }
      if (audioChannelCount_ != 0) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(7, audioChannelCount_);
      }
      if (enableWordTimeOffsets_ != false) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(8, enableWordTimeOffsets_);
      }
      if (enableAutomaticPunctuation_ != false) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(11, enableAutomaticPunctuation_);
      }
      if (enableSeparateRecognitionPerChannel_ != false) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(12, enableSeparateRecognitionPerChannel_);
      }
      if (!getModelBytes().isEmpty()) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(13, model_);
      }
      if (verbatimTranscripts_ != false) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(14, verbatimTranscripts_);
      }
      for (java.util.Map.Entry<java.lang.String, java.lang.String> entry
           : internalGetCustomConfiguration().getMap().entrySet()) {
        com.google.protobuf.MapEntry<java.lang.String, java.lang.String>
        customConfiguration__ = CustomConfigurationDefaultEntryHolder.defaultEntry.newBuilderForType()
            .setKey(entry.getKey())
            .setValue(entry.getValue())
            .build();
        size += com.google.protobuf.CodedOutputStream
            .computeMessageSize(24, customConfiguration__);
      }
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof nvidia.riva.asr.RivaAsr.RecognitionConfig)) {
        return super.equals(obj);
      }
      nvidia.riva.asr.RivaAsr.RecognitionConfig other = (nvidia.riva.asr.RivaAsr.RecognitionConfig) obj;

      boolean result = true;
      result = result && encoding_ == other.encoding_;
      result = result && (getSampleRateHertz()
          == other.getSampleRateHertz());
      result = result && getLanguageCode()
          .equals(other.getLanguageCode());
      result = result && (getMaxAlternatives()
          == other.getMaxAlternatives());
      result = result && (getAudioChannelCount()
          == other.getAudioChannelCount());
      result = result && (getEnableWordTimeOffsets()
          == other.getEnableWordTimeOffsets());
      result = result && (getEnableAutomaticPunctuation()
          == other.getEnableAutomaticPunctuation());
      result = result && (getEnableSeparateRecognitionPerChannel()
          == other.getEnableSeparateRecognitionPerChannel());
      result = result && getModel()
          .equals(other.getModel());
      result = result && (getVerbatimTranscripts()
          == other.getVerbatimTranscripts());
      result = result && internalGetCustomConfiguration().equals(
          other.internalGetCustomConfiguration());
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      hash = (37 * hash) + ENCODING_FIELD_NUMBER;
      hash = (53 * hash) + encoding_;
      hash = (37 * hash) + SAMPLE_RATE_HERTZ_FIELD_NUMBER;
      hash = (53 * hash) + getSampleRateHertz();
      hash = (37 * hash) + LANGUAGE_CODE_FIELD_NUMBER;
      hash = (53 * hash) + getLanguageCode().hashCode();
      hash = (37 * hash) + MAX_ALTERNATIVES_FIELD_NUMBER;
      hash = (53 * hash) + getMaxAlternatives();
      hash = (37 * hash) + AUDIO_CHANNEL_COUNT_FIELD_NUMBER;
      hash = (53 * hash) + getAudioChannelCount();
      hash = (37 * hash) + ENABLE_WORD_TIME_OFFSETS_FIELD_NUMBER;
      hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
          getEnableWordTimeOffsets());
      hash = (37 * hash) + ENABLE_AUTOMATIC_PUNCTUATION_FIELD_NUMBER;
      hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
          getEnableAutomaticPunctuation());
      hash = (37 * hash) + ENABLE_SEPARATE_RECOGNITION_PER_CHANNEL_FIELD_NUMBER;
      hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
          getEnableSeparateRecognitionPerChannel());
      hash = (37 * hash) + MODEL_FIELD_NUMBER;
      hash = (53 * hash) + getModel().hashCode();
      hash = (37 * hash) + VERBATIM_TRANSCRIPTS_FIELD_NUMBER;
      hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
          getVerbatimTranscripts());
      if (!internalGetCustomConfiguration().getMap().isEmpty()) {
        hash = (37 * hash) + CUSTOM_CONFIGURATION_FIELD_NUMBER;
        hash = (53 * hash) + internalGetCustomConfiguration().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static nvidia.riva.asr.RivaAsr.RecognitionConfig parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static nvidia.riva.asr.RivaAsr.RecognitionConfig parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static nvidia.riva.asr.RivaAsr.RecognitionConfig parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static nvidia.riva.asr.RivaAsr.RecognitionConfig parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static nvidia.riva.asr.RivaAsr.RecognitionConfig parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static nvidia.riva.asr.RivaAsr.RecognitionConfig parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static nvidia.riva.asr.RivaAsr.RecognitionConfig parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static nvidia.riva.asr.RivaAsr.RecognitionConfig parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static nvidia.riva.asr.RivaAsr.RecognitionConfig parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static nvidia.riva.asr.RivaAsr.RecognitionConfig parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(nvidia.riva.asr.RivaAsr.RecognitionConfig prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     * Provides information to the recognizer that specifies how to process the request
     * </pre>
     *
     * Protobuf type {@code nvidia.riva.asr.RecognitionConfig}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:nvidia.riva.asr.RecognitionConfig)
        nvidia.riva.asr.RivaAsr.RecognitionConfigOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return nvidia.riva.asr.RivaAsr.internal_static_nvidia_riva_asr_RecognitionConfig_descriptor;
      }

      @SuppressWarnings({"rawtypes"})
      protected com.google.protobuf.MapField internalGetMapField(
          int number) {
        switch (number) {
          case 24:
            return internalGetCustomConfiguration();
          default:
            throw new RuntimeException(
                "Invalid map field number: " + number);
        }
      }
      @SuppressWarnings({"rawtypes"})
      protected com.google.protobuf.MapField internalGetMutableMapField(
          int number) {
        switch (number) {
          case 24:
            return internalGetMutableCustomConfiguration();
          default:
            throw new RuntimeException(
                "Invalid map field number: " + number);
        }
      }
      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return nvidia.riva.asr.RivaAsr.internal_static_nvidia_riva_asr_RecognitionConfig_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                nvidia.riva.asr.RivaAsr.RecognitionConfig.class, nvidia.riva.asr.RivaAsr.RecognitionConfig.Builder.class);
      }

      // Construct using nvidia.riva.asr.RivaAsr.RecognitionConfig.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      public Builder clear() {
        super.clear();
        encoding_ = 0;

        sampleRateHertz_ = 0;

        languageCode_ = "";

        maxAlternatives_ = 0;

        audioChannelCount_ = 0;

        enableWordTimeOffsets_ = false;

        enableAutomaticPunctuation_ = false;

        enableSeparateRecognitionPerChannel_ = false;

        model_ = "";

        verbatimTranscripts_ = false;

        internalGetMutableCustomConfiguration().clear();
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return nvidia.riva.asr.RivaAsr.internal_static_nvidia_riva_asr_RecognitionConfig_descriptor;
      }

      public nvidia.riva.asr.RivaAsr.RecognitionConfig getDefaultInstanceForType() {
        return nvidia.riva.asr.RivaAsr.RecognitionConfig.getDefaultInstance();
      }

      public nvidia.riva.asr.RivaAsr.RecognitionConfig build() {
        nvidia.riva.asr.RivaAsr.RecognitionConfig result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public nvidia.riva.asr.RivaAsr.RecognitionConfig buildPartial() {
        nvidia.riva.asr.RivaAsr.RecognitionConfig result = new nvidia.riva.asr.RivaAsr.RecognitionConfig(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        result.encoding_ = encoding_;
        result.sampleRateHertz_ = sampleRateHertz_;
        result.languageCode_ = languageCode_;
        result.maxAlternatives_ = maxAlternatives_;
        result.audioChannelCount_ = audioChannelCount_;
        result.enableWordTimeOffsets_ = enableWordTimeOffsets_;
        result.enableAutomaticPunctuation_ = enableAutomaticPunctuation_;
        result.enableSeparateRecognitionPerChannel_ = enableSeparateRecognitionPerChannel_;
        result.model_ = model_;
        result.verbatimTranscripts_ = verbatimTranscripts_;
        result.customConfiguration_ = internalGetCustomConfiguration();
        result.customConfiguration_.makeImmutable();
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof nvidia.riva.asr.RivaAsr.RecognitionConfig) {
          return mergeFrom((nvidia.riva.asr.RivaAsr.RecognitionConfig)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(nvidia.riva.asr.RivaAsr.RecognitionConfig other) {
        if (other == nvidia.riva.asr.RivaAsr.RecognitionConfig.getDefaultInstance()) return this;
        if (other.encoding_ != 0) {
          setEncodingValue(other.getEncodingValue());
        }
        if (other.getSampleRateHertz() != 0) {
          setSampleRateHertz(other.getSampleRateHertz());
        }
        if (!other.getLanguageCode().isEmpty()) {
          languageCode_ = other.languageCode_;
          onChanged();
        }
        if (other.getMaxAlternatives() != 0) {
          setMaxAlternatives(other.getMaxAlternatives());
        }
        if (other.getAudioChannelCount() != 0) {
          setAudioChannelCount(other.getAudioChannelCount());
        }
        if (other.getEnableWordTimeOffsets() != false) {
          setEnableWordTimeOffsets(other.getEnableWordTimeOffsets());
        }
        if (other.getEnableAutomaticPunctuation() != false) {
          setEnableAutomaticPunctuation(other.getEnableAutomaticPunctuation());
        }
        if (other.getEnableSeparateRecognitionPerChannel() != false) {
          setEnableSeparateRecognitionPerChannel(other.getEnableSeparateRecognitionPerChannel());
        }
        if (!other.getModel().isEmpty()) {
          model_ = other.model_;
          onChanged();
        }
        if (other.getVerbatimTranscripts() != false) {
          setVerbatimTranscripts(other.getVerbatimTranscripts());
        }
        internalGetMutableCustomConfiguration().mergeFrom(
            other.internalGetCustomConfiguration());
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        nvidia.riva.asr.RivaAsr.RecognitionConfig parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (nvidia.riva.asr.RivaAsr.RecognitionConfig) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private int encoding_ = 0;
      /**
       * <pre>
       * The encoding of the audio data sent in the request.
       * All encodings support only 1 channel (mono) audio.
       * </pre>
       *
       * <code>optional .nvidia.riva.AudioEncoding encoding = 1;</code>
       */
      public int getEncodingValue() {
        return encoding_;
      }
      /**
       * <pre>
       * The encoding of the audio data sent in the request.
       * All encodings support only 1 channel (mono) audio.
       * </pre>
       *
       * <code>optional .nvidia.riva.AudioEncoding encoding = 1;</code>
       */
      public Builder setEncodingValue(int value) {
        encoding_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The encoding of the audio data sent in the request.
       * All encodings support only 1 channel (mono) audio.
       * </pre>
       *
       * <code>optional .nvidia.riva.AudioEncoding encoding = 1;</code>
       */
      public nvidia.riva.RivaAudio.AudioEncoding getEncoding() {
        nvidia.riva.RivaAudio.AudioEncoding result = nvidia.riva.RivaAudio.AudioEncoding.valueOf(encoding_);
        return result == null ? nvidia.riva.RivaAudio.AudioEncoding.UNRECOGNIZED : result;
      }
      /**
       * <pre>
       * The encoding of the audio data sent in the request.
       * All encodings support only 1 channel (mono) audio.
       * </pre>
       *
       * <code>optional .nvidia.riva.AudioEncoding encoding = 1;</code>
       */
      public Builder setEncoding(nvidia.riva.RivaAudio.AudioEncoding value) {
        if (value == null) {
          throw new NullPointerException();
        }
        
        encoding_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The encoding of the audio data sent in the request.
       * All encodings support only 1 channel (mono) audio.
       * </pre>
       *
       * <code>optional .nvidia.riva.AudioEncoding encoding = 1;</code>
       */
      public Builder clearEncoding() {
        
        encoding_ = 0;
        onChanged();
        return this;
      }

      private int sampleRateHertz_ ;
      /**
       * <pre>
       *  Sample rate in Hertz of the audio data sent in all
       * `RecognizeAudio` messages.
       * </pre>
       *
       * <code>optional int32 sample_rate_hertz = 2;</code>
       */
      public int getSampleRateHertz() {
        return sampleRateHertz_;
      }
      /**
       * <pre>
       *  Sample rate in Hertz of the audio data sent in all
       * `RecognizeAudio` messages.
       * </pre>
       *
       * <code>optional int32 sample_rate_hertz = 2;</code>
       */
      public Builder setSampleRateHertz(int value) {
        
        sampleRateHertz_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       *  Sample rate in Hertz of the audio data sent in all
       * `RecognizeAudio` messages.
       * </pre>
       *
       * <code>optional int32 sample_rate_hertz = 2;</code>
       */
      public Builder clearSampleRateHertz() {
        
        sampleRateHertz_ = 0;
        onChanged();
        return this;
      }

      private java.lang.Object languageCode_ = "";
      /**
       * <pre>
       * Required. The language of the supplied audio as a
       * [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt) language tag.
       * Example: "en-US".
       * Currently only en-US is supported
       * </pre>
       *
       * <code>optional string language_code = 3;</code>
       */
      public java.lang.String getLanguageCode() {
        java.lang.Object ref = languageCode_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          languageCode_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * Required. The language of the supplied audio as a
       * [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt) language tag.
       * Example: "en-US".
       * Currently only en-US is supported
       * </pre>
       *
       * <code>optional string language_code = 3;</code>
       */
      public com.google.protobuf.ByteString
          getLanguageCodeBytes() {
        java.lang.Object ref = languageCode_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          languageCode_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * Required. The language of the supplied audio as a
       * [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt) language tag.
       * Example: "en-US".
       * Currently only en-US is supported
       * </pre>
       *
       * <code>optional string language_code = 3;</code>
       */
      public Builder setLanguageCode(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  
        languageCode_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Required. The language of the supplied audio as a
       * [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt) language tag.
       * Example: "en-US".
       * Currently only en-US is supported
       * </pre>
       *
       * <code>optional string language_code = 3;</code>
       */
      public Builder clearLanguageCode() {
        
        languageCode_ = getDefaultInstance().getLanguageCode();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Required. The language of the supplied audio as a
       * [BCP-47](https://www.rfc-editor.org/rfc/bcp/bcp47.txt) language tag.
       * Example: "en-US".
       * Currently only en-US is supported
       * </pre>
       *
       * <code>optional string language_code = 3;</code>
       */
      public Builder setLanguageCodeBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        
        languageCode_ = value;
        onChanged();
        return this;
      }

      private int maxAlternatives_ ;
      /**
       * <pre>
       * Maximum number of recognition hypotheses to be returned.
       * Specifically, the maximum number of `SpeechRecognizeAlternative` messages
       * within each `SpeechRecognizeResult`.
       * The server may return fewer than `max_alternatives`.
       * If omitted, will return a maximum of one.
       * </pre>
       *
       * <code>optional int32 max_alternatives = 4;</code>
       */
      public int getMaxAlternatives() {
        return maxAlternatives_;
      }
      /**
       * <pre>
       * Maximum number of recognition hypotheses to be returned.
       * Specifically, the maximum number of `SpeechRecognizeAlternative` messages
       * within each `SpeechRecognizeResult`.
       * The server may return fewer than `max_alternatives`.
       * If omitted, will return a maximum of one.
       * </pre>
       *
       * <code>optional int32 max_alternatives = 4;</code>
       */
      public Builder setMaxAlternatives(int value) {
        
        maxAlternatives_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Maximum number of recognition hypotheses to be returned.
       * Specifically, the maximum number of `SpeechRecognizeAlternative` messages
       * within each `SpeechRecognizeResult`.
       * The server may return fewer than `max_alternatives`.
       * If omitted, will return a maximum of one.
       * </pre>
       *
       * <code>optional int32 max_alternatives = 4;</code>
       */
      public Builder clearMaxAlternatives() {
        
        maxAlternatives_ = 0;
        onChanged();
        return this;
      }

      private int audioChannelCount_ ;
      /**
       * <pre>
       * The number of channels in the input audio data.
       * ONLY set this for MULTI-CHANNEL recognition.
       * Valid values for LINEAR16 and FLAC are `1`-`8`.
       * Valid values for OGG_OPUS are '1'-'254'.
       * Valid value for MULAW, AMR, AMR_WB and SPEEX_WITH_HEADER_BYTE is only `1`.
       * If `0` or omitted, defaults to one channel (mono).
       * Note: We only recognize the first channel by default.
       * To perform independent recognition on each channel set
       * `enable_separate_recognition_per_channel` to 'true'.
       * </pre>
       *
       * <code>optional int32 audio_channel_count = 7;</code>
       */
      public int getAudioChannelCount() {
        return audioChannelCount_;
      }
      /**
       * <pre>
       * The number of channels in the input audio data.
       * ONLY set this for MULTI-CHANNEL recognition.
       * Valid values for LINEAR16 and FLAC are `1`-`8`.
       * Valid values for OGG_OPUS are '1'-'254'.
       * Valid value for MULAW, AMR, AMR_WB and SPEEX_WITH_HEADER_BYTE is only `1`.
       * If `0` or omitted, defaults to one channel (mono).
       * Note: We only recognize the first channel by default.
       * To perform independent recognition on each channel set
       * `enable_separate_recognition_per_channel` to 'true'.
       * </pre>
       *
       * <code>optional int32 audio_channel_count = 7;</code>
       */
      public Builder setAudioChannelCount(int value) {
        
        audioChannelCount_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The number of channels in the input audio data.
       * ONLY set this for MULTI-CHANNEL recognition.
       * Valid values for LINEAR16 and FLAC are `1`-`8`.
       * Valid values for OGG_OPUS are '1'-'254'.
       * Valid value for MULAW, AMR, AMR_WB and SPEEX_WITH_HEADER_BYTE is only `1`.
       * If `0` or omitted, defaults to one channel (mono).
       * Note: We only recognize the first channel by default.
       * To perform independent recognition on each channel set
       * `enable_separate_recognition_per_channel` to 'true'.
       * </pre>
       *
       * <code>optional int32 audio_channel_count = 7;</code>
       */
      public Builder clearAudioChannelCount() {
        
        audioChannelCount_ = 0;
        onChanged();
        return this;
      }

      private boolean enableWordTimeOffsets_ ;
      /**
       * <pre>
       * If `true`, the top result includes a list of words and
       * the start and end time offsets (timestamps) for those words. If
       * `false`, no word-level time offset information is returned. The default is
       * `false`.
       * </pre>
       *
       * <code>optional bool enable_word_time_offsets = 8;</code>
       */
      public boolean getEnableWordTimeOffsets() {
        return enableWordTimeOffsets_;
      }
      /**
       * <pre>
       * If `true`, the top result includes a list of words and
       * the start and end time offsets (timestamps) for those words. If
       * `false`, no word-level time offset information is returned. The default is
       * `false`.
       * </pre>
       *
       * <code>optional bool enable_word_time_offsets = 8;</code>
       */
      public Builder setEnableWordTimeOffsets(boolean value) {
        
        enableWordTimeOffsets_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * If `true`, the top result includes a list of words and
       * the start and end time offsets (timestamps) for those words. If
       * `false`, no word-level time offset information is returned. The default is
       * `false`.
       * </pre>
       *
       * <code>optional bool enable_word_time_offsets = 8;</code>
       */
      public Builder clearEnableWordTimeOffsets() {
        
        enableWordTimeOffsets_ = false;
        onChanged();
        return this;
      }

      private boolean enableAutomaticPunctuation_ ;
      /**
       * <pre>
       * If 'true', adds punctuation to recognition result hypotheses.
       * The default 'false' value does not add punctuation to result hypotheses.
       * </pre>
       *
       * <code>optional bool enable_automatic_punctuation = 11;</code>
       */
      public boolean getEnableAutomaticPunctuation() {
        return enableAutomaticPunctuation_;
      }
      /**
       * <pre>
       * If 'true', adds punctuation to recognition result hypotheses.
       * The default 'false' value does not add punctuation to result hypotheses.
       * </pre>
       *
       * <code>optional bool enable_automatic_punctuation = 11;</code>
       */
      public Builder setEnableAutomaticPunctuation(boolean value) {
        
        enableAutomaticPunctuation_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * If 'true', adds punctuation to recognition result hypotheses.
       * The default 'false' value does not add punctuation to result hypotheses.
       * </pre>
       *
       * <code>optional bool enable_automatic_punctuation = 11;</code>
       */
      public Builder clearEnableAutomaticPunctuation() {
        
        enableAutomaticPunctuation_ = false;
        onChanged();
        return this;
      }

      private boolean enableSeparateRecognitionPerChannel_ ;
      /**
       * <pre>
       * This needs to be set to `true` explicitly and `audio_channel_count` &gt; 1
       * to get each channel recognized separately. The recognition result will
       * contain a `channel_tag` field to state which channel that result belongs
       * to. If this is not true, we will only recognize the first channel. The
       * request is billed cumulatively for all channels recognized:
       * `audio_channel_count` multiplied by the length of the audio.
       * </pre>
       *
       * <code>optional bool enable_separate_recognition_per_channel = 12;</code>
       */
      public boolean getEnableSeparateRecognitionPerChannel() {
        return enableSeparateRecognitionPerChannel_;
      }
      /**
       * <pre>
       * This needs to be set to `true` explicitly and `audio_channel_count` &gt; 1
       * to get each channel recognized separately. The recognition result will
       * contain a `channel_tag` field to state which channel that result belongs
       * to. If this is not true, we will only recognize the first channel. The
       * request is billed cumulatively for all channels recognized:
       * `audio_channel_count` multiplied by the length of the audio.
       * </pre>
       *
       * <code>optional bool enable_separate_recognition_per_channel = 12;</code>
       */
      public Builder setEnableSeparateRecognitionPerChannel(boolean value) {
        
        enableSeparateRecognitionPerChannel_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * This needs to be set to `true` explicitly and `audio_channel_count` &gt; 1
       * to get each channel recognized separately. The recognition result will
       * contain a `channel_tag` field to state which channel that result belongs
       * to. If this is not true, we will only recognize the first channel. The
       * request is billed cumulatively for all channels recognized:
       * `audio_channel_count` multiplied by the length of the audio.
       * </pre>
       *
       * <code>optional bool enable_separate_recognition_per_channel = 12;</code>
       */
      public Builder clearEnableSeparateRecognitionPerChannel() {
        
        enableSeparateRecognitionPerChannel_ = false;
        onChanged();
        return this;
      }

      private java.lang.Object model_ = "";
      /**
       * <pre>
       * Which model to select for the given request. Valid choices: Jasper, Quartznet
       * </pre>
       *
       * <code>optional string model = 13;</code>
       */
      public java.lang.String getModel() {
        java.lang.Object ref = model_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          model_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * Which model to select for the given request. Valid choices: Jasper, Quartznet
       * </pre>
       *
       * <code>optional string model = 13;</code>
       */
      public com.google.protobuf.ByteString
          getModelBytes() {
        java.lang.Object ref = model_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          model_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * Which model to select for the given request. Valid choices: Jasper, Quartznet
       * </pre>
       *
       * <code>optional string model = 13;</code>
       */
      public Builder setModel(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  
        model_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Which model to select for the given request. Valid choices: Jasper, Quartznet
       * </pre>
       *
       * <code>optional string model = 13;</code>
       */
      public Builder clearModel() {
        
        model_ = getDefaultInstance().getModel();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Which model to select for the given request. Valid choices: Jasper, Quartznet
       * </pre>
       *
       * <code>optional string model = 13;</code>
       */
      public Builder setModelBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        
        model_ = value;
        onChanged();
        return this;
      }

      private boolean verbatimTranscripts_ ;
      /**
       * <pre>
       * The verbatim_transcripts flag enables or disable inverse text normalization.
       * 'true' returns exactly what was said, with no denormalization.
       * 'false' applies inverse text normalization, also this is the default
       * </pre>
       *
       * <code>optional bool verbatim_transcripts = 14;</code>
       */
      public boolean getVerbatimTranscripts() {
        return verbatimTranscripts_;
      }
      /**
       * <pre>
       * The verbatim_transcripts flag enables or disable inverse text normalization.
       * 'true' returns exactly what was said, with no denormalization.
       * 'false' applies inverse text normalization, also this is the default
       * </pre>
       *
       * <code>optional bool verbatim_transcripts = 14;</code>
       */
      public Builder setVerbatimTranscripts(boolean value) {
        
        verbatimTranscripts_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The verbatim_transcripts flag enables or disable inverse text normalization.
       * 'true' returns exactly what was said, with no denormalization.
       * 'false' applies inverse text normalization, also this is the default
       * </pre>
       *
       * <code>optional bool verbatim_transcripts = 14;</code>
       */
      public Builder clearVerbatimTranscripts() {
        
        verbatimTranscripts_ = false;
        onChanged();
        return this;
      }

      private com.google.protobuf.MapField<
          java.lang.String, java.lang.String> customConfiguration_;
      private com.google.protobuf.MapField<java.lang.String, java.lang.String>
      internalGetCustomConfiguration() {
        if (customConfiguration_ == null) {
          return com.google.protobuf.MapField.emptyMapField(
              CustomConfigurationDefaultEntryHolder.defaultEntry);
        }
        return customConfiguration_;
      }
      private com.google.protobuf.MapField<java.lang.String, java.lang.String>
      internalGetMutableCustomConfiguration() {
        onChanged();;
        if (customConfiguration_ == null) {
          customConfiguration_ = com.google.protobuf.MapField.newMapField(
              CustomConfigurationDefaultEntryHolder.defaultEntry);
        }
        if (!customConfiguration_.isMutable()) {
          customConfiguration_ = customConfiguration_.copy();
        }
        return customConfiguration_;
      }

      public int getCustomConfigurationCount() {
        return internalGetCustomConfiguration().getMap().size();
      }
      /**
       * <pre>
       * Custom fields for passing request-level
       * configuration options to plugins used in the
       * model pipeline.
       * </pre>
       *
       * <code>map&lt;string, string&gt; custom_configuration = 24;</code>
       */

      public boolean containsCustomConfiguration(
          java.lang.String key) {
        if (key == null) { throw new java.lang.NullPointerException(); }
        return internalGetCustomConfiguration().getMap().containsKey(key);
      }
      /**
       * Use {@link #getCustomConfigurationMap()} instead.
       */
      @java.lang.Deprecated
      public java.util.Map<java.lang.String, java.lang.String> getCustomConfiguration() {
        return getCustomConfigurationMap();
      }
      /**
       * <pre>
       * Custom fields for passing request-level
       * configuration options to plugins used in the
       * model pipeline.
       * </pre>
       *
       * <code>map&lt;string, string&gt; custom_configuration = 24;</code>
       */

      public java.util.Map<java.lang.String, java.lang.String> getCustomConfigurationMap() {
        return internalGetCustomConfiguration().getMap();
      }
      /**
       * <pre>
       * Custom fields for passing request-level
       * configuration options to plugins used in the
       * model pipeline.
       * </pre>
       *
       * <code>map&lt;string, string&gt; custom_configuration = 24;</code>
       */

      public java.lang.String getCustomConfigurationOrDefault(
          java.lang.String key,
          java.lang.String defaultValue) {
        if (key == null) { throw new java.lang.NullPointerException(); }
        java.util.Map<java.lang.String, java.lang.String> map =
            internalGetCustomConfiguration().getMap();
        return map.containsKey(key) ? map.get(key) : defaultValue;
      }
      /**
       * <pre>
       * Custom fields for passing request-level
       * configuration options to plugins used in the
       * model pipeline.
       * </pre>
       *
       * <code>map&lt;string, string&gt; custom_configuration = 24;</code>
       */

      public java.lang.String getCustomConfigurationOrThrow(
          java.lang.String key) {
        if (key == null) { throw new java.lang.NullPointerException(); }
        java.util.Map<java.lang.String, java.lang.String> map =
            internalGetCustomConfiguration().getMap();
        if (!map.containsKey(key)) {
          throw new java.lang.IllegalArgumentException();
        }
        return map.get(key);
      }

      public Builder clearCustomConfiguration() {
        getMutableCustomConfiguration().clear();
        return this;
      }
      /**
       * <pre>
       * Custom fields for passing request-level
       * configuration options to plugins used in the
       * model pipeline.
       * </pre>
       *
       * <code>map&lt;string, string&gt; custom_configuration = 24;</code>
       */

      public Builder removeCustomConfiguration(
          java.lang.String key) {
        if (key == null) { throw new java.lang.NullPointerException(); }
        getMutableCustomConfiguration().remove(key);
        return this;
      }
      /**
       * Use alternate mutation accessors instead.
       */
      @java.lang.Deprecated
      public java.util.Map<java.lang.String, java.lang.String>
      getMutableCustomConfiguration() {
        return internalGetMutableCustomConfiguration().getMutableMap();
      }
      /**
       * <pre>
       * Custom fields for passing request-level
       * configuration options to plugins used in the
       * model pipeline.
       * </pre>
       *
       * <code>map&lt;string, string&gt; custom_configuration = 24;</code>
       */
      public Builder putCustomConfiguration(
          java.lang.String key,
          java.lang.String value) {
        if (key == null) { throw new java.lang.NullPointerException(); }
        if (value == null) { throw new java.lang.NullPointerException(); }
        getMutableCustomConfiguration().put(key, value);
        return this;
      }
      /**
       * <pre>
       * Custom fields for passing request-level
       * configuration options to plugins used in the
       * model pipeline.
       * </pre>
       *
       * <code>map&lt;string, string&gt; custom_configuration = 24;</code>
       */

      public Builder putAllCustomConfiguration(
          java.util.Map<java.lang.String, java.lang.String> values) {
        getMutableCustomConfiguration().putAll(values);
        return this;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return this;
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return this;
      }


      // @@protoc_insertion_point(builder_scope:nvidia.riva.asr.RecognitionConfig)
    }

    // @@protoc_insertion_point(class_scope:nvidia.riva.asr.RecognitionConfig)
    private static final nvidia.riva.asr.RivaAsr.RecognitionConfig DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new nvidia.riva.asr.RivaAsr.RecognitionConfig();
    }

    public static nvidia.riva.asr.RivaAsr.RecognitionConfig getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<RecognitionConfig>
        PARSER = new com.google.protobuf.AbstractParser<RecognitionConfig>() {
      public RecognitionConfig parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new RecognitionConfig(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<RecognitionConfig> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<RecognitionConfig> getParserForType() {
      return PARSER;
    }

    public nvidia.riva.asr.RivaAsr.RecognitionConfig getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface StreamingRecognitionConfigOrBuilder extends
      // @@protoc_insertion_point(interface_extends:nvidia.riva.asr.StreamingRecognitionConfig)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * Provides information to the recognizer that specifies how to process the request
     * </pre>
     *
     * <code>optional .nvidia.riva.asr.RecognitionConfig config = 1;</code>
     */
    boolean hasConfig();
    /**
     * <pre>
     * Provides information to the recognizer that specifies how to process the request
     * </pre>
     *
     * <code>optional .nvidia.riva.asr.RecognitionConfig config = 1;</code>
     */
    nvidia.riva.asr.RivaAsr.RecognitionConfig getConfig();
    /**
     * <pre>
     * Provides information to the recognizer that specifies how to process the request
     * </pre>
     *
     * <code>optional .nvidia.riva.asr.RecognitionConfig config = 1;</code>
     */
    nvidia.riva.asr.RivaAsr.RecognitionConfigOrBuilder getConfigOrBuilder();

    /**
     * <pre>
     * If `true`, interim results (tentative hypotheses) may be
     * returned as they become available (these interim results are indicated with
     * the `is_final=false` flag).
     * If `false` or omitted, only `is_final=true` result(s) are returned.
     * </pre>
     *
     * <code>optional bool interim_results = 2;</code>
     */
    boolean getInterimResults();
  }
  /**
   * <pre>
   * Provides information to the recognizer that specifies how to process the request
   * </pre>
   *
   * Protobuf type {@code nvidia.riva.asr.StreamingRecognitionConfig}
   */
  public  static final class StreamingRecognitionConfig extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:nvidia.riva.asr.StreamingRecognitionConfig)
      StreamingRecognitionConfigOrBuilder {
    // Use StreamingRecognitionConfig.newBuilder() to construct.
    private StreamingRecognitionConfig(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private StreamingRecognitionConfig() {
      interimResults_ = false;
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return com.google.protobuf.UnknownFieldSet.getDefaultInstance();
    }
    private StreamingRecognitionConfig(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!input.skipField(tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              nvidia.riva.asr.RivaAsr.RecognitionConfig.Builder subBuilder = null;
              if (config_ != null) {
                subBuilder = config_.toBuilder();
              }
              config_ = input.readMessage(nvidia.riva.asr.RivaAsr.RecognitionConfig.parser(), extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(config_);
                config_ = subBuilder.buildPartial();
              }

              break;
            }
            case 16: {

              interimResults_ = input.readBool();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return nvidia.riva.asr.RivaAsr.internal_static_nvidia_riva_asr_StreamingRecognitionConfig_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return nvidia.riva.asr.RivaAsr.internal_static_nvidia_riva_asr_StreamingRecognitionConfig_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              nvidia.riva.asr.RivaAsr.StreamingRecognitionConfig.class, nvidia.riva.asr.RivaAsr.StreamingRecognitionConfig.Builder.class);
    }

    public static final int CONFIG_FIELD_NUMBER = 1;
    private nvidia.riva.asr.RivaAsr.RecognitionConfig config_;
    /**
     * <pre>
     * Provides information to the recognizer that specifies how to process the request
     * </pre>
     *
     * <code>optional .nvidia.riva.asr.RecognitionConfig config = 1;</code>
     */
    public boolean hasConfig() {
      return config_ != null;
    }
    /**
     * <pre>
     * Provides information to the recognizer that specifies how to process the request
     * </pre>
     *
     * <code>optional .nvidia.riva.asr.RecognitionConfig config = 1;</code>
     */
    public nvidia.riva.asr.RivaAsr.RecognitionConfig getConfig() {
      return config_ == null ? nvidia.riva.asr.RivaAsr.RecognitionConfig.getDefaultInstance() : config_;
    }
    /**
     * <pre>
     * Provides information to the recognizer that specifies how to process the request
     * </pre>
     *
     * <code>optional .nvidia.riva.asr.RecognitionConfig config = 1;</code>
     */
    public nvidia.riva.asr.RivaAsr.RecognitionConfigOrBuilder getConfigOrBuilder() {
      return getConfig();
    }

    public static final int INTERIM_RESULTS_FIELD_NUMBER = 2;
    private boolean interimResults_;
    /**
     * <pre>
     * If `true`, interim results (tentative hypotheses) may be
     * returned as they become available (these interim results are indicated with
     * the `is_final=false` flag).
     * If `false` or omitted, only `is_final=true` result(s) are returned.
     * </pre>
     *
     * <code>optional bool interim_results = 2;</code>
     */
    public boolean getInterimResults() {
      return interimResults_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (config_ != null) {
        output.writeMessage(1, getConfig());
      }
      if (interimResults_ != false) {
        output.writeBool(2, interimResults_);
      }
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (config_ != null) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getConfig());
      }
      if (interimResults_ != false) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(2, interimResults_);
      }
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof nvidia.riva.asr.RivaAsr.StreamingRecognitionConfig)) {
        return super.equals(obj);
      }
      nvidia.riva.asr.RivaAsr.StreamingRecognitionConfig other = (nvidia.riva.asr.RivaAsr.StreamingRecognitionConfig) obj;

      boolean result = true;
      result = result && (hasConfig() == other.hasConfig());
      if (hasConfig()) {
        result = result && getConfig()
            .equals(other.getConfig());
      }
      result = result && (getInterimResults()
          == other.getInterimResults());
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (hasConfig()) {
        hash = (37 * hash) + CONFIG_FIELD_NUMBER;
        hash = (53 * hash) + getConfig().hashCode();
      }
      hash = (37 * hash) + INTERIM_RESULTS_FIELD_NUMBER;
      hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
          getInterimResults());
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static nvidia.riva.asr.RivaAsr.StreamingRecognitionConfig parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static nvidia.riva.asr.RivaAsr.StreamingRecognitionConfig parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static nvidia.riva.asr.RivaAsr.StreamingRecognitionConfig parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static nvidia.riva.asr.RivaAsr.StreamingRecognitionConfig parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static nvidia.riva.asr.RivaAsr.StreamingRecognitionConfig parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static nvidia.riva.asr.RivaAsr.StreamingRecognitionConfig parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static nvidia.riva.asr.RivaAsr.StreamingRecognitionConfig parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static nvidia.riva.asr.RivaAsr.StreamingRecognitionConfig parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static nvidia.riva.asr.RivaAsr.StreamingRecognitionConfig parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static nvidia.riva.asr.RivaAsr.StreamingRecognitionConfig parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(nvidia.riva.asr.RivaAsr.StreamingRecognitionConfig prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     * Provides information to the recognizer that specifies how to process the request
     * </pre>
     *
     * Protobuf type {@code nvidia.riva.asr.StreamingRecognitionConfig}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:nvidia.riva.asr.StreamingRecognitionConfig)
        nvidia.riva.asr.RivaAsr.StreamingRecognitionConfigOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return nvidia.riva.asr.RivaAsr.internal_static_nvidia_riva_asr_StreamingRecognitionConfig_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return nvidia.riva.asr.RivaAsr.internal_static_nvidia_riva_asr_StreamingRecognitionConfig_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                nvidia.riva.asr.RivaAsr.StreamingRecognitionConfig.class, nvidia.riva.asr.RivaAsr.StreamingRecognitionConfig.Builder.class);
      }

      // Construct using nvidia.riva.asr.RivaAsr.StreamingRecognitionConfig.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      public Builder clear() {
        super.clear();
        if (configBuilder_ == null) {
          config_ = null;
        } else {
          config_ = null;
          configBuilder_ = null;
        }
        interimResults_ = false;

        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return nvidia.riva.asr.RivaAsr.internal_static_nvidia_riva_asr_StreamingRecognitionConfig_descriptor;
      }

      public nvidia.riva.asr.RivaAsr.StreamingRecognitionConfig getDefaultInstanceForType() {
        return nvidia.riva.asr.RivaAsr.StreamingRecognitionConfig.getDefaultInstance();
      }

      public nvidia.riva.asr.RivaAsr.StreamingRecognitionConfig build() {
        nvidia.riva.asr.RivaAsr.StreamingRecognitionConfig result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public nvidia.riva.asr.RivaAsr.StreamingRecognitionConfig buildPartial() {
        nvidia.riva.asr.RivaAsr.StreamingRecognitionConfig result = new nvidia.riva.asr.RivaAsr.StreamingRecognitionConfig(this);
        if (configBuilder_ == null) {
          result.config_ = config_;
        } else {
          result.config_ = configBuilder_.build();
        }
        result.interimResults_ = interimResults_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof nvidia.riva.asr.RivaAsr.StreamingRecognitionConfig) {
          return mergeFrom((nvidia.riva.asr.RivaAsr.StreamingRecognitionConfig)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(nvidia.riva.asr.RivaAsr.StreamingRecognitionConfig other) {
        if (other == nvidia.riva.asr.RivaAsr.StreamingRecognitionConfig.getDefaultInstance()) return this;
        if (other.hasConfig()) {
          mergeConfig(other.getConfig());
        }
        if (other.getInterimResults() != false) {
          setInterimResults(other.getInterimResults());
        }
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        nvidia.riva.asr.RivaAsr.StreamingRecognitionConfig parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (nvidia.riva.asr.RivaAsr.StreamingRecognitionConfig) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }

      private nvidia.riva.asr.RivaAsr.RecognitionConfig config_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          nvidia.riva.asr.RivaAsr.RecognitionConfig, nvidia.riva.asr.RivaAsr.RecognitionConfig.Builder, nvidia.riva.asr.RivaAsr.RecognitionConfigOrBuilder> configBuilder_;
      /**
       * <pre>
       * Provides information to the recognizer that specifies how to process the request
       * </pre>
       *
       * <code>optional .nvidia.riva.asr.RecognitionConfig config = 1;</code>
       */
      public boolean hasConfig() {
        return configBuilder_ != null || config_ != null;
      }
      /**
       * <pre>
       * Provides information to the recognizer that specifies how to process the request
       * </pre>
       *
       * <code>optional .nvidia.riva.asr.RecognitionConfig config = 1;</code>
       */
      public nvidia.riva.asr.RivaAsr.RecognitionConfig getConfig() {
        if (configBuilder_ == null) {
          return config_ == null ? nvidia.riva.asr.RivaAsr.RecognitionConfig.getDefaultInstance() : config_;
        } else {
          return configBuilder_.getMessage();
        }
      }
      /**
       * <pre>
       * Provides information to the recognizer that specifies how to process the request
       * </pre>
       *
       * <code>optional .nvidia.riva.asr.RecognitionConfig config = 1;</code>
       */
      public Builder setConfig(nvidia.riva.asr.RivaAsr.RecognitionConfig value) {
        if (configBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          config_ = value;
          onChanged();
        } else {
          configBuilder_.setMessage(value);
        }

        return this;
      }
      /**
       * <pre>
       * Provides information to the recognizer that specifies how to process the request
       * </pre>
       *
       * <code>optional .nvidia.riva.asr.RecognitionConfig config = 1;</code>
       */
      public Builder setConfig(
          nvidia.riva.asr.RivaAsr.RecognitionConfig.Builder builderForValue) {
        if (configBuilder_ == null) {
          config_ = builderForValue.build();
          onChanged();
        } else {
          configBuilder_.setMessage(builderForValue.build());
        }

        return this;
      }
      /**
       * <pre>
       * Provides information to the recognizer that specifies how to process the request
       * </pre>
       *
       * <code>optional .nvidia.riva.asr.RecognitionConfig config = 1;</code>
       */
      public Builder mergeConfig(nvidia.riva.asr.RivaAsr.RecognitionConfig value) {
        if (configBuilder_ == null) {
          if (config_ != null) {
            config_ =
              nvidia.riva.asr.RivaAsr.RecognitionConfig.newBuilder(config_).mergeFrom(value).buildPartial();
          } else {
            config_ = value;
          }
          onChanged();
        } else {
          configBuilder_.mergeFrom(value);
        }

        return this;
      }
      /**
       * <pre>
       * Provides information to the recognizer that specifies how to process the request
       * </pre>
       *
       * <code>optional .nvidia.riva.asr.RecognitionConfig config = 1;</code>
       */
      public Builder clearConfig() {
        if (configBuilder_ == null) {
          config_ = null;
          onChanged();
        } else {
          config_ = null;
          configBuilder_ = null;
        }

        return this;
      }
      /**
       * <pre>
       * Provides information to the recognizer that specifies how to process the request
       * </pre>
       *
       * <code>optional .nvidia.riva.asr.RecognitionConfig config = 1;</code>
       */
      public nvidia.riva.asr.RivaAsr.RecognitionConfig.Builder getConfigBuilder() {
        
        onChanged();
        return getConfigFieldBuilder().getBuilder();
      }
      /**
       * <pre>
       * Provides information to the recognizer that specifies how to process the request
       * </pre>
       *
       * <code>optional .nvidia.riva.asr.RecognitionConfig config = 1;</code>
       */
      public nvidia.riva.asr.RivaAsr.RecognitionConfigOrBuilder getConfigOrBuilder() {
        if (configBuilder_ != null) {
          return configBuilder_.getMessageOrBuilder();
        } else {
          return config_ == null ?
              nvidia.riva.asr.RivaAsr.RecognitionConfig.getDefaultInstance() : config_;
        }
      }
      /**
       * <pre>
       * Provides information to the recognizer that specifies how to process the request
       * </pre>
       *
       * <code>optional .nvidia.riva.asr.RecognitionConfig config = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          nvidia.riva.asr.RivaAsr.RecognitionConfig, nvidia.riva.asr.RivaAsr.RecognitionConfig.Builder, nvidia.riva.asr.RivaAsr.RecognitionConfigOrBuilder> 
          getConfigFieldBuilder() {
        if (configBuilder_ == null) {
          configBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              nvidia.riva.asr.RivaAsr.RecognitionConfig, nvidia.riva.asr.RivaAsr.RecognitionConfig.Builder, nvidia.riva.asr.RivaAsr.RecognitionConfigOrBuilder>(
                  getConfig(),
                  getParentForChildren(),
                  isClean());
          config_ = null;
        }
        return configBuilder_;
      }

      private boolean interimResults_ ;
      /**
       * <pre>
       * If `true`, interim results (tentative hypotheses) may be
       * returned as they become available (these interim results are indicated with
       * the `is_final=false` flag).
       * If `false` or omitted, only `is_final=true` result(s) are returned.
       * </pre>
       *
       * <code>optional bool interim_results = 2;</code>
       */
      public boolean getInterimResults() {
        return interimResults_;
      }
      /**
       * <pre>
       * If `true`, interim results (tentative hypotheses) may be
       * returned as they become available (these interim results are indicated with
       * the `is_final=false` flag).
       * If `false` or omitted, only `is_final=true` result(s) are returned.
       * </pre>
       *
       * <code>optional bool interim_results = 2;</code>
       */
      public Builder setInterimResults(boolean value) {
        
        interimResults_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * If `true`, interim results (tentative hypotheses) may be
       * returned as they become available (these interim results are indicated with
       * the `is_final=false` flag).
       * If `false` or omitted, only `is_final=true` result(s) are returned.
       * </pre>
       *
       * <code>optional bool interim_results = 2;</code>
       */
      public Builder clearInterimResults() {
        
        interimResults_ = false;
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return this;
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return this;
      }


      // @@protoc_insertion_point(builder_scope:nvidia.riva.asr.StreamingRecognitionConfig)
    }

    // @@protoc_insertion_point(class_scope:nvidia.riva.asr.StreamingRecognitionConfig)
    private static final nvidia.riva.asr.RivaAsr.StreamingRecognitionConfig DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new nvidia.riva.asr.RivaAsr.StreamingRecognitionConfig();
    }

    public static nvidia.riva.asr.RivaAsr.StreamingRecognitionConfig getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<StreamingRecognitionConfig>
        PARSER = new com.google.protobuf.AbstractParser<StreamingRecognitionConfig>() {
      public StreamingRecognitionConfig parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new StreamingRecognitionConfig(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<StreamingRecognitionConfig> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<StreamingRecognitionConfig> getParserForType() {
      return PARSER;
    }

    public nvidia.riva.asr.RivaAsr.StreamingRecognitionConfig getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface RecognizeResponseOrBuilder extends
      // @@protoc_insertion_point(interface_extends:nvidia.riva.asr.RecognizeResponse)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * Sequential list of transcription results corresponding to
     * sequential portions of audio. Currently only returns one transcript.
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.SpeechRecognitionResult results = 1;</code>
     */
    java.util.List<nvidia.riva.asr.RivaAsr.SpeechRecognitionResult> 
        getResultsList();
    /**
     * <pre>
     * Sequential list of transcription results corresponding to
     * sequential portions of audio. Currently only returns one transcript.
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.SpeechRecognitionResult results = 1;</code>
     */
    nvidia.riva.asr.RivaAsr.SpeechRecognitionResult getResults(int index);
    /**
     * <pre>
     * Sequential list of transcription results corresponding to
     * sequential portions of audio. Currently only returns one transcript.
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.SpeechRecognitionResult results = 1;</code>
     */
    int getResultsCount();
    /**
     * <pre>
     * Sequential list of transcription results corresponding to
     * sequential portions of audio. Currently only returns one transcript.
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.SpeechRecognitionResult results = 1;</code>
     */
    java.util.List<? extends nvidia.riva.asr.RivaAsr.SpeechRecognitionResultOrBuilder> 
        getResultsOrBuilderList();
    /**
     * <pre>
     * Sequential list of transcription results corresponding to
     * sequential portions of audio. Currently only returns one transcript.
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.SpeechRecognitionResult results = 1;</code>
     */
    nvidia.riva.asr.RivaAsr.SpeechRecognitionResultOrBuilder getResultsOrBuilder(
        int index);
  }
  /**
   * <pre>
   * The only message returned to the client by the `Recognize` method. It
   * contains the result as zero or more sequential `SpeechRecognitionResult`
   * messages.
   * </pre>
   *
   * Protobuf type {@code nvidia.riva.asr.RecognizeResponse}
   */
  public  static final class RecognizeResponse extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:nvidia.riva.asr.RecognizeResponse)
      RecognizeResponseOrBuilder {
    // Use RecognizeResponse.newBuilder() to construct.
    private RecognizeResponse(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private RecognizeResponse() {
      results_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return com.google.protobuf.UnknownFieldSet.getDefaultInstance();
    }
    private RecognizeResponse(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!input.skipField(tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              if (!((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
                results_ = new java.util.ArrayList<nvidia.riva.asr.RivaAsr.SpeechRecognitionResult>();
                mutable_bitField0_ |= 0x00000001;
              }
              results_.add(
                  input.readMessage(nvidia.riva.asr.RivaAsr.SpeechRecognitionResult.parser(), extensionRegistry));
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
          results_ = java.util.Collections.unmodifiableList(results_);
        }
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return nvidia.riva.asr.RivaAsr.internal_static_nvidia_riva_asr_RecognizeResponse_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return nvidia.riva.asr.RivaAsr.internal_static_nvidia_riva_asr_RecognizeResponse_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              nvidia.riva.asr.RivaAsr.RecognizeResponse.class, nvidia.riva.asr.RivaAsr.RecognizeResponse.Builder.class);
    }

    public static final int RESULTS_FIELD_NUMBER = 1;
    private java.util.List<nvidia.riva.asr.RivaAsr.SpeechRecognitionResult> results_;
    /**
     * <pre>
     * Sequential list of transcription results corresponding to
     * sequential portions of audio. Currently only returns one transcript.
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.SpeechRecognitionResult results = 1;</code>
     */
    public java.util.List<nvidia.riva.asr.RivaAsr.SpeechRecognitionResult> getResultsList() {
      return results_;
    }
    /**
     * <pre>
     * Sequential list of transcription results corresponding to
     * sequential portions of audio. Currently only returns one transcript.
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.SpeechRecognitionResult results = 1;</code>
     */
    public java.util.List<? extends nvidia.riva.asr.RivaAsr.SpeechRecognitionResultOrBuilder> 
        getResultsOrBuilderList() {
      return results_;
    }
    /**
     * <pre>
     * Sequential list of transcription results corresponding to
     * sequential portions of audio. Currently only returns one transcript.
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.SpeechRecognitionResult results = 1;</code>
     */
    public int getResultsCount() {
      return results_.size();
    }
    /**
     * <pre>
     * Sequential list of transcription results corresponding to
     * sequential portions of audio. Currently only returns one transcript.
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.SpeechRecognitionResult results = 1;</code>
     */
    public nvidia.riva.asr.RivaAsr.SpeechRecognitionResult getResults(int index) {
      return results_.get(index);
    }
    /**
     * <pre>
     * Sequential list of transcription results corresponding to
     * sequential portions of audio. Currently only returns one transcript.
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.SpeechRecognitionResult results = 1;</code>
     */
    public nvidia.riva.asr.RivaAsr.SpeechRecognitionResultOrBuilder getResultsOrBuilder(
        int index) {
      return results_.get(index);
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < results_.size(); i++) {
        output.writeMessage(1, results_.get(i));
      }
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < results_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, results_.get(i));
      }
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof nvidia.riva.asr.RivaAsr.RecognizeResponse)) {
        return super.equals(obj);
      }
      nvidia.riva.asr.RivaAsr.RecognizeResponse other = (nvidia.riva.asr.RivaAsr.RecognizeResponse) obj;

      boolean result = true;
      result = result && getResultsList()
          .equals(other.getResultsList());
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (getResultsCount() > 0) {
        hash = (37 * hash) + RESULTS_FIELD_NUMBER;
        hash = (53 * hash) + getResultsList().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static nvidia.riva.asr.RivaAsr.RecognizeResponse parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static nvidia.riva.asr.RivaAsr.RecognizeResponse parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static nvidia.riva.asr.RivaAsr.RecognizeResponse parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static nvidia.riva.asr.RivaAsr.RecognizeResponse parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static nvidia.riva.asr.RivaAsr.RecognizeResponse parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static nvidia.riva.asr.RivaAsr.RecognizeResponse parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static nvidia.riva.asr.RivaAsr.RecognizeResponse parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static nvidia.riva.asr.RivaAsr.RecognizeResponse parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static nvidia.riva.asr.RivaAsr.RecognizeResponse parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static nvidia.riva.asr.RivaAsr.RecognizeResponse parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(nvidia.riva.asr.RivaAsr.RecognizeResponse prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     * The only message returned to the client by the `Recognize` method. It
     * contains the result as zero or more sequential `SpeechRecognitionResult`
     * messages.
     * </pre>
     *
     * Protobuf type {@code nvidia.riva.asr.RecognizeResponse}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:nvidia.riva.asr.RecognizeResponse)
        nvidia.riva.asr.RivaAsr.RecognizeResponseOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return nvidia.riva.asr.RivaAsr.internal_static_nvidia_riva_asr_RecognizeResponse_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return nvidia.riva.asr.RivaAsr.internal_static_nvidia_riva_asr_RecognizeResponse_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                nvidia.riva.asr.RivaAsr.RecognizeResponse.class, nvidia.riva.asr.RivaAsr.RecognizeResponse.Builder.class);
      }

      // Construct using nvidia.riva.asr.RivaAsr.RecognizeResponse.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getResultsFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (resultsBuilder_ == null) {
          results_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
        } else {
          resultsBuilder_.clear();
        }
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return nvidia.riva.asr.RivaAsr.internal_static_nvidia_riva_asr_RecognizeResponse_descriptor;
      }

      public nvidia.riva.asr.RivaAsr.RecognizeResponse getDefaultInstanceForType() {
        return nvidia.riva.asr.RivaAsr.RecognizeResponse.getDefaultInstance();
      }

      public nvidia.riva.asr.RivaAsr.RecognizeResponse build() {
        nvidia.riva.asr.RivaAsr.RecognizeResponse result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public nvidia.riva.asr.RivaAsr.RecognizeResponse buildPartial() {
        nvidia.riva.asr.RivaAsr.RecognizeResponse result = new nvidia.riva.asr.RivaAsr.RecognizeResponse(this);
        int from_bitField0_ = bitField0_;
        if (resultsBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001)) {
            results_ = java.util.Collections.unmodifiableList(results_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.results_ = results_;
        } else {
          result.results_ = resultsBuilder_.build();
        }
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof nvidia.riva.asr.RivaAsr.RecognizeResponse) {
          return mergeFrom((nvidia.riva.asr.RivaAsr.RecognizeResponse)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(nvidia.riva.asr.RivaAsr.RecognizeResponse other) {
        if (other == nvidia.riva.asr.RivaAsr.RecognizeResponse.getDefaultInstance()) return this;
        if (resultsBuilder_ == null) {
          if (!other.results_.isEmpty()) {
            if (results_.isEmpty()) {
              results_ = other.results_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureResultsIsMutable();
              results_.addAll(other.results_);
            }
            onChanged();
          }
        } else {
          if (!other.results_.isEmpty()) {
            if (resultsBuilder_.isEmpty()) {
              resultsBuilder_.dispose();
              resultsBuilder_ = null;
              results_ = other.results_;
              bitField0_ = (bitField0_ & ~0x00000001);
              resultsBuilder_ = 
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getResultsFieldBuilder() : null;
            } else {
              resultsBuilder_.addAllMessages(other.results_);
            }
          }
        }
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        nvidia.riva.asr.RivaAsr.RecognizeResponse parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (nvidia.riva.asr.RivaAsr.RecognizeResponse) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.util.List<nvidia.riva.asr.RivaAsr.SpeechRecognitionResult> results_ =
        java.util.Collections.emptyList();
      private void ensureResultsIsMutable() {
        if (!((bitField0_ & 0x00000001) == 0x00000001)) {
          results_ = new java.util.ArrayList<nvidia.riva.asr.RivaAsr.SpeechRecognitionResult>(results_);
          bitField0_ |= 0x00000001;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          nvidia.riva.asr.RivaAsr.SpeechRecognitionResult, nvidia.riva.asr.RivaAsr.SpeechRecognitionResult.Builder, nvidia.riva.asr.RivaAsr.SpeechRecognitionResultOrBuilder> resultsBuilder_;

      /**
       * <pre>
       * Sequential list of transcription results corresponding to
       * sequential portions of audio. Currently only returns one transcript.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionResult results = 1;</code>
       */
      public java.util.List<nvidia.riva.asr.RivaAsr.SpeechRecognitionResult> getResultsList() {
        if (resultsBuilder_ == null) {
          return java.util.Collections.unmodifiableList(results_);
        } else {
          return resultsBuilder_.getMessageList();
        }
      }
      /**
       * <pre>
       * Sequential list of transcription results corresponding to
       * sequential portions of audio. Currently only returns one transcript.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionResult results = 1;</code>
       */
      public int getResultsCount() {
        if (resultsBuilder_ == null) {
          return results_.size();
        } else {
          return resultsBuilder_.getCount();
        }
      }
      /**
       * <pre>
       * Sequential list of transcription results corresponding to
       * sequential portions of audio. Currently only returns one transcript.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionResult results = 1;</code>
       */
      public nvidia.riva.asr.RivaAsr.SpeechRecognitionResult getResults(int index) {
        if (resultsBuilder_ == null) {
          return results_.get(index);
        } else {
          return resultsBuilder_.getMessage(index);
        }
      }
      /**
       * <pre>
       * Sequential list of transcription results corresponding to
       * sequential portions of audio. Currently only returns one transcript.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionResult results = 1;</code>
       */
      public Builder setResults(
          int index, nvidia.riva.asr.RivaAsr.SpeechRecognitionResult value) {
        if (resultsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureResultsIsMutable();
          results_.set(index, value);
          onChanged();
        } else {
          resultsBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <pre>
       * Sequential list of transcription results corresponding to
       * sequential portions of audio. Currently only returns one transcript.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionResult results = 1;</code>
       */
      public Builder setResults(
          int index, nvidia.riva.asr.RivaAsr.SpeechRecognitionResult.Builder builderForValue) {
        if (resultsBuilder_ == null) {
          ensureResultsIsMutable();
          results_.set(index, builderForValue.build());
          onChanged();
        } else {
          resultsBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       * Sequential list of transcription results corresponding to
       * sequential portions of audio. Currently only returns one transcript.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionResult results = 1;</code>
       */
      public Builder addResults(nvidia.riva.asr.RivaAsr.SpeechRecognitionResult value) {
        if (resultsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureResultsIsMutable();
          results_.add(value);
          onChanged();
        } else {
          resultsBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <pre>
       * Sequential list of transcription results corresponding to
       * sequential portions of audio. Currently only returns one transcript.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionResult results = 1;</code>
       */
      public Builder addResults(
          int index, nvidia.riva.asr.RivaAsr.SpeechRecognitionResult value) {
        if (resultsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureResultsIsMutable();
          results_.add(index, value);
          onChanged();
        } else {
          resultsBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <pre>
       * Sequential list of transcription results corresponding to
       * sequential portions of audio. Currently only returns one transcript.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionResult results = 1;</code>
       */
      public Builder addResults(
          nvidia.riva.asr.RivaAsr.SpeechRecognitionResult.Builder builderForValue) {
        if (resultsBuilder_ == null) {
          ensureResultsIsMutable();
          results_.add(builderForValue.build());
          onChanged();
        } else {
          resultsBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       * Sequential list of transcription results corresponding to
       * sequential portions of audio. Currently only returns one transcript.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionResult results = 1;</code>
       */
      public Builder addResults(
          int index, nvidia.riva.asr.RivaAsr.SpeechRecognitionResult.Builder builderForValue) {
        if (resultsBuilder_ == null) {
          ensureResultsIsMutable();
          results_.add(index, builderForValue.build());
          onChanged();
        } else {
          resultsBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       * Sequential list of transcription results corresponding to
       * sequential portions of audio. Currently only returns one transcript.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionResult results = 1;</code>
       */
      public Builder addAllResults(
          java.lang.Iterable<? extends nvidia.riva.asr.RivaAsr.SpeechRecognitionResult> values) {
        if (resultsBuilder_ == null) {
          ensureResultsIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, results_);
          onChanged();
        } else {
          resultsBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <pre>
       * Sequential list of transcription results corresponding to
       * sequential portions of audio. Currently only returns one transcript.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionResult results = 1;</code>
       */
      public Builder clearResults() {
        if (resultsBuilder_ == null) {
          results_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          resultsBuilder_.clear();
        }
        return this;
      }
      /**
       * <pre>
       * Sequential list of transcription results corresponding to
       * sequential portions of audio. Currently only returns one transcript.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionResult results = 1;</code>
       */
      public Builder removeResults(int index) {
        if (resultsBuilder_ == null) {
          ensureResultsIsMutable();
          results_.remove(index);
          onChanged();
        } else {
          resultsBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <pre>
       * Sequential list of transcription results corresponding to
       * sequential portions of audio. Currently only returns one transcript.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionResult results = 1;</code>
       */
      public nvidia.riva.asr.RivaAsr.SpeechRecognitionResult.Builder getResultsBuilder(
          int index) {
        return getResultsFieldBuilder().getBuilder(index);
      }
      /**
       * <pre>
       * Sequential list of transcription results corresponding to
       * sequential portions of audio. Currently only returns one transcript.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionResult results = 1;</code>
       */
      public nvidia.riva.asr.RivaAsr.SpeechRecognitionResultOrBuilder getResultsOrBuilder(
          int index) {
        if (resultsBuilder_ == null) {
          return results_.get(index);  } else {
          return resultsBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <pre>
       * Sequential list of transcription results corresponding to
       * sequential portions of audio. Currently only returns one transcript.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionResult results = 1;</code>
       */
      public java.util.List<? extends nvidia.riva.asr.RivaAsr.SpeechRecognitionResultOrBuilder> 
           getResultsOrBuilderList() {
        if (resultsBuilder_ != null) {
          return resultsBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(results_);
        }
      }
      /**
       * <pre>
       * Sequential list of transcription results corresponding to
       * sequential portions of audio. Currently only returns one transcript.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionResult results = 1;</code>
       */
      public nvidia.riva.asr.RivaAsr.SpeechRecognitionResult.Builder addResultsBuilder() {
        return getResultsFieldBuilder().addBuilder(
            nvidia.riva.asr.RivaAsr.SpeechRecognitionResult.getDefaultInstance());
      }
      /**
       * <pre>
       * Sequential list of transcription results corresponding to
       * sequential portions of audio. Currently only returns one transcript.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionResult results = 1;</code>
       */
      public nvidia.riva.asr.RivaAsr.SpeechRecognitionResult.Builder addResultsBuilder(
          int index) {
        return getResultsFieldBuilder().addBuilder(
            index, nvidia.riva.asr.RivaAsr.SpeechRecognitionResult.getDefaultInstance());
      }
      /**
       * <pre>
       * Sequential list of transcription results corresponding to
       * sequential portions of audio. Currently only returns one transcript.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionResult results = 1;</code>
       */
      public java.util.List<nvidia.riva.asr.RivaAsr.SpeechRecognitionResult.Builder> 
           getResultsBuilderList() {
        return getResultsFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          nvidia.riva.asr.RivaAsr.SpeechRecognitionResult, nvidia.riva.asr.RivaAsr.SpeechRecognitionResult.Builder, nvidia.riva.asr.RivaAsr.SpeechRecognitionResultOrBuilder> 
          getResultsFieldBuilder() {
        if (resultsBuilder_ == null) {
          resultsBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              nvidia.riva.asr.RivaAsr.SpeechRecognitionResult, nvidia.riva.asr.RivaAsr.SpeechRecognitionResult.Builder, nvidia.riva.asr.RivaAsr.SpeechRecognitionResultOrBuilder>(
                  results_,
                  ((bitField0_ & 0x00000001) == 0x00000001),
                  getParentForChildren(),
                  isClean());
          results_ = null;
        }
        return resultsBuilder_;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return this;
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return this;
      }


      // @@protoc_insertion_point(builder_scope:nvidia.riva.asr.RecognizeResponse)
    }

    // @@protoc_insertion_point(class_scope:nvidia.riva.asr.RecognizeResponse)
    private static final nvidia.riva.asr.RivaAsr.RecognizeResponse DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new nvidia.riva.asr.RivaAsr.RecognizeResponse();
    }

    public static nvidia.riva.asr.RivaAsr.RecognizeResponse getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<RecognizeResponse>
        PARSER = new com.google.protobuf.AbstractParser<RecognizeResponse>() {
      public RecognizeResponse parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new RecognizeResponse(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<RecognizeResponse> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<RecognizeResponse> getParserForType() {
      return PARSER;
    }

    public nvidia.riva.asr.RivaAsr.RecognizeResponse getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface SpeechRecognitionResultOrBuilder extends
      // @@protoc_insertion_point(interface_extends:nvidia.riva.asr.SpeechRecognitionResult)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * May contain one or more recognition hypotheses (up to the
     * maximum specified in `max_alternatives`).
     * These alternatives are ordered in terms of accuracy, with the top (first)
     * alternative being the most probable, as ranked by the recognizer.
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
     */
    java.util.List<nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative> 
        getAlternativesList();
    /**
     * <pre>
     * May contain one or more recognition hypotheses (up to the
     * maximum specified in `max_alternatives`).
     * These alternatives are ordered in terms of accuracy, with the top (first)
     * alternative being the most probable, as ranked by the recognizer.
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
     */
    nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative getAlternatives(int index);
    /**
     * <pre>
     * May contain one or more recognition hypotheses (up to the
     * maximum specified in `max_alternatives`).
     * These alternatives are ordered in terms of accuracy, with the top (first)
     * alternative being the most probable, as ranked by the recognizer.
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
     */
    int getAlternativesCount();
    /**
     * <pre>
     * May contain one or more recognition hypotheses (up to the
     * maximum specified in `max_alternatives`).
     * These alternatives are ordered in terms of accuracy, with the top (first)
     * alternative being the most probable, as ranked by the recognizer.
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
     */
    java.util.List<? extends nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternativeOrBuilder> 
        getAlternativesOrBuilderList();
    /**
     * <pre>
     * May contain one or more recognition hypotheses (up to the
     * maximum specified in `max_alternatives`).
     * These alternatives are ordered in terms of accuracy, with the top (first)
     * alternative being the most probable, as ranked by the recognizer.
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
     */
    nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternativeOrBuilder getAlternativesOrBuilder(
        int index);

    /**
     * <pre>
     * For multi-channel audio, this is the channel number corresponding to the
     * recognized result for the audio from that channel.
     * For audio_channel_count = N, its output values can range from '1' to 'N'.
     * </pre>
     *
     * <code>optional int32 channel_tag = 2;</code>
     */
    int getChannelTag();

    /**
     * <pre>
     * Length of audio processed so far in seconds
     * </pre>
     *
     * <code>optional float audio_processed = 3;</code>
     */
    float getAudioProcessed();
  }
  /**
   * <pre>
   * A speech recognition result corresponding to the latest transcript
   * </pre>
   *
   * Protobuf type {@code nvidia.riva.asr.SpeechRecognitionResult}
   */
  public  static final class SpeechRecognitionResult extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:nvidia.riva.asr.SpeechRecognitionResult)
      SpeechRecognitionResultOrBuilder {
    // Use SpeechRecognitionResult.newBuilder() to construct.
    private SpeechRecognitionResult(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private SpeechRecognitionResult() {
      alternatives_ = java.util.Collections.emptyList();
      channelTag_ = 0;
      audioProcessed_ = 0F;
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return com.google.protobuf.UnknownFieldSet.getDefaultInstance();
    }
    private SpeechRecognitionResult(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!input.skipField(tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              if (!((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
                alternatives_ = new java.util.ArrayList<nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative>();
                mutable_bitField0_ |= 0x00000001;
              }
              alternatives_.add(
                  input.readMessage(nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative.parser(), extensionRegistry));
              break;
            }
            case 16: {

              channelTag_ = input.readInt32();
              break;
            }
            case 29: {

              audioProcessed_ = input.readFloat();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
          alternatives_ = java.util.Collections.unmodifiableList(alternatives_);
        }
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return nvidia.riva.asr.RivaAsr.internal_static_nvidia_riva_asr_SpeechRecognitionResult_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return nvidia.riva.asr.RivaAsr.internal_static_nvidia_riva_asr_SpeechRecognitionResult_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              nvidia.riva.asr.RivaAsr.SpeechRecognitionResult.class, nvidia.riva.asr.RivaAsr.SpeechRecognitionResult.Builder.class);
    }

    private int bitField0_;
    public static final int ALTERNATIVES_FIELD_NUMBER = 1;
    private java.util.List<nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative> alternatives_;
    /**
     * <pre>
     * May contain one or more recognition hypotheses (up to the
     * maximum specified in `max_alternatives`).
     * These alternatives are ordered in terms of accuracy, with the top (first)
     * alternative being the most probable, as ranked by the recognizer.
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
     */
    public java.util.List<nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative> getAlternativesList() {
      return alternatives_;
    }
    /**
     * <pre>
     * May contain one or more recognition hypotheses (up to the
     * maximum specified in `max_alternatives`).
     * These alternatives are ordered in terms of accuracy, with the top (first)
     * alternative being the most probable, as ranked by the recognizer.
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
     */
    public java.util.List<? extends nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternativeOrBuilder> 
        getAlternativesOrBuilderList() {
      return alternatives_;
    }
    /**
     * <pre>
     * May contain one or more recognition hypotheses (up to the
     * maximum specified in `max_alternatives`).
     * These alternatives are ordered in terms of accuracy, with the top (first)
     * alternative being the most probable, as ranked by the recognizer.
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
     */
    public int getAlternativesCount() {
      return alternatives_.size();
    }
    /**
     * <pre>
     * May contain one or more recognition hypotheses (up to the
     * maximum specified in `max_alternatives`).
     * These alternatives are ordered in terms of accuracy, with the top (first)
     * alternative being the most probable, as ranked by the recognizer.
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
     */
    public nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative getAlternatives(int index) {
      return alternatives_.get(index);
    }
    /**
     * <pre>
     * May contain one or more recognition hypotheses (up to the
     * maximum specified in `max_alternatives`).
     * These alternatives are ordered in terms of accuracy, with the top (first)
     * alternative being the most probable, as ranked by the recognizer.
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
     */
    public nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternativeOrBuilder getAlternativesOrBuilder(
        int index) {
      return alternatives_.get(index);
    }

    public static final int CHANNEL_TAG_FIELD_NUMBER = 2;
    private int channelTag_;
    /**
     * <pre>
     * For multi-channel audio, this is the channel number corresponding to the
     * recognized result for the audio from that channel.
     * For audio_channel_count = N, its output values can range from '1' to 'N'.
     * </pre>
     *
     * <code>optional int32 channel_tag = 2;</code>
     */
    public int getChannelTag() {
      return channelTag_;
    }

    public static final int AUDIO_PROCESSED_FIELD_NUMBER = 3;
    private float audioProcessed_;
    /**
     * <pre>
     * Length of audio processed so far in seconds
     * </pre>
     *
     * <code>optional float audio_processed = 3;</code>
     */
    public float getAudioProcessed() {
      return audioProcessed_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < alternatives_.size(); i++) {
        output.writeMessage(1, alternatives_.get(i));
      }
      if (channelTag_ != 0) {
        output.writeInt32(2, channelTag_);
      }
      if (audioProcessed_ != 0F) {
        output.writeFloat(3, audioProcessed_);
      }
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < alternatives_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, alternatives_.get(i));
      }
      if (channelTag_ != 0) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(2, channelTag_);
      }
      if (audioProcessed_ != 0F) {
        size += com.google.protobuf.CodedOutputStream
          .computeFloatSize(3, audioProcessed_);
      }
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof nvidia.riva.asr.RivaAsr.SpeechRecognitionResult)) {
        return super.equals(obj);
      }
      nvidia.riva.asr.RivaAsr.SpeechRecognitionResult other = (nvidia.riva.asr.RivaAsr.SpeechRecognitionResult) obj;

      boolean result = true;
      result = result && getAlternativesList()
          .equals(other.getAlternativesList());
      result = result && (getChannelTag()
          == other.getChannelTag());
      result = result && (
          java.lang.Float.floatToIntBits(getAudioProcessed())
          == java.lang.Float.floatToIntBits(
              other.getAudioProcessed()));
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (getAlternativesCount() > 0) {
        hash = (37 * hash) + ALTERNATIVES_FIELD_NUMBER;
        hash = (53 * hash) + getAlternativesList().hashCode();
      }
      hash = (37 * hash) + CHANNEL_TAG_FIELD_NUMBER;
      hash = (53 * hash) + getChannelTag();
      hash = (37 * hash) + AUDIO_PROCESSED_FIELD_NUMBER;
      hash = (53 * hash) + java.lang.Float.floatToIntBits(
          getAudioProcessed());
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static nvidia.riva.asr.RivaAsr.SpeechRecognitionResult parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static nvidia.riva.asr.RivaAsr.SpeechRecognitionResult parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static nvidia.riva.asr.RivaAsr.SpeechRecognitionResult parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static nvidia.riva.asr.RivaAsr.SpeechRecognitionResult parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static nvidia.riva.asr.RivaAsr.SpeechRecognitionResult parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static nvidia.riva.asr.RivaAsr.SpeechRecognitionResult parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static nvidia.riva.asr.RivaAsr.SpeechRecognitionResult parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static nvidia.riva.asr.RivaAsr.SpeechRecognitionResult parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static nvidia.riva.asr.RivaAsr.SpeechRecognitionResult parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static nvidia.riva.asr.RivaAsr.SpeechRecognitionResult parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(nvidia.riva.asr.RivaAsr.SpeechRecognitionResult prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     * A speech recognition result corresponding to the latest transcript
     * </pre>
     *
     * Protobuf type {@code nvidia.riva.asr.SpeechRecognitionResult}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:nvidia.riva.asr.SpeechRecognitionResult)
        nvidia.riva.asr.RivaAsr.SpeechRecognitionResultOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return nvidia.riva.asr.RivaAsr.internal_static_nvidia_riva_asr_SpeechRecognitionResult_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return nvidia.riva.asr.RivaAsr.internal_static_nvidia_riva_asr_SpeechRecognitionResult_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                nvidia.riva.asr.RivaAsr.SpeechRecognitionResult.class, nvidia.riva.asr.RivaAsr.SpeechRecognitionResult.Builder.class);
      }

      // Construct using nvidia.riva.asr.RivaAsr.SpeechRecognitionResult.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getAlternativesFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (alternativesBuilder_ == null) {
          alternatives_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
        } else {
          alternativesBuilder_.clear();
        }
        channelTag_ = 0;

        audioProcessed_ = 0F;

        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return nvidia.riva.asr.RivaAsr.internal_static_nvidia_riva_asr_SpeechRecognitionResult_descriptor;
      }

      public nvidia.riva.asr.RivaAsr.SpeechRecognitionResult getDefaultInstanceForType() {
        return nvidia.riva.asr.RivaAsr.SpeechRecognitionResult.getDefaultInstance();
      }

      public nvidia.riva.asr.RivaAsr.SpeechRecognitionResult build() {
        nvidia.riva.asr.RivaAsr.SpeechRecognitionResult result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public nvidia.riva.asr.RivaAsr.SpeechRecognitionResult buildPartial() {
        nvidia.riva.asr.RivaAsr.SpeechRecognitionResult result = new nvidia.riva.asr.RivaAsr.SpeechRecognitionResult(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (alternativesBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001)) {
            alternatives_ = java.util.Collections.unmodifiableList(alternatives_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.alternatives_ = alternatives_;
        } else {
          result.alternatives_ = alternativesBuilder_.build();
        }
        result.channelTag_ = channelTag_;
        result.audioProcessed_ = audioProcessed_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof nvidia.riva.asr.RivaAsr.SpeechRecognitionResult) {
          return mergeFrom((nvidia.riva.asr.RivaAsr.SpeechRecognitionResult)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(nvidia.riva.asr.RivaAsr.SpeechRecognitionResult other) {
        if (other == nvidia.riva.asr.RivaAsr.SpeechRecognitionResult.getDefaultInstance()) return this;
        if (alternativesBuilder_ == null) {
          if (!other.alternatives_.isEmpty()) {
            if (alternatives_.isEmpty()) {
              alternatives_ = other.alternatives_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureAlternativesIsMutable();
              alternatives_.addAll(other.alternatives_);
            }
            onChanged();
          }
        } else {
          if (!other.alternatives_.isEmpty()) {
            if (alternativesBuilder_.isEmpty()) {
              alternativesBuilder_.dispose();
              alternativesBuilder_ = null;
              alternatives_ = other.alternatives_;
              bitField0_ = (bitField0_ & ~0x00000001);
              alternativesBuilder_ = 
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getAlternativesFieldBuilder() : null;
            } else {
              alternativesBuilder_.addAllMessages(other.alternatives_);
            }
          }
        }
        if (other.getChannelTag() != 0) {
          setChannelTag(other.getChannelTag());
        }
        if (other.getAudioProcessed() != 0F) {
          setAudioProcessed(other.getAudioProcessed());
        }
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        nvidia.riva.asr.RivaAsr.SpeechRecognitionResult parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (nvidia.riva.asr.RivaAsr.SpeechRecognitionResult) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.util.List<nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative> alternatives_ =
        java.util.Collections.emptyList();
      private void ensureAlternativesIsMutable() {
        if (!((bitField0_ & 0x00000001) == 0x00000001)) {
          alternatives_ = new java.util.ArrayList<nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative>(alternatives_);
          bitField0_ |= 0x00000001;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative, nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative.Builder, nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternativeOrBuilder> alternativesBuilder_;

      /**
       * <pre>
       * May contain one or more recognition hypotheses (up to the
       * maximum specified in `max_alternatives`).
       * These alternatives are ordered in terms of accuracy, with the top (first)
       * alternative being the most probable, as ranked by the recognizer.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
       */
      public java.util.List<nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative> getAlternativesList() {
        if (alternativesBuilder_ == null) {
          return java.util.Collections.unmodifiableList(alternatives_);
        } else {
          return alternativesBuilder_.getMessageList();
        }
      }
      /**
       * <pre>
       * May contain one or more recognition hypotheses (up to the
       * maximum specified in `max_alternatives`).
       * These alternatives are ordered in terms of accuracy, with the top (first)
       * alternative being the most probable, as ranked by the recognizer.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
       */
      public int getAlternativesCount() {
        if (alternativesBuilder_ == null) {
          return alternatives_.size();
        } else {
          return alternativesBuilder_.getCount();
        }
      }
      /**
       * <pre>
       * May contain one or more recognition hypotheses (up to the
       * maximum specified in `max_alternatives`).
       * These alternatives are ordered in terms of accuracy, with the top (first)
       * alternative being the most probable, as ranked by the recognizer.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
       */
      public nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative getAlternatives(int index) {
        if (alternativesBuilder_ == null) {
          return alternatives_.get(index);
        } else {
          return alternativesBuilder_.getMessage(index);
        }
      }
      /**
       * <pre>
       * May contain one or more recognition hypotheses (up to the
       * maximum specified in `max_alternatives`).
       * These alternatives are ordered in terms of accuracy, with the top (first)
       * alternative being the most probable, as ranked by the recognizer.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
       */
      public Builder setAlternatives(
          int index, nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative value) {
        if (alternativesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureAlternativesIsMutable();
          alternatives_.set(index, value);
          onChanged();
        } else {
          alternativesBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <pre>
       * May contain one or more recognition hypotheses (up to the
       * maximum specified in `max_alternatives`).
       * These alternatives are ordered in terms of accuracy, with the top (first)
       * alternative being the most probable, as ranked by the recognizer.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
       */
      public Builder setAlternatives(
          int index, nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative.Builder builderForValue) {
        if (alternativesBuilder_ == null) {
          ensureAlternativesIsMutable();
          alternatives_.set(index, builderForValue.build());
          onChanged();
        } else {
          alternativesBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       * May contain one or more recognition hypotheses (up to the
       * maximum specified in `max_alternatives`).
       * These alternatives are ordered in terms of accuracy, with the top (first)
       * alternative being the most probable, as ranked by the recognizer.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
       */
      public Builder addAlternatives(nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative value) {
        if (alternativesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureAlternativesIsMutable();
          alternatives_.add(value);
          onChanged();
        } else {
          alternativesBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <pre>
       * May contain one or more recognition hypotheses (up to the
       * maximum specified in `max_alternatives`).
       * These alternatives are ordered in terms of accuracy, with the top (first)
       * alternative being the most probable, as ranked by the recognizer.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
       */
      public Builder addAlternatives(
          int index, nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative value) {
        if (alternativesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureAlternativesIsMutable();
          alternatives_.add(index, value);
          onChanged();
        } else {
          alternativesBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <pre>
       * May contain one or more recognition hypotheses (up to the
       * maximum specified in `max_alternatives`).
       * These alternatives are ordered in terms of accuracy, with the top (first)
       * alternative being the most probable, as ranked by the recognizer.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
       */
      public Builder addAlternatives(
          nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative.Builder builderForValue) {
        if (alternativesBuilder_ == null) {
          ensureAlternativesIsMutable();
          alternatives_.add(builderForValue.build());
          onChanged();
        } else {
          alternativesBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       * May contain one or more recognition hypotheses (up to the
       * maximum specified in `max_alternatives`).
       * These alternatives are ordered in terms of accuracy, with the top (first)
       * alternative being the most probable, as ranked by the recognizer.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
       */
      public Builder addAlternatives(
          int index, nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative.Builder builderForValue) {
        if (alternativesBuilder_ == null) {
          ensureAlternativesIsMutable();
          alternatives_.add(index, builderForValue.build());
          onChanged();
        } else {
          alternativesBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       * May contain one or more recognition hypotheses (up to the
       * maximum specified in `max_alternatives`).
       * These alternatives are ordered in terms of accuracy, with the top (first)
       * alternative being the most probable, as ranked by the recognizer.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
       */
      public Builder addAllAlternatives(
          java.lang.Iterable<? extends nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative> values) {
        if (alternativesBuilder_ == null) {
          ensureAlternativesIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, alternatives_);
          onChanged();
        } else {
          alternativesBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <pre>
       * May contain one or more recognition hypotheses (up to the
       * maximum specified in `max_alternatives`).
       * These alternatives are ordered in terms of accuracy, with the top (first)
       * alternative being the most probable, as ranked by the recognizer.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
       */
      public Builder clearAlternatives() {
        if (alternativesBuilder_ == null) {
          alternatives_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          alternativesBuilder_.clear();
        }
        return this;
      }
      /**
       * <pre>
       * May contain one or more recognition hypotheses (up to the
       * maximum specified in `max_alternatives`).
       * These alternatives are ordered in terms of accuracy, with the top (first)
       * alternative being the most probable, as ranked by the recognizer.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
       */
      public Builder removeAlternatives(int index) {
        if (alternativesBuilder_ == null) {
          ensureAlternativesIsMutable();
          alternatives_.remove(index);
          onChanged();
        } else {
          alternativesBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <pre>
       * May contain one or more recognition hypotheses (up to the
       * maximum specified in `max_alternatives`).
       * These alternatives are ordered in terms of accuracy, with the top (first)
       * alternative being the most probable, as ranked by the recognizer.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
       */
      public nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative.Builder getAlternativesBuilder(
          int index) {
        return getAlternativesFieldBuilder().getBuilder(index);
      }
      /**
       * <pre>
       * May contain one or more recognition hypotheses (up to the
       * maximum specified in `max_alternatives`).
       * These alternatives are ordered in terms of accuracy, with the top (first)
       * alternative being the most probable, as ranked by the recognizer.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
       */
      public nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternativeOrBuilder getAlternativesOrBuilder(
          int index) {
        if (alternativesBuilder_ == null) {
          return alternatives_.get(index);  } else {
          return alternativesBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <pre>
       * May contain one or more recognition hypotheses (up to the
       * maximum specified in `max_alternatives`).
       * These alternatives are ordered in terms of accuracy, with the top (first)
       * alternative being the most probable, as ranked by the recognizer.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
       */
      public java.util.List<? extends nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternativeOrBuilder> 
           getAlternativesOrBuilderList() {
        if (alternativesBuilder_ != null) {
          return alternativesBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(alternatives_);
        }
      }
      /**
       * <pre>
       * May contain one or more recognition hypotheses (up to the
       * maximum specified in `max_alternatives`).
       * These alternatives are ordered in terms of accuracy, with the top (first)
       * alternative being the most probable, as ranked by the recognizer.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
       */
      public nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative.Builder addAlternativesBuilder() {
        return getAlternativesFieldBuilder().addBuilder(
            nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative.getDefaultInstance());
      }
      /**
       * <pre>
       * May contain one or more recognition hypotheses (up to the
       * maximum specified in `max_alternatives`).
       * These alternatives are ordered in terms of accuracy, with the top (first)
       * alternative being the most probable, as ranked by the recognizer.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
       */
      public nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative.Builder addAlternativesBuilder(
          int index) {
        return getAlternativesFieldBuilder().addBuilder(
            index, nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative.getDefaultInstance());
      }
      /**
       * <pre>
       * May contain one or more recognition hypotheses (up to the
       * maximum specified in `max_alternatives`).
       * These alternatives are ordered in terms of accuracy, with the top (first)
       * alternative being the most probable, as ranked by the recognizer.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
       */
      public java.util.List<nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative.Builder> 
           getAlternativesBuilderList() {
        return getAlternativesFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative, nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative.Builder, nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternativeOrBuilder> 
          getAlternativesFieldBuilder() {
        if (alternativesBuilder_ == null) {
          alternativesBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative, nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative.Builder, nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternativeOrBuilder>(
                  alternatives_,
                  ((bitField0_ & 0x00000001) == 0x00000001),
                  getParentForChildren(),
                  isClean());
          alternatives_ = null;
        }
        return alternativesBuilder_;
      }

      private int channelTag_ ;
      /**
       * <pre>
       * For multi-channel audio, this is the channel number corresponding to the
       * recognized result for the audio from that channel.
       * For audio_channel_count = N, its output values can range from '1' to 'N'.
       * </pre>
       *
       * <code>optional int32 channel_tag = 2;</code>
       */
      public int getChannelTag() {
        return channelTag_;
      }
      /**
       * <pre>
       * For multi-channel audio, this is the channel number corresponding to the
       * recognized result for the audio from that channel.
       * For audio_channel_count = N, its output values can range from '1' to 'N'.
       * </pre>
       *
       * <code>optional int32 channel_tag = 2;</code>
       */
      public Builder setChannelTag(int value) {
        
        channelTag_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * For multi-channel audio, this is the channel number corresponding to the
       * recognized result for the audio from that channel.
       * For audio_channel_count = N, its output values can range from '1' to 'N'.
       * </pre>
       *
       * <code>optional int32 channel_tag = 2;</code>
       */
      public Builder clearChannelTag() {
        
        channelTag_ = 0;
        onChanged();
        return this;
      }

      private float audioProcessed_ ;
      /**
       * <pre>
       * Length of audio processed so far in seconds
       * </pre>
       *
       * <code>optional float audio_processed = 3;</code>
       */
      public float getAudioProcessed() {
        return audioProcessed_;
      }
      /**
       * <pre>
       * Length of audio processed so far in seconds
       * </pre>
       *
       * <code>optional float audio_processed = 3;</code>
       */
      public Builder setAudioProcessed(float value) {
        
        audioProcessed_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Length of audio processed so far in seconds
       * </pre>
       *
       * <code>optional float audio_processed = 3;</code>
       */
      public Builder clearAudioProcessed() {
        
        audioProcessed_ = 0F;
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return this;
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return this;
      }


      // @@protoc_insertion_point(builder_scope:nvidia.riva.asr.SpeechRecognitionResult)
    }

    // @@protoc_insertion_point(class_scope:nvidia.riva.asr.SpeechRecognitionResult)
    private static final nvidia.riva.asr.RivaAsr.SpeechRecognitionResult DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new nvidia.riva.asr.RivaAsr.SpeechRecognitionResult();
    }

    public static nvidia.riva.asr.RivaAsr.SpeechRecognitionResult getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<SpeechRecognitionResult>
        PARSER = new com.google.protobuf.AbstractParser<SpeechRecognitionResult>() {
      public SpeechRecognitionResult parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new SpeechRecognitionResult(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<SpeechRecognitionResult> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<SpeechRecognitionResult> getParserForType() {
      return PARSER;
    }

    public nvidia.riva.asr.RivaAsr.SpeechRecognitionResult getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface SpeechRecognitionAlternativeOrBuilder extends
      // @@protoc_insertion_point(interface_extends:nvidia.riva.asr.SpeechRecognitionAlternative)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * Transcript text representing the words that the user spoke.
     * </pre>
     *
     * <code>optional string transcript = 1;</code>
     */
    java.lang.String getTranscript();
    /**
     * <pre>
     * Transcript text representing the words that the user spoke.
     * </pre>
     *
     * <code>optional string transcript = 1;</code>
     */
    com.google.protobuf.ByteString
        getTranscriptBytes();

    /**
     * <pre>
     * The non-normalized confidence estimate. A higher number
     * indicates an estimated greater likelihood that the recognized words are
     * correct. This field is set only for a non-streaming
     * result or, of a streaming result where `is_final=true`.
     * This field is not guaranteed to be accurate and users should not rely on it
     * to be always provided.
     * </pre>
     *
     * <code>optional float confidence = 2;</code>
     */
    float getConfidence();

    /**
     * <pre>
     * A list of word-specific information for each recognized word. Only populated
     * if is_final=true
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.WordInfo words = 3;</code>
     */
    java.util.List<nvidia.riva.asr.RivaAsr.WordInfo> 
        getWordsList();
    /**
     * <pre>
     * A list of word-specific information for each recognized word. Only populated
     * if is_final=true
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.WordInfo words = 3;</code>
     */
    nvidia.riva.asr.RivaAsr.WordInfo getWords(int index);
    /**
     * <pre>
     * A list of word-specific information for each recognized word. Only populated
     * if is_final=true
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.WordInfo words = 3;</code>
     */
    int getWordsCount();
    /**
     * <pre>
     * A list of word-specific information for each recognized word. Only populated
     * if is_final=true
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.WordInfo words = 3;</code>
     */
    java.util.List<? extends nvidia.riva.asr.RivaAsr.WordInfoOrBuilder> 
        getWordsOrBuilderList();
    /**
     * <pre>
     * A list of word-specific information for each recognized word. Only populated
     * if is_final=true
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.WordInfo words = 3;</code>
     */
    nvidia.riva.asr.RivaAsr.WordInfoOrBuilder getWordsOrBuilder(
        int index);
  }
  /**
   * <pre>
   * Alternative hypotheses (a.k.a. n-best list).
   * </pre>
   *
   * Protobuf type {@code nvidia.riva.asr.SpeechRecognitionAlternative}
   */
  public  static final class SpeechRecognitionAlternative extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:nvidia.riva.asr.SpeechRecognitionAlternative)
      SpeechRecognitionAlternativeOrBuilder {
    // Use SpeechRecognitionAlternative.newBuilder() to construct.
    private SpeechRecognitionAlternative(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private SpeechRecognitionAlternative() {
      transcript_ = "";
      confidence_ = 0F;
      words_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return com.google.protobuf.UnknownFieldSet.getDefaultInstance();
    }
    private SpeechRecognitionAlternative(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!input.skipField(tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              java.lang.String s = input.readStringRequireUtf8();

              transcript_ = s;
              break;
            }
            case 21: {

              confidence_ = input.readFloat();
              break;
            }
            case 26: {
              if (!((mutable_bitField0_ & 0x00000004) == 0x00000004)) {
                words_ = new java.util.ArrayList<nvidia.riva.asr.RivaAsr.WordInfo>();
                mutable_bitField0_ |= 0x00000004;
              }
              words_.add(
                  input.readMessage(nvidia.riva.asr.RivaAsr.WordInfo.parser(), extensionRegistry));
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000004) == 0x00000004)) {
          words_ = java.util.Collections.unmodifiableList(words_);
        }
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return nvidia.riva.asr.RivaAsr.internal_static_nvidia_riva_asr_SpeechRecognitionAlternative_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return nvidia.riva.asr.RivaAsr.internal_static_nvidia_riva_asr_SpeechRecognitionAlternative_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative.class, nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative.Builder.class);
    }

    private int bitField0_;
    public static final int TRANSCRIPT_FIELD_NUMBER = 1;
    private volatile java.lang.Object transcript_;
    /**
     * <pre>
     * Transcript text representing the words that the user spoke.
     * </pre>
     *
     * <code>optional string transcript = 1;</code>
     */
    public java.lang.String getTranscript() {
      java.lang.Object ref = transcript_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        transcript_ = s;
        return s;
      }
    }
    /**
     * <pre>
     * Transcript text representing the words that the user spoke.
     * </pre>
     *
     * <code>optional string transcript = 1;</code>
     */
    public com.google.protobuf.ByteString
        getTranscriptBytes() {
      java.lang.Object ref = transcript_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        transcript_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int CONFIDENCE_FIELD_NUMBER = 2;
    private float confidence_;
    /**
     * <pre>
     * The non-normalized confidence estimate. A higher number
     * indicates an estimated greater likelihood that the recognized words are
     * correct. This field is set only for a non-streaming
     * result or, of a streaming result where `is_final=true`.
     * This field is not guaranteed to be accurate and users should not rely on it
     * to be always provided.
     * </pre>
     *
     * <code>optional float confidence = 2;</code>
     */
    public float getConfidence() {
      return confidence_;
    }

    public static final int WORDS_FIELD_NUMBER = 3;
    private java.util.List<nvidia.riva.asr.RivaAsr.WordInfo> words_;
    /**
     * <pre>
     * A list of word-specific information for each recognized word. Only populated
     * if is_final=true
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.WordInfo words = 3;</code>
     */
    public java.util.List<nvidia.riva.asr.RivaAsr.WordInfo> getWordsList() {
      return words_;
    }
    /**
     * <pre>
     * A list of word-specific information for each recognized word. Only populated
     * if is_final=true
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.WordInfo words = 3;</code>
     */
    public java.util.List<? extends nvidia.riva.asr.RivaAsr.WordInfoOrBuilder> 
        getWordsOrBuilderList() {
      return words_;
    }
    /**
     * <pre>
     * A list of word-specific information for each recognized word. Only populated
     * if is_final=true
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.WordInfo words = 3;</code>
     */
    public int getWordsCount() {
      return words_.size();
    }
    /**
     * <pre>
     * A list of word-specific information for each recognized word. Only populated
     * if is_final=true
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.WordInfo words = 3;</code>
     */
    public nvidia.riva.asr.RivaAsr.WordInfo getWords(int index) {
      return words_.get(index);
    }
    /**
     * <pre>
     * A list of word-specific information for each recognized word. Only populated
     * if is_final=true
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.WordInfo words = 3;</code>
     */
    public nvidia.riva.asr.RivaAsr.WordInfoOrBuilder getWordsOrBuilder(
        int index) {
      return words_.get(index);
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (!getTranscriptBytes().isEmpty()) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 1, transcript_);
      }
      if (confidence_ != 0F) {
        output.writeFloat(2, confidence_);
      }
      for (int i = 0; i < words_.size(); i++) {
        output.writeMessage(3, words_.get(i));
      }
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (!getTranscriptBytes().isEmpty()) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, transcript_);
      }
      if (confidence_ != 0F) {
        size += com.google.protobuf.CodedOutputStream
          .computeFloatSize(2, confidence_);
      }
      for (int i = 0; i < words_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, words_.get(i));
      }
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative)) {
        return super.equals(obj);
      }
      nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative other = (nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative) obj;

      boolean result = true;
      result = result && getTranscript()
          .equals(other.getTranscript());
      result = result && (
          java.lang.Float.floatToIntBits(getConfidence())
          == java.lang.Float.floatToIntBits(
              other.getConfidence()));
      result = result && getWordsList()
          .equals(other.getWordsList());
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      hash = (37 * hash) + TRANSCRIPT_FIELD_NUMBER;
      hash = (53 * hash) + getTranscript().hashCode();
      hash = (37 * hash) + CONFIDENCE_FIELD_NUMBER;
      hash = (53 * hash) + java.lang.Float.floatToIntBits(
          getConfidence());
      if (getWordsCount() > 0) {
        hash = (37 * hash) + WORDS_FIELD_NUMBER;
        hash = (53 * hash) + getWordsList().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     * Alternative hypotheses (a.k.a. n-best list).
     * </pre>
     *
     * Protobuf type {@code nvidia.riva.asr.SpeechRecognitionAlternative}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:nvidia.riva.asr.SpeechRecognitionAlternative)
        nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternativeOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return nvidia.riva.asr.RivaAsr.internal_static_nvidia_riva_asr_SpeechRecognitionAlternative_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return nvidia.riva.asr.RivaAsr.internal_static_nvidia_riva_asr_SpeechRecognitionAlternative_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative.class, nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative.Builder.class);
      }

      // Construct using nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getWordsFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        transcript_ = "";

        confidence_ = 0F;

        if (wordsBuilder_ == null) {
          words_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000004);
        } else {
          wordsBuilder_.clear();
        }
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return nvidia.riva.asr.RivaAsr.internal_static_nvidia_riva_asr_SpeechRecognitionAlternative_descriptor;
      }

      public nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative getDefaultInstanceForType() {
        return nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative.getDefaultInstance();
      }

      public nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative build() {
        nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative buildPartial() {
        nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative result = new nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        result.transcript_ = transcript_;
        result.confidence_ = confidence_;
        if (wordsBuilder_ == null) {
          if (((bitField0_ & 0x00000004) == 0x00000004)) {
            words_ = java.util.Collections.unmodifiableList(words_);
            bitField0_ = (bitField0_ & ~0x00000004);
          }
          result.words_ = words_;
        } else {
          result.words_ = wordsBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative) {
          return mergeFrom((nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative other) {
        if (other == nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative.getDefaultInstance()) return this;
        if (!other.getTranscript().isEmpty()) {
          transcript_ = other.transcript_;
          onChanged();
        }
        if (other.getConfidence() != 0F) {
          setConfidence(other.getConfidence());
        }
        if (wordsBuilder_ == null) {
          if (!other.words_.isEmpty()) {
            if (words_.isEmpty()) {
              words_ = other.words_;
              bitField0_ = (bitField0_ & ~0x00000004);
            } else {
              ensureWordsIsMutable();
              words_.addAll(other.words_);
            }
            onChanged();
          }
        } else {
          if (!other.words_.isEmpty()) {
            if (wordsBuilder_.isEmpty()) {
              wordsBuilder_.dispose();
              wordsBuilder_ = null;
              words_ = other.words_;
              bitField0_ = (bitField0_ & ~0x00000004);
              wordsBuilder_ = 
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getWordsFieldBuilder() : null;
            } else {
              wordsBuilder_.addAllMessages(other.words_);
            }
          }
        }
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.lang.Object transcript_ = "";
      /**
       * <pre>
       * Transcript text representing the words that the user spoke.
       * </pre>
       *
       * <code>optional string transcript = 1;</code>
       */
      public java.lang.String getTranscript() {
        java.lang.Object ref = transcript_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          transcript_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * Transcript text representing the words that the user spoke.
       * </pre>
       *
       * <code>optional string transcript = 1;</code>
       */
      public com.google.protobuf.ByteString
          getTranscriptBytes() {
        java.lang.Object ref = transcript_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          transcript_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * Transcript text representing the words that the user spoke.
       * </pre>
       *
       * <code>optional string transcript = 1;</code>
       */
      public Builder setTranscript(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  
        transcript_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Transcript text representing the words that the user spoke.
       * </pre>
       *
       * <code>optional string transcript = 1;</code>
       */
      public Builder clearTranscript() {
        
        transcript_ = getDefaultInstance().getTranscript();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Transcript text representing the words that the user spoke.
       * </pre>
       *
       * <code>optional string transcript = 1;</code>
       */
      public Builder setTranscriptBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        
        transcript_ = value;
        onChanged();
        return this;
      }

      private float confidence_ ;
      /**
       * <pre>
       * The non-normalized confidence estimate. A higher number
       * indicates an estimated greater likelihood that the recognized words are
       * correct. This field is set only for a non-streaming
       * result or, of a streaming result where `is_final=true`.
       * This field is not guaranteed to be accurate and users should not rely on it
       * to be always provided.
       * </pre>
       *
       * <code>optional float confidence = 2;</code>
       */
      public float getConfidence() {
        return confidence_;
      }
      /**
       * <pre>
       * The non-normalized confidence estimate. A higher number
       * indicates an estimated greater likelihood that the recognized words are
       * correct. This field is set only for a non-streaming
       * result or, of a streaming result where `is_final=true`.
       * This field is not guaranteed to be accurate and users should not rely on it
       * to be always provided.
       * </pre>
       *
       * <code>optional float confidence = 2;</code>
       */
      public Builder setConfidence(float value) {
        
        confidence_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The non-normalized confidence estimate. A higher number
       * indicates an estimated greater likelihood that the recognized words are
       * correct. This field is set only for a non-streaming
       * result or, of a streaming result where `is_final=true`.
       * This field is not guaranteed to be accurate and users should not rely on it
       * to be always provided.
       * </pre>
       *
       * <code>optional float confidence = 2;</code>
       */
      public Builder clearConfidence() {
        
        confidence_ = 0F;
        onChanged();
        return this;
      }

      private java.util.List<nvidia.riva.asr.RivaAsr.WordInfo> words_ =
        java.util.Collections.emptyList();
      private void ensureWordsIsMutable() {
        if (!((bitField0_ & 0x00000004) == 0x00000004)) {
          words_ = new java.util.ArrayList<nvidia.riva.asr.RivaAsr.WordInfo>(words_);
          bitField0_ |= 0x00000004;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          nvidia.riva.asr.RivaAsr.WordInfo, nvidia.riva.asr.RivaAsr.WordInfo.Builder, nvidia.riva.asr.RivaAsr.WordInfoOrBuilder> wordsBuilder_;

      /**
       * <pre>
       * A list of word-specific information for each recognized word. Only populated
       * if is_final=true
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.WordInfo words = 3;</code>
       */
      public java.util.List<nvidia.riva.asr.RivaAsr.WordInfo> getWordsList() {
        if (wordsBuilder_ == null) {
          return java.util.Collections.unmodifiableList(words_);
        } else {
          return wordsBuilder_.getMessageList();
        }
      }
      /**
       * <pre>
       * A list of word-specific information for each recognized word. Only populated
       * if is_final=true
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.WordInfo words = 3;</code>
       */
      public int getWordsCount() {
        if (wordsBuilder_ == null) {
          return words_.size();
        } else {
          return wordsBuilder_.getCount();
        }
      }
      /**
       * <pre>
       * A list of word-specific information for each recognized word. Only populated
       * if is_final=true
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.WordInfo words = 3;</code>
       */
      public nvidia.riva.asr.RivaAsr.WordInfo getWords(int index) {
        if (wordsBuilder_ == null) {
          return words_.get(index);
        } else {
          return wordsBuilder_.getMessage(index);
        }
      }
      /**
       * <pre>
       * A list of word-specific information for each recognized word. Only populated
       * if is_final=true
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.WordInfo words = 3;</code>
       */
      public Builder setWords(
          int index, nvidia.riva.asr.RivaAsr.WordInfo value) {
        if (wordsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureWordsIsMutable();
          words_.set(index, value);
          onChanged();
        } else {
          wordsBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <pre>
       * A list of word-specific information for each recognized word. Only populated
       * if is_final=true
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.WordInfo words = 3;</code>
       */
      public Builder setWords(
          int index, nvidia.riva.asr.RivaAsr.WordInfo.Builder builderForValue) {
        if (wordsBuilder_ == null) {
          ensureWordsIsMutable();
          words_.set(index, builderForValue.build());
          onChanged();
        } else {
          wordsBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       * A list of word-specific information for each recognized word. Only populated
       * if is_final=true
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.WordInfo words = 3;</code>
       */
      public Builder addWords(nvidia.riva.asr.RivaAsr.WordInfo value) {
        if (wordsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureWordsIsMutable();
          words_.add(value);
          onChanged();
        } else {
          wordsBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <pre>
       * A list of word-specific information for each recognized word. Only populated
       * if is_final=true
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.WordInfo words = 3;</code>
       */
      public Builder addWords(
          int index, nvidia.riva.asr.RivaAsr.WordInfo value) {
        if (wordsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureWordsIsMutable();
          words_.add(index, value);
          onChanged();
        } else {
          wordsBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <pre>
       * A list of word-specific information for each recognized word. Only populated
       * if is_final=true
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.WordInfo words = 3;</code>
       */
      public Builder addWords(
          nvidia.riva.asr.RivaAsr.WordInfo.Builder builderForValue) {
        if (wordsBuilder_ == null) {
          ensureWordsIsMutable();
          words_.add(builderForValue.build());
          onChanged();
        } else {
          wordsBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       * A list of word-specific information for each recognized word. Only populated
       * if is_final=true
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.WordInfo words = 3;</code>
       */
      public Builder addWords(
          int index, nvidia.riva.asr.RivaAsr.WordInfo.Builder builderForValue) {
        if (wordsBuilder_ == null) {
          ensureWordsIsMutable();
          words_.add(index, builderForValue.build());
          onChanged();
        } else {
          wordsBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       * A list of word-specific information for each recognized word. Only populated
       * if is_final=true
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.WordInfo words = 3;</code>
       */
      public Builder addAllWords(
          java.lang.Iterable<? extends nvidia.riva.asr.RivaAsr.WordInfo> values) {
        if (wordsBuilder_ == null) {
          ensureWordsIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, words_);
          onChanged();
        } else {
          wordsBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <pre>
       * A list of word-specific information for each recognized word. Only populated
       * if is_final=true
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.WordInfo words = 3;</code>
       */
      public Builder clearWords() {
        if (wordsBuilder_ == null) {
          words_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000004);
          onChanged();
        } else {
          wordsBuilder_.clear();
        }
        return this;
      }
      /**
       * <pre>
       * A list of word-specific information for each recognized word. Only populated
       * if is_final=true
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.WordInfo words = 3;</code>
       */
      public Builder removeWords(int index) {
        if (wordsBuilder_ == null) {
          ensureWordsIsMutable();
          words_.remove(index);
          onChanged();
        } else {
          wordsBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <pre>
       * A list of word-specific information for each recognized word. Only populated
       * if is_final=true
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.WordInfo words = 3;</code>
       */
      public nvidia.riva.asr.RivaAsr.WordInfo.Builder getWordsBuilder(
          int index) {
        return getWordsFieldBuilder().getBuilder(index);
      }
      /**
       * <pre>
       * A list of word-specific information for each recognized word. Only populated
       * if is_final=true
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.WordInfo words = 3;</code>
       */
      public nvidia.riva.asr.RivaAsr.WordInfoOrBuilder getWordsOrBuilder(
          int index) {
        if (wordsBuilder_ == null) {
          return words_.get(index);  } else {
          return wordsBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <pre>
       * A list of word-specific information for each recognized word. Only populated
       * if is_final=true
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.WordInfo words = 3;</code>
       */
      public java.util.List<? extends nvidia.riva.asr.RivaAsr.WordInfoOrBuilder> 
           getWordsOrBuilderList() {
        if (wordsBuilder_ != null) {
          return wordsBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(words_);
        }
      }
      /**
       * <pre>
       * A list of word-specific information for each recognized word. Only populated
       * if is_final=true
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.WordInfo words = 3;</code>
       */
      public nvidia.riva.asr.RivaAsr.WordInfo.Builder addWordsBuilder() {
        return getWordsFieldBuilder().addBuilder(
            nvidia.riva.asr.RivaAsr.WordInfo.getDefaultInstance());
      }
      /**
       * <pre>
       * A list of word-specific information for each recognized word. Only populated
       * if is_final=true
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.WordInfo words = 3;</code>
       */
      public nvidia.riva.asr.RivaAsr.WordInfo.Builder addWordsBuilder(
          int index) {
        return getWordsFieldBuilder().addBuilder(
            index, nvidia.riva.asr.RivaAsr.WordInfo.getDefaultInstance());
      }
      /**
       * <pre>
       * A list of word-specific information for each recognized word. Only populated
       * if is_final=true
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.WordInfo words = 3;</code>
       */
      public java.util.List<nvidia.riva.asr.RivaAsr.WordInfo.Builder> 
           getWordsBuilderList() {
        return getWordsFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          nvidia.riva.asr.RivaAsr.WordInfo, nvidia.riva.asr.RivaAsr.WordInfo.Builder, nvidia.riva.asr.RivaAsr.WordInfoOrBuilder> 
          getWordsFieldBuilder() {
        if (wordsBuilder_ == null) {
          wordsBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              nvidia.riva.asr.RivaAsr.WordInfo, nvidia.riva.asr.RivaAsr.WordInfo.Builder, nvidia.riva.asr.RivaAsr.WordInfoOrBuilder>(
                  words_,
                  ((bitField0_ & 0x00000004) == 0x00000004),
                  getParentForChildren(),
                  isClean());
          words_ = null;
        }
        return wordsBuilder_;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return this;
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return this;
      }


      // @@protoc_insertion_point(builder_scope:nvidia.riva.asr.SpeechRecognitionAlternative)
    }

    // @@protoc_insertion_point(class_scope:nvidia.riva.asr.SpeechRecognitionAlternative)
    private static final nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative();
    }

    public static nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<SpeechRecognitionAlternative>
        PARSER = new com.google.protobuf.AbstractParser<SpeechRecognitionAlternative>() {
      public SpeechRecognitionAlternative parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new SpeechRecognitionAlternative(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<SpeechRecognitionAlternative> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<SpeechRecognitionAlternative> getParserForType() {
      return PARSER;
    }

    public nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface WordInfoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:nvidia.riva.asr.WordInfo)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * Time offset relative to the beginning of the audio in ms
     * and corresponding to the start of the spoken word.
     * This field is only set if `enable_word_time_offsets=true` and only
     * in the top hypothesis.
     * </pre>
     *
     * <code>optional int32 start_time = 1;</code>
     */
    int getStartTime();

    /**
     * <pre>
     * Time offset relative to the beginning of the audio in ms
     * and corresponding to the end of the spoken word.
     * This field is only set if `enable_word_time_offsets=true` and only
     * in the top hypothesis.
     * </pre>
     *
     * <code>optional int32 end_time = 2;</code>
     */
    int getEndTime();

    /**
     * <pre>
     * The word corresponding to this set of information.
     * </pre>
     *
     * <code>optional string word = 3;</code>
     */
    java.lang.String getWord();
    /**
     * <pre>
     * The word corresponding to this set of information.
     * </pre>
     *
     * <code>optional string word = 3;</code>
     */
    com.google.protobuf.ByteString
        getWordBytes();
  }
  /**
   * <pre>
   * Word-specific information for recognized words.
   * </pre>
   *
   * Protobuf type {@code nvidia.riva.asr.WordInfo}
   */
  public  static final class WordInfo extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:nvidia.riva.asr.WordInfo)
      WordInfoOrBuilder {
    // Use WordInfo.newBuilder() to construct.
    private WordInfo(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private WordInfo() {
      startTime_ = 0;
      endTime_ = 0;
      word_ = "";
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return com.google.protobuf.UnknownFieldSet.getDefaultInstance();
    }
    private WordInfo(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!input.skipField(tag)) {
                done = true;
              }
              break;
            }
            case 8: {

              startTime_ = input.readInt32();
              break;
            }
            case 16: {

              endTime_ = input.readInt32();
              break;
            }
            case 26: {
              java.lang.String s = input.readStringRequireUtf8();

              word_ = s;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return nvidia.riva.asr.RivaAsr.internal_static_nvidia_riva_asr_WordInfo_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return nvidia.riva.asr.RivaAsr.internal_static_nvidia_riva_asr_WordInfo_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              nvidia.riva.asr.RivaAsr.WordInfo.class, nvidia.riva.asr.RivaAsr.WordInfo.Builder.class);
    }

    public static final int START_TIME_FIELD_NUMBER = 1;
    private int startTime_;
    /**
     * <pre>
     * Time offset relative to the beginning of the audio in ms
     * and corresponding to the start of the spoken word.
     * This field is only set if `enable_word_time_offsets=true` and only
     * in the top hypothesis.
     * </pre>
     *
     * <code>optional int32 start_time = 1;</code>
     */
    public int getStartTime() {
      return startTime_;
    }

    public static final int END_TIME_FIELD_NUMBER = 2;
    private int endTime_;
    /**
     * <pre>
     * Time offset relative to the beginning of the audio in ms
     * and corresponding to the end of the spoken word.
     * This field is only set if `enable_word_time_offsets=true` and only
     * in the top hypothesis.
     * </pre>
     *
     * <code>optional int32 end_time = 2;</code>
     */
    public int getEndTime() {
      return endTime_;
    }

    public static final int WORD_FIELD_NUMBER = 3;
    private volatile java.lang.Object word_;
    /**
     * <pre>
     * The word corresponding to this set of information.
     * </pre>
     *
     * <code>optional string word = 3;</code>
     */
    public java.lang.String getWord() {
      java.lang.Object ref = word_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        word_ = s;
        return s;
      }
    }
    /**
     * <pre>
     * The word corresponding to this set of information.
     * </pre>
     *
     * <code>optional string word = 3;</code>
     */
    public com.google.protobuf.ByteString
        getWordBytes() {
      java.lang.Object ref = word_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        word_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (startTime_ != 0) {
        output.writeInt32(1, startTime_);
      }
      if (endTime_ != 0) {
        output.writeInt32(2, endTime_);
      }
      if (!getWordBytes().isEmpty()) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 3, word_);
      }
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (startTime_ != 0) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(1, startTime_);
      }
      if (endTime_ != 0) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(2, endTime_);
      }
      if (!getWordBytes().isEmpty()) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(3, word_);
      }
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof nvidia.riva.asr.RivaAsr.WordInfo)) {
        return super.equals(obj);
      }
      nvidia.riva.asr.RivaAsr.WordInfo other = (nvidia.riva.asr.RivaAsr.WordInfo) obj;

      boolean result = true;
      result = result && (getStartTime()
          == other.getStartTime());
      result = result && (getEndTime()
          == other.getEndTime());
      result = result && getWord()
          .equals(other.getWord());
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      hash = (37 * hash) + START_TIME_FIELD_NUMBER;
      hash = (53 * hash) + getStartTime();
      hash = (37 * hash) + END_TIME_FIELD_NUMBER;
      hash = (53 * hash) + getEndTime();
      hash = (37 * hash) + WORD_FIELD_NUMBER;
      hash = (53 * hash) + getWord().hashCode();
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static nvidia.riva.asr.RivaAsr.WordInfo parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static nvidia.riva.asr.RivaAsr.WordInfo parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static nvidia.riva.asr.RivaAsr.WordInfo parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static nvidia.riva.asr.RivaAsr.WordInfo parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static nvidia.riva.asr.RivaAsr.WordInfo parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static nvidia.riva.asr.RivaAsr.WordInfo parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static nvidia.riva.asr.RivaAsr.WordInfo parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static nvidia.riva.asr.RivaAsr.WordInfo parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static nvidia.riva.asr.RivaAsr.WordInfo parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static nvidia.riva.asr.RivaAsr.WordInfo parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(nvidia.riva.asr.RivaAsr.WordInfo prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     * Word-specific information for recognized words.
     * </pre>
     *
     * Protobuf type {@code nvidia.riva.asr.WordInfo}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:nvidia.riva.asr.WordInfo)
        nvidia.riva.asr.RivaAsr.WordInfoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return nvidia.riva.asr.RivaAsr.internal_static_nvidia_riva_asr_WordInfo_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return nvidia.riva.asr.RivaAsr.internal_static_nvidia_riva_asr_WordInfo_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                nvidia.riva.asr.RivaAsr.WordInfo.class, nvidia.riva.asr.RivaAsr.WordInfo.Builder.class);
      }

      // Construct using nvidia.riva.asr.RivaAsr.WordInfo.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      public Builder clear() {
        super.clear();
        startTime_ = 0;

        endTime_ = 0;

        word_ = "";

        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return nvidia.riva.asr.RivaAsr.internal_static_nvidia_riva_asr_WordInfo_descriptor;
      }

      public nvidia.riva.asr.RivaAsr.WordInfo getDefaultInstanceForType() {
        return nvidia.riva.asr.RivaAsr.WordInfo.getDefaultInstance();
      }

      public nvidia.riva.asr.RivaAsr.WordInfo build() {
        nvidia.riva.asr.RivaAsr.WordInfo result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public nvidia.riva.asr.RivaAsr.WordInfo buildPartial() {
        nvidia.riva.asr.RivaAsr.WordInfo result = new nvidia.riva.asr.RivaAsr.WordInfo(this);
        result.startTime_ = startTime_;
        result.endTime_ = endTime_;
        result.word_ = word_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof nvidia.riva.asr.RivaAsr.WordInfo) {
          return mergeFrom((nvidia.riva.asr.RivaAsr.WordInfo)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(nvidia.riva.asr.RivaAsr.WordInfo other) {
        if (other == nvidia.riva.asr.RivaAsr.WordInfo.getDefaultInstance()) return this;
        if (other.getStartTime() != 0) {
          setStartTime(other.getStartTime());
        }
        if (other.getEndTime() != 0) {
          setEndTime(other.getEndTime());
        }
        if (!other.getWord().isEmpty()) {
          word_ = other.word_;
          onChanged();
        }
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        nvidia.riva.asr.RivaAsr.WordInfo parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (nvidia.riva.asr.RivaAsr.WordInfo) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }

      private int startTime_ ;
      /**
       * <pre>
       * Time offset relative to the beginning of the audio in ms
       * and corresponding to the start of the spoken word.
       * This field is only set if `enable_word_time_offsets=true` and only
       * in the top hypothesis.
       * </pre>
       *
       * <code>optional int32 start_time = 1;</code>
       */
      public int getStartTime() {
        return startTime_;
      }
      /**
       * <pre>
       * Time offset relative to the beginning of the audio in ms
       * and corresponding to the start of the spoken word.
       * This field is only set if `enable_word_time_offsets=true` and only
       * in the top hypothesis.
       * </pre>
       *
       * <code>optional int32 start_time = 1;</code>
       */
      public Builder setStartTime(int value) {
        
        startTime_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Time offset relative to the beginning of the audio in ms
       * and corresponding to the start of the spoken word.
       * This field is only set if `enable_word_time_offsets=true` and only
       * in the top hypothesis.
       * </pre>
       *
       * <code>optional int32 start_time = 1;</code>
       */
      public Builder clearStartTime() {
        
        startTime_ = 0;
        onChanged();
        return this;
      }

      private int endTime_ ;
      /**
       * <pre>
       * Time offset relative to the beginning of the audio in ms
       * and corresponding to the end of the spoken word.
       * This field is only set if `enable_word_time_offsets=true` and only
       * in the top hypothesis.
       * </pre>
       *
       * <code>optional int32 end_time = 2;</code>
       */
      public int getEndTime() {
        return endTime_;
      }
      /**
       * <pre>
       * Time offset relative to the beginning of the audio in ms
       * and corresponding to the end of the spoken word.
       * This field is only set if `enable_word_time_offsets=true` and only
       * in the top hypothesis.
       * </pre>
       *
       * <code>optional int32 end_time = 2;</code>
       */
      public Builder setEndTime(int value) {
        
        endTime_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Time offset relative to the beginning of the audio in ms
       * and corresponding to the end of the spoken word.
       * This field is only set if `enable_word_time_offsets=true` and only
       * in the top hypothesis.
       * </pre>
       *
       * <code>optional int32 end_time = 2;</code>
       */
      public Builder clearEndTime() {
        
        endTime_ = 0;
        onChanged();
        return this;
      }

      private java.lang.Object word_ = "";
      /**
       * <pre>
       * The word corresponding to this set of information.
       * </pre>
       *
       * <code>optional string word = 3;</code>
       */
      public java.lang.String getWord() {
        java.lang.Object ref = word_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          word_ = s;
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <pre>
       * The word corresponding to this set of information.
       * </pre>
       *
       * <code>optional string word = 3;</code>
       */
      public com.google.protobuf.ByteString
          getWordBytes() {
        java.lang.Object ref = word_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          word_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <pre>
       * The word corresponding to this set of information.
       * </pre>
       *
       * <code>optional string word = 3;</code>
       */
      public Builder setWord(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  
        word_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The word corresponding to this set of information.
       * </pre>
       *
       * <code>optional string word = 3;</code>
       */
      public Builder clearWord() {
        
        word_ = getDefaultInstance().getWord();
        onChanged();
        return this;
      }
      /**
       * <pre>
       * The word corresponding to this set of information.
       * </pre>
       *
       * <code>optional string word = 3;</code>
       */
      public Builder setWordBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  checkByteStringIsUtf8(value);
        
        word_ = value;
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return this;
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return this;
      }


      // @@protoc_insertion_point(builder_scope:nvidia.riva.asr.WordInfo)
    }

    // @@protoc_insertion_point(class_scope:nvidia.riva.asr.WordInfo)
    private static final nvidia.riva.asr.RivaAsr.WordInfo DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new nvidia.riva.asr.RivaAsr.WordInfo();
    }

    public static nvidia.riva.asr.RivaAsr.WordInfo getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<WordInfo>
        PARSER = new com.google.protobuf.AbstractParser<WordInfo>() {
      public WordInfo parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new WordInfo(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<WordInfo> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<WordInfo> getParserForType() {
      return PARSER;
    }

    public nvidia.riva.asr.RivaAsr.WordInfo getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface StreamingRecognizeResponseOrBuilder extends
      // @@protoc_insertion_point(interface_extends:nvidia.riva.asr.StreamingRecognizeResponse)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * This repeated list contains the latest transcript(s) corresponding to
     * audio currently being processed.
     * Currently one result is returned, where each result can have multiple
     * alternatives
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.StreamingRecognitionResult results = 1;</code>
     */
    java.util.List<nvidia.riva.asr.RivaAsr.StreamingRecognitionResult> 
        getResultsList();
    /**
     * <pre>
     * This repeated list contains the latest transcript(s) corresponding to
     * audio currently being processed.
     * Currently one result is returned, where each result can have multiple
     * alternatives
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.StreamingRecognitionResult results = 1;</code>
     */
    nvidia.riva.asr.RivaAsr.StreamingRecognitionResult getResults(int index);
    /**
     * <pre>
     * This repeated list contains the latest transcript(s) corresponding to
     * audio currently being processed.
     * Currently one result is returned, where each result can have multiple
     * alternatives
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.StreamingRecognitionResult results = 1;</code>
     */
    int getResultsCount();
    /**
     * <pre>
     * This repeated list contains the latest transcript(s) corresponding to
     * audio currently being processed.
     * Currently one result is returned, where each result can have multiple
     * alternatives
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.StreamingRecognitionResult results = 1;</code>
     */
    java.util.List<? extends nvidia.riva.asr.RivaAsr.StreamingRecognitionResultOrBuilder> 
        getResultsOrBuilderList();
    /**
     * <pre>
     * This repeated list contains the latest transcript(s) corresponding to
     * audio currently being processed.
     * Currently one result is returned, where each result can have multiple
     * alternatives
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.StreamingRecognitionResult results = 1;</code>
     */
    nvidia.riva.asr.RivaAsr.StreamingRecognitionResultOrBuilder getResultsOrBuilder(
        int index);
  }
  /**
   * Protobuf type {@code nvidia.riva.asr.StreamingRecognizeResponse}
   */
  public  static final class StreamingRecognizeResponse extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:nvidia.riva.asr.StreamingRecognizeResponse)
      StreamingRecognizeResponseOrBuilder {
    // Use StreamingRecognizeResponse.newBuilder() to construct.
    private StreamingRecognizeResponse(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private StreamingRecognizeResponse() {
      results_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return com.google.protobuf.UnknownFieldSet.getDefaultInstance();
    }
    private StreamingRecognizeResponse(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!input.skipField(tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              if (!((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
                results_ = new java.util.ArrayList<nvidia.riva.asr.RivaAsr.StreamingRecognitionResult>();
                mutable_bitField0_ |= 0x00000001;
              }
              results_.add(
                  input.readMessage(nvidia.riva.asr.RivaAsr.StreamingRecognitionResult.parser(), extensionRegistry));
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
          results_ = java.util.Collections.unmodifiableList(results_);
        }
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return nvidia.riva.asr.RivaAsr.internal_static_nvidia_riva_asr_StreamingRecognizeResponse_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return nvidia.riva.asr.RivaAsr.internal_static_nvidia_riva_asr_StreamingRecognizeResponse_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              nvidia.riva.asr.RivaAsr.StreamingRecognizeResponse.class, nvidia.riva.asr.RivaAsr.StreamingRecognizeResponse.Builder.class);
    }

    public static final int RESULTS_FIELD_NUMBER = 1;
    private java.util.List<nvidia.riva.asr.RivaAsr.StreamingRecognitionResult> results_;
    /**
     * <pre>
     * This repeated list contains the latest transcript(s) corresponding to
     * audio currently being processed.
     * Currently one result is returned, where each result can have multiple
     * alternatives
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.StreamingRecognitionResult results = 1;</code>
     */
    public java.util.List<nvidia.riva.asr.RivaAsr.StreamingRecognitionResult> getResultsList() {
      return results_;
    }
    /**
     * <pre>
     * This repeated list contains the latest transcript(s) corresponding to
     * audio currently being processed.
     * Currently one result is returned, where each result can have multiple
     * alternatives
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.StreamingRecognitionResult results = 1;</code>
     */
    public java.util.List<? extends nvidia.riva.asr.RivaAsr.StreamingRecognitionResultOrBuilder> 
        getResultsOrBuilderList() {
      return results_;
    }
    /**
     * <pre>
     * This repeated list contains the latest transcript(s) corresponding to
     * audio currently being processed.
     * Currently one result is returned, where each result can have multiple
     * alternatives
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.StreamingRecognitionResult results = 1;</code>
     */
    public int getResultsCount() {
      return results_.size();
    }
    /**
     * <pre>
     * This repeated list contains the latest transcript(s) corresponding to
     * audio currently being processed.
     * Currently one result is returned, where each result can have multiple
     * alternatives
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.StreamingRecognitionResult results = 1;</code>
     */
    public nvidia.riva.asr.RivaAsr.StreamingRecognitionResult getResults(int index) {
      return results_.get(index);
    }
    /**
     * <pre>
     * This repeated list contains the latest transcript(s) corresponding to
     * audio currently being processed.
     * Currently one result is returned, where each result can have multiple
     * alternatives
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.StreamingRecognitionResult results = 1;</code>
     */
    public nvidia.riva.asr.RivaAsr.StreamingRecognitionResultOrBuilder getResultsOrBuilder(
        int index) {
      return results_.get(index);
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < results_.size(); i++) {
        output.writeMessage(1, results_.get(i));
      }
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < results_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, results_.get(i));
      }
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof nvidia.riva.asr.RivaAsr.StreamingRecognizeResponse)) {
        return super.equals(obj);
      }
      nvidia.riva.asr.RivaAsr.StreamingRecognizeResponse other = (nvidia.riva.asr.RivaAsr.StreamingRecognizeResponse) obj;

      boolean result = true;
      result = result && getResultsList()
          .equals(other.getResultsList());
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (getResultsCount() > 0) {
        hash = (37 * hash) + RESULTS_FIELD_NUMBER;
        hash = (53 * hash) + getResultsList().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static nvidia.riva.asr.RivaAsr.StreamingRecognizeResponse parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static nvidia.riva.asr.RivaAsr.StreamingRecognizeResponse parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static nvidia.riva.asr.RivaAsr.StreamingRecognizeResponse parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static nvidia.riva.asr.RivaAsr.StreamingRecognizeResponse parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static nvidia.riva.asr.RivaAsr.StreamingRecognizeResponse parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static nvidia.riva.asr.RivaAsr.StreamingRecognizeResponse parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static nvidia.riva.asr.RivaAsr.StreamingRecognizeResponse parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static nvidia.riva.asr.RivaAsr.StreamingRecognizeResponse parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static nvidia.riva.asr.RivaAsr.StreamingRecognizeResponse parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static nvidia.riva.asr.RivaAsr.StreamingRecognizeResponse parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(nvidia.riva.asr.RivaAsr.StreamingRecognizeResponse prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code nvidia.riva.asr.StreamingRecognizeResponse}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:nvidia.riva.asr.StreamingRecognizeResponse)
        nvidia.riva.asr.RivaAsr.StreamingRecognizeResponseOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return nvidia.riva.asr.RivaAsr.internal_static_nvidia_riva_asr_StreamingRecognizeResponse_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return nvidia.riva.asr.RivaAsr.internal_static_nvidia_riva_asr_StreamingRecognizeResponse_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                nvidia.riva.asr.RivaAsr.StreamingRecognizeResponse.class, nvidia.riva.asr.RivaAsr.StreamingRecognizeResponse.Builder.class);
      }

      // Construct using nvidia.riva.asr.RivaAsr.StreamingRecognizeResponse.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getResultsFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (resultsBuilder_ == null) {
          results_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
        } else {
          resultsBuilder_.clear();
        }
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return nvidia.riva.asr.RivaAsr.internal_static_nvidia_riva_asr_StreamingRecognizeResponse_descriptor;
      }

      public nvidia.riva.asr.RivaAsr.StreamingRecognizeResponse getDefaultInstanceForType() {
        return nvidia.riva.asr.RivaAsr.StreamingRecognizeResponse.getDefaultInstance();
      }

      public nvidia.riva.asr.RivaAsr.StreamingRecognizeResponse build() {
        nvidia.riva.asr.RivaAsr.StreamingRecognizeResponse result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public nvidia.riva.asr.RivaAsr.StreamingRecognizeResponse buildPartial() {
        nvidia.riva.asr.RivaAsr.StreamingRecognizeResponse result = new nvidia.riva.asr.RivaAsr.StreamingRecognizeResponse(this);
        int from_bitField0_ = bitField0_;
        if (resultsBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001)) {
            results_ = java.util.Collections.unmodifiableList(results_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.results_ = results_;
        } else {
          result.results_ = resultsBuilder_.build();
        }
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof nvidia.riva.asr.RivaAsr.StreamingRecognizeResponse) {
          return mergeFrom((nvidia.riva.asr.RivaAsr.StreamingRecognizeResponse)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(nvidia.riva.asr.RivaAsr.StreamingRecognizeResponse other) {
        if (other == nvidia.riva.asr.RivaAsr.StreamingRecognizeResponse.getDefaultInstance()) return this;
        if (resultsBuilder_ == null) {
          if (!other.results_.isEmpty()) {
            if (results_.isEmpty()) {
              results_ = other.results_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureResultsIsMutable();
              results_.addAll(other.results_);
            }
            onChanged();
          }
        } else {
          if (!other.results_.isEmpty()) {
            if (resultsBuilder_.isEmpty()) {
              resultsBuilder_.dispose();
              resultsBuilder_ = null;
              results_ = other.results_;
              bitField0_ = (bitField0_ & ~0x00000001);
              resultsBuilder_ = 
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getResultsFieldBuilder() : null;
            } else {
              resultsBuilder_.addAllMessages(other.results_);
            }
          }
        }
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        nvidia.riva.asr.RivaAsr.StreamingRecognizeResponse parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (nvidia.riva.asr.RivaAsr.StreamingRecognizeResponse) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.util.List<nvidia.riva.asr.RivaAsr.StreamingRecognitionResult> results_ =
        java.util.Collections.emptyList();
      private void ensureResultsIsMutable() {
        if (!((bitField0_ & 0x00000001) == 0x00000001)) {
          results_ = new java.util.ArrayList<nvidia.riva.asr.RivaAsr.StreamingRecognitionResult>(results_);
          bitField0_ |= 0x00000001;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          nvidia.riva.asr.RivaAsr.StreamingRecognitionResult, nvidia.riva.asr.RivaAsr.StreamingRecognitionResult.Builder, nvidia.riva.asr.RivaAsr.StreamingRecognitionResultOrBuilder> resultsBuilder_;

      /**
       * <pre>
       * This repeated list contains the latest transcript(s) corresponding to
       * audio currently being processed.
       * Currently one result is returned, where each result can have multiple
       * alternatives
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.StreamingRecognitionResult results = 1;</code>
       */
      public java.util.List<nvidia.riva.asr.RivaAsr.StreamingRecognitionResult> getResultsList() {
        if (resultsBuilder_ == null) {
          return java.util.Collections.unmodifiableList(results_);
        } else {
          return resultsBuilder_.getMessageList();
        }
      }
      /**
       * <pre>
       * This repeated list contains the latest transcript(s) corresponding to
       * audio currently being processed.
       * Currently one result is returned, where each result can have multiple
       * alternatives
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.StreamingRecognitionResult results = 1;</code>
       */
      public int getResultsCount() {
        if (resultsBuilder_ == null) {
          return results_.size();
        } else {
          return resultsBuilder_.getCount();
        }
      }
      /**
       * <pre>
       * This repeated list contains the latest transcript(s) corresponding to
       * audio currently being processed.
       * Currently one result is returned, where each result can have multiple
       * alternatives
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.StreamingRecognitionResult results = 1;</code>
       */
      public nvidia.riva.asr.RivaAsr.StreamingRecognitionResult getResults(int index) {
        if (resultsBuilder_ == null) {
          return results_.get(index);
        } else {
          return resultsBuilder_.getMessage(index);
        }
      }
      /**
       * <pre>
       * This repeated list contains the latest transcript(s) corresponding to
       * audio currently being processed.
       * Currently one result is returned, where each result can have multiple
       * alternatives
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.StreamingRecognitionResult results = 1;</code>
       */
      public Builder setResults(
          int index, nvidia.riva.asr.RivaAsr.StreamingRecognitionResult value) {
        if (resultsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureResultsIsMutable();
          results_.set(index, value);
          onChanged();
        } else {
          resultsBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <pre>
       * This repeated list contains the latest transcript(s) corresponding to
       * audio currently being processed.
       * Currently one result is returned, where each result can have multiple
       * alternatives
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.StreamingRecognitionResult results = 1;</code>
       */
      public Builder setResults(
          int index, nvidia.riva.asr.RivaAsr.StreamingRecognitionResult.Builder builderForValue) {
        if (resultsBuilder_ == null) {
          ensureResultsIsMutable();
          results_.set(index, builderForValue.build());
          onChanged();
        } else {
          resultsBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       * This repeated list contains the latest transcript(s) corresponding to
       * audio currently being processed.
       * Currently one result is returned, where each result can have multiple
       * alternatives
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.StreamingRecognitionResult results = 1;</code>
       */
      public Builder addResults(nvidia.riva.asr.RivaAsr.StreamingRecognitionResult value) {
        if (resultsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureResultsIsMutable();
          results_.add(value);
          onChanged();
        } else {
          resultsBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <pre>
       * This repeated list contains the latest transcript(s) corresponding to
       * audio currently being processed.
       * Currently one result is returned, where each result can have multiple
       * alternatives
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.StreamingRecognitionResult results = 1;</code>
       */
      public Builder addResults(
          int index, nvidia.riva.asr.RivaAsr.StreamingRecognitionResult value) {
        if (resultsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureResultsIsMutable();
          results_.add(index, value);
          onChanged();
        } else {
          resultsBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <pre>
       * This repeated list contains the latest transcript(s) corresponding to
       * audio currently being processed.
       * Currently one result is returned, where each result can have multiple
       * alternatives
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.StreamingRecognitionResult results = 1;</code>
       */
      public Builder addResults(
          nvidia.riva.asr.RivaAsr.StreamingRecognitionResult.Builder builderForValue) {
        if (resultsBuilder_ == null) {
          ensureResultsIsMutable();
          results_.add(builderForValue.build());
          onChanged();
        } else {
          resultsBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       * This repeated list contains the latest transcript(s) corresponding to
       * audio currently being processed.
       * Currently one result is returned, where each result can have multiple
       * alternatives
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.StreamingRecognitionResult results = 1;</code>
       */
      public Builder addResults(
          int index, nvidia.riva.asr.RivaAsr.StreamingRecognitionResult.Builder builderForValue) {
        if (resultsBuilder_ == null) {
          ensureResultsIsMutable();
          results_.add(index, builderForValue.build());
          onChanged();
        } else {
          resultsBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       * This repeated list contains the latest transcript(s) corresponding to
       * audio currently being processed.
       * Currently one result is returned, where each result can have multiple
       * alternatives
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.StreamingRecognitionResult results = 1;</code>
       */
      public Builder addAllResults(
          java.lang.Iterable<? extends nvidia.riva.asr.RivaAsr.StreamingRecognitionResult> values) {
        if (resultsBuilder_ == null) {
          ensureResultsIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, results_);
          onChanged();
        } else {
          resultsBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <pre>
       * This repeated list contains the latest transcript(s) corresponding to
       * audio currently being processed.
       * Currently one result is returned, where each result can have multiple
       * alternatives
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.StreamingRecognitionResult results = 1;</code>
       */
      public Builder clearResults() {
        if (resultsBuilder_ == null) {
          results_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          resultsBuilder_.clear();
        }
        return this;
      }
      /**
       * <pre>
       * This repeated list contains the latest transcript(s) corresponding to
       * audio currently being processed.
       * Currently one result is returned, where each result can have multiple
       * alternatives
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.StreamingRecognitionResult results = 1;</code>
       */
      public Builder removeResults(int index) {
        if (resultsBuilder_ == null) {
          ensureResultsIsMutable();
          results_.remove(index);
          onChanged();
        } else {
          resultsBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <pre>
       * This repeated list contains the latest transcript(s) corresponding to
       * audio currently being processed.
       * Currently one result is returned, where each result can have multiple
       * alternatives
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.StreamingRecognitionResult results = 1;</code>
       */
      public nvidia.riva.asr.RivaAsr.StreamingRecognitionResult.Builder getResultsBuilder(
          int index) {
        return getResultsFieldBuilder().getBuilder(index);
      }
      /**
       * <pre>
       * This repeated list contains the latest transcript(s) corresponding to
       * audio currently being processed.
       * Currently one result is returned, where each result can have multiple
       * alternatives
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.StreamingRecognitionResult results = 1;</code>
       */
      public nvidia.riva.asr.RivaAsr.StreamingRecognitionResultOrBuilder getResultsOrBuilder(
          int index) {
        if (resultsBuilder_ == null) {
          return results_.get(index);  } else {
          return resultsBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <pre>
       * This repeated list contains the latest transcript(s) corresponding to
       * audio currently being processed.
       * Currently one result is returned, where each result can have multiple
       * alternatives
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.StreamingRecognitionResult results = 1;</code>
       */
      public java.util.List<? extends nvidia.riva.asr.RivaAsr.StreamingRecognitionResultOrBuilder> 
           getResultsOrBuilderList() {
        if (resultsBuilder_ != null) {
          return resultsBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(results_);
        }
      }
      /**
       * <pre>
       * This repeated list contains the latest transcript(s) corresponding to
       * audio currently being processed.
       * Currently one result is returned, where each result can have multiple
       * alternatives
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.StreamingRecognitionResult results = 1;</code>
       */
      public nvidia.riva.asr.RivaAsr.StreamingRecognitionResult.Builder addResultsBuilder() {
        return getResultsFieldBuilder().addBuilder(
            nvidia.riva.asr.RivaAsr.StreamingRecognitionResult.getDefaultInstance());
      }
      /**
       * <pre>
       * This repeated list contains the latest transcript(s) corresponding to
       * audio currently being processed.
       * Currently one result is returned, where each result can have multiple
       * alternatives
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.StreamingRecognitionResult results = 1;</code>
       */
      public nvidia.riva.asr.RivaAsr.StreamingRecognitionResult.Builder addResultsBuilder(
          int index) {
        return getResultsFieldBuilder().addBuilder(
            index, nvidia.riva.asr.RivaAsr.StreamingRecognitionResult.getDefaultInstance());
      }
      /**
       * <pre>
       * This repeated list contains the latest transcript(s) corresponding to
       * audio currently being processed.
       * Currently one result is returned, where each result can have multiple
       * alternatives
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.StreamingRecognitionResult results = 1;</code>
       */
      public java.util.List<nvidia.riva.asr.RivaAsr.StreamingRecognitionResult.Builder> 
           getResultsBuilderList() {
        return getResultsFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          nvidia.riva.asr.RivaAsr.StreamingRecognitionResult, nvidia.riva.asr.RivaAsr.StreamingRecognitionResult.Builder, nvidia.riva.asr.RivaAsr.StreamingRecognitionResultOrBuilder> 
          getResultsFieldBuilder() {
        if (resultsBuilder_ == null) {
          resultsBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              nvidia.riva.asr.RivaAsr.StreamingRecognitionResult, nvidia.riva.asr.RivaAsr.StreamingRecognitionResult.Builder, nvidia.riva.asr.RivaAsr.StreamingRecognitionResultOrBuilder>(
                  results_,
                  ((bitField0_ & 0x00000001) == 0x00000001),
                  getParentForChildren(),
                  isClean());
          results_ = null;
        }
        return resultsBuilder_;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return this;
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return this;
      }


      // @@protoc_insertion_point(builder_scope:nvidia.riva.asr.StreamingRecognizeResponse)
    }

    // @@protoc_insertion_point(class_scope:nvidia.riva.asr.StreamingRecognizeResponse)
    private static final nvidia.riva.asr.RivaAsr.StreamingRecognizeResponse DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new nvidia.riva.asr.RivaAsr.StreamingRecognizeResponse();
    }

    public static nvidia.riva.asr.RivaAsr.StreamingRecognizeResponse getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<StreamingRecognizeResponse>
        PARSER = new com.google.protobuf.AbstractParser<StreamingRecognizeResponse>() {
      public StreamingRecognizeResponse parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new StreamingRecognizeResponse(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<StreamingRecognizeResponse> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<StreamingRecognizeResponse> getParserForType() {
      return PARSER;
    }

    public nvidia.riva.asr.RivaAsr.StreamingRecognizeResponse getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface StreamingRecognitionResultOrBuilder extends
      // @@protoc_insertion_point(interface_extends:nvidia.riva.asr.StreamingRecognitionResult)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <pre>
     * May contain one or more recognition hypotheses (up to the
     * maximum specified in `max_alternatives`).
     * These alternatives are ordered in terms of accuracy, with the top (first)
     * alternative being the most probable, as ranked by the recognizer.
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
     */
    java.util.List<nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative> 
        getAlternativesList();
    /**
     * <pre>
     * May contain one or more recognition hypotheses (up to the
     * maximum specified in `max_alternatives`).
     * These alternatives are ordered in terms of accuracy, with the top (first)
     * alternative being the most probable, as ranked by the recognizer.
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
     */
    nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative getAlternatives(int index);
    /**
     * <pre>
     * May contain one or more recognition hypotheses (up to the
     * maximum specified in `max_alternatives`).
     * These alternatives are ordered in terms of accuracy, with the top (first)
     * alternative being the most probable, as ranked by the recognizer.
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
     */
    int getAlternativesCount();
    /**
     * <pre>
     * May contain one or more recognition hypotheses (up to the
     * maximum specified in `max_alternatives`).
     * These alternatives are ordered in terms of accuracy, with the top (first)
     * alternative being the most probable, as ranked by the recognizer.
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
     */
    java.util.List<? extends nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternativeOrBuilder> 
        getAlternativesOrBuilderList();
    /**
     * <pre>
     * May contain one or more recognition hypotheses (up to the
     * maximum specified in `max_alternatives`).
     * These alternatives are ordered in terms of accuracy, with the top (first)
     * alternative being the most probable, as ranked by the recognizer.
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
     */
    nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternativeOrBuilder getAlternativesOrBuilder(
        int index);

    /**
     * <pre>
     * If `false`, this `StreamingRecognitionResult` represents an
     * interim result that may change. If `true`, this is the final time the
     * speech service will return this particular `StreamingRecognitionResult`,
     * the recognizer will not return any further hypotheses for this portion of
     * the transcript and corresponding audio.
     * </pre>
     *
     * <code>optional bool is_final = 2;</code>
     */
    boolean getIsFinal();

    /**
     * <pre>
     * An estimate of the likelihood that the recognizer will not
     * change its guess about this interim result. Values range from 0.0
     * (completely unstable) to 1.0 (completely stable).
     * This field is only provided for interim results (`is_final=false`).
     * The default of 0.0 is a sentinel value indicating `stability` was not set.
     * </pre>
     *
     * <code>optional float stability = 3;</code>
     */
    float getStability();

    /**
     * <pre>
     * For multi-channel audio, this is the channel number corresponding to the
     * recognized result for the audio from that channel.
     * For audio_channel_count = N, its output values can range from '1' to 'N'.
     * </pre>
     *
     * <code>optional int32 channel_tag = 5;</code>
     */
    int getChannelTag();

    /**
     * <pre>
     * Length of audio processed so far in seconds
     * </pre>
     *
     * <code>optional float audio_processed = 6;</code>
     */
    float getAudioProcessed();
  }
  /**
   * <pre>
   * A streaming speech recognition result corresponding to a portion of the audio
   * that is currently being processed.
   * </pre>
   *
   * Protobuf type {@code nvidia.riva.asr.StreamingRecognitionResult}
   */
  public  static final class StreamingRecognitionResult extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:nvidia.riva.asr.StreamingRecognitionResult)
      StreamingRecognitionResultOrBuilder {
    // Use StreamingRecognitionResult.newBuilder() to construct.
    private StreamingRecognitionResult(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private StreamingRecognitionResult() {
      alternatives_ = java.util.Collections.emptyList();
      isFinal_ = false;
      stability_ = 0F;
      channelTag_ = 0;
      audioProcessed_ = 0F;
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return com.google.protobuf.UnknownFieldSet.getDefaultInstance();
    }
    private StreamingRecognitionResult(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!input.skipField(tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              if (!((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
                alternatives_ = new java.util.ArrayList<nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative>();
                mutable_bitField0_ |= 0x00000001;
              }
              alternatives_.add(
                  input.readMessage(nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative.parser(), extensionRegistry));
              break;
            }
            case 16: {

              isFinal_ = input.readBool();
              break;
            }
            case 29: {

              stability_ = input.readFloat();
              break;
            }
            case 40: {

              channelTag_ = input.readInt32();
              break;
            }
            case 53: {

              audioProcessed_ = input.readFloat();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
          alternatives_ = java.util.Collections.unmodifiableList(alternatives_);
        }
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return nvidia.riva.asr.RivaAsr.internal_static_nvidia_riva_asr_StreamingRecognitionResult_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return nvidia.riva.asr.RivaAsr.internal_static_nvidia_riva_asr_StreamingRecognitionResult_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              nvidia.riva.asr.RivaAsr.StreamingRecognitionResult.class, nvidia.riva.asr.RivaAsr.StreamingRecognitionResult.Builder.class);
    }

    private int bitField0_;
    public static final int ALTERNATIVES_FIELD_NUMBER = 1;
    private java.util.List<nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative> alternatives_;
    /**
     * <pre>
     * May contain one or more recognition hypotheses (up to the
     * maximum specified in `max_alternatives`).
     * These alternatives are ordered in terms of accuracy, with the top (first)
     * alternative being the most probable, as ranked by the recognizer.
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
     */
    public java.util.List<nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative> getAlternativesList() {
      return alternatives_;
    }
    /**
     * <pre>
     * May contain one or more recognition hypotheses (up to the
     * maximum specified in `max_alternatives`).
     * These alternatives are ordered in terms of accuracy, with the top (first)
     * alternative being the most probable, as ranked by the recognizer.
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
     */
    public java.util.List<? extends nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternativeOrBuilder> 
        getAlternativesOrBuilderList() {
      return alternatives_;
    }
    /**
     * <pre>
     * May contain one or more recognition hypotheses (up to the
     * maximum specified in `max_alternatives`).
     * These alternatives are ordered in terms of accuracy, with the top (first)
     * alternative being the most probable, as ranked by the recognizer.
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
     */
    public int getAlternativesCount() {
      return alternatives_.size();
    }
    /**
     * <pre>
     * May contain one or more recognition hypotheses (up to the
     * maximum specified in `max_alternatives`).
     * These alternatives are ordered in terms of accuracy, with the top (first)
     * alternative being the most probable, as ranked by the recognizer.
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
     */
    public nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative getAlternatives(int index) {
      return alternatives_.get(index);
    }
    /**
     * <pre>
     * May contain one or more recognition hypotheses (up to the
     * maximum specified in `max_alternatives`).
     * These alternatives are ordered in terms of accuracy, with the top (first)
     * alternative being the most probable, as ranked by the recognizer.
     * </pre>
     *
     * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
     */
    public nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternativeOrBuilder getAlternativesOrBuilder(
        int index) {
      return alternatives_.get(index);
    }

    public static final int IS_FINAL_FIELD_NUMBER = 2;
    private boolean isFinal_;
    /**
     * <pre>
     * If `false`, this `StreamingRecognitionResult` represents an
     * interim result that may change. If `true`, this is the final time the
     * speech service will return this particular `StreamingRecognitionResult`,
     * the recognizer will not return any further hypotheses for this portion of
     * the transcript and corresponding audio.
     * </pre>
     *
     * <code>optional bool is_final = 2;</code>
     */
    public boolean getIsFinal() {
      return isFinal_;
    }

    public static final int STABILITY_FIELD_NUMBER = 3;
    private float stability_;
    /**
     * <pre>
     * An estimate of the likelihood that the recognizer will not
     * change its guess about this interim result. Values range from 0.0
     * (completely unstable) to 1.0 (completely stable).
     * This field is only provided for interim results (`is_final=false`).
     * The default of 0.0 is a sentinel value indicating `stability` was not set.
     * </pre>
     *
     * <code>optional float stability = 3;</code>
     */
    public float getStability() {
      return stability_;
    }

    public static final int CHANNEL_TAG_FIELD_NUMBER = 5;
    private int channelTag_;
    /**
     * <pre>
     * For multi-channel audio, this is the channel number corresponding to the
     * recognized result for the audio from that channel.
     * For audio_channel_count = N, its output values can range from '1' to 'N'.
     * </pre>
     *
     * <code>optional int32 channel_tag = 5;</code>
     */
    public int getChannelTag() {
      return channelTag_;
    }

    public static final int AUDIO_PROCESSED_FIELD_NUMBER = 6;
    private float audioProcessed_;
    /**
     * <pre>
     * Length of audio processed so far in seconds
     * </pre>
     *
     * <code>optional float audio_processed = 6;</code>
     */
    public float getAudioProcessed() {
      return audioProcessed_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < alternatives_.size(); i++) {
        output.writeMessage(1, alternatives_.get(i));
      }
      if (isFinal_ != false) {
        output.writeBool(2, isFinal_);
      }
      if (stability_ != 0F) {
        output.writeFloat(3, stability_);
      }
      if (channelTag_ != 0) {
        output.writeInt32(5, channelTag_);
      }
      if (audioProcessed_ != 0F) {
        output.writeFloat(6, audioProcessed_);
      }
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < alternatives_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, alternatives_.get(i));
      }
      if (isFinal_ != false) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(2, isFinal_);
      }
      if (stability_ != 0F) {
        size += com.google.protobuf.CodedOutputStream
          .computeFloatSize(3, stability_);
      }
      if (channelTag_ != 0) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(5, channelTag_);
      }
      if (audioProcessed_ != 0F) {
        size += com.google.protobuf.CodedOutputStream
          .computeFloatSize(6, audioProcessed_);
      }
      memoizedSize = size;
      return size;
    }

    private static final long serialVersionUID = 0L;
    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof nvidia.riva.asr.RivaAsr.StreamingRecognitionResult)) {
        return super.equals(obj);
      }
      nvidia.riva.asr.RivaAsr.StreamingRecognitionResult other = (nvidia.riva.asr.RivaAsr.StreamingRecognitionResult) obj;

      boolean result = true;
      result = result && getAlternativesList()
          .equals(other.getAlternativesList());
      result = result && (getIsFinal()
          == other.getIsFinal());
      result = result && (
          java.lang.Float.floatToIntBits(getStability())
          == java.lang.Float.floatToIntBits(
              other.getStability()));
      result = result && (getChannelTag()
          == other.getChannelTag());
      result = result && (
          java.lang.Float.floatToIntBits(getAudioProcessed())
          == java.lang.Float.floatToIntBits(
              other.getAudioProcessed()));
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptorForType().hashCode();
      if (getAlternativesCount() > 0) {
        hash = (37 * hash) + ALTERNATIVES_FIELD_NUMBER;
        hash = (53 * hash) + getAlternativesList().hashCode();
      }
      hash = (37 * hash) + IS_FINAL_FIELD_NUMBER;
      hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
          getIsFinal());
      hash = (37 * hash) + STABILITY_FIELD_NUMBER;
      hash = (53 * hash) + java.lang.Float.floatToIntBits(
          getStability());
      hash = (37 * hash) + CHANNEL_TAG_FIELD_NUMBER;
      hash = (53 * hash) + getChannelTag();
      hash = (37 * hash) + AUDIO_PROCESSED_FIELD_NUMBER;
      hash = (53 * hash) + java.lang.Float.floatToIntBits(
          getAudioProcessed());
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static nvidia.riva.asr.RivaAsr.StreamingRecognitionResult parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static nvidia.riva.asr.RivaAsr.StreamingRecognitionResult parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static nvidia.riva.asr.RivaAsr.StreamingRecognitionResult parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static nvidia.riva.asr.RivaAsr.StreamingRecognitionResult parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static nvidia.riva.asr.RivaAsr.StreamingRecognitionResult parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static nvidia.riva.asr.RivaAsr.StreamingRecognitionResult parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static nvidia.riva.asr.RivaAsr.StreamingRecognitionResult parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static nvidia.riva.asr.RivaAsr.StreamingRecognitionResult parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static nvidia.riva.asr.RivaAsr.StreamingRecognitionResult parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static nvidia.riva.asr.RivaAsr.StreamingRecognitionResult parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(nvidia.riva.asr.RivaAsr.StreamingRecognitionResult prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     * A streaming speech recognition result corresponding to a portion of the audio
     * that is currently being processed.
     * </pre>
     *
     * Protobuf type {@code nvidia.riva.asr.StreamingRecognitionResult}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:nvidia.riva.asr.StreamingRecognitionResult)
        nvidia.riva.asr.RivaAsr.StreamingRecognitionResultOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return nvidia.riva.asr.RivaAsr.internal_static_nvidia_riva_asr_StreamingRecognitionResult_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return nvidia.riva.asr.RivaAsr.internal_static_nvidia_riva_asr_StreamingRecognitionResult_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                nvidia.riva.asr.RivaAsr.StreamingRecognitionResult.class, nvidia.riva.asr.RivaAsr.StreamingRecognitionResult.Builder.class);
      }

      // Construct using nvidia.riva.asr.RivaAsr.StreamingRecognitionResult.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getAlternativesFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (alternativesBuilder_ == null) {
          alternatives_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
        } else {
          alternativesBuilder_.clear();
        }
        isFinal_ = false;

        stability_ = 0F;

        channelTag_ = 0;

        audioProcessed_ = 0F;

        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return nvidia.riva.asr.RivaAsr.internal_static_nvidia_riva_asr_StreamingRecognitionResult_descriptor;
      }

      public nvidia.riva.asr.RivaAsr.StreamingRecognitionResult getDefaultInstanceForType() {
        return nvidia.riva.asr.RivaAsr.StreamingRecognitionResult.getDefaultInstance();
      }

      public nvidia.riva.asr.RivaAsr.StreamingRecognitionResult build() {
        nvidia.riva.asr.RivaAsr.StreamingRecognitionResult result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public nvidia.riva.asr.RivaAsr.StreamingRecognitionResult buildPartial() {
        nvidia.riva.asr.RivaAsr.StreamingRecognitionResult result = new nvidia.riva.asr.RivaAsr.StreamingRecognitionResult(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (alternativesBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001)) {
            alternatives_ = java.util.Collections.unmodifiableList(alternatives_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.alternatives_ = alternatives_;
        } else {
          result.alternatives_ = alternativesBuilder_.build();
        }
        result.isFinal_ = isFinal_;
        result.stability_ = stability_;
        result.channelTag_ = channelTag_;
        result.audioProcessed_ = audioProcessed_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof nvidia.riva.asr.RivaAsr.StreamingRecognitionResult) {
          return mergeFrom((nvidia.riva.asr.RivaAsr.StreamingRecognitionResult)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(nvidia.riva.asr.RivaAsr.StreamingRecognitionResult other) {
        if (other == nvidia.riva.asr.RivaAsr.StreamingRecognitionResult.getDefaultInstance()) return this;
        if (alternativesBuilder_ == null) {
          if (!other.alternatives_.isEmpty()) {
            if (alternatives_.isEmpty()) {
              alternatives_ = other.alternatives_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureAlternativesIsMutable();
              alternatives_.addAll(other.alternatives_);
            }
            onChanged();
          }
        } else {
          if (!other.alternatives_.isEmpty()) {
            if (alternativesBuilder_.isEmpty()) {
              alternativesBuilder_.dispose();
              alternativesBuilder_ = null;
              alternatives_ = other.alternatives_;
              bitField0_ = (bitField0_ & ~0x00000001);
              alternativesBuilder_ = 
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getAlternativesFieldBuilder() : null;
            } else {
              alternativesBuilder_.addAllMessages(other.alternatives_);
            }
          }
        }
        if (other.getIsFinal() != false) {
          setIsFinal(other.getIsFinal());
        }
        if (other.getStability() != 0F) {
          setStability(other.getStability());
        }
        if (other.getChannelTag() != 0) {
          setChannelTag(other.getChannelTag());
        }
        if (other.getAudioProcessed() != 0F) {
          setAudioProcessed(other.getAudioProcessed());
        }
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        nvidia.riva.asr.RivaAsr.StreamingRecognitionResult parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (nvidia.riva.asr.RivaAsr.StreamingRecognitionResult) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.util.List<nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative> alternatives_ =
        java.util.Collections.emptyList();
      private void ensureAlternativesIsMutable() {
        if (!((bitField0_ & 0x00000001) == 0x00000001)) {
          alternatives_ = new java.util.ArrayList<nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative>(alternatives_);
          bitField0_ |= 0x00000001;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative, nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative.Builder, nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternativeOrBuilder> alternativesBuilder_;

      /**
       * <pre>
       * May contain one or more recognition hypotheses (up to the
       * maximum specified in `max_alternatives`).
       * These alternatives are ordered in terms of accuracy, with the top (first)
       * alternative being the most probable, as ranked by the recognizer.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
       */
      public java.util.List<nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative> getAlternativesList() {
        if (alternativesBuilder_ == null) {
          return java.util.Collections.unmodifiableList(alternatives_);
        } else {
          return alternativesBuilder_.getMessageList();
        }
      }
      /**
       * <pre>
       * May contain one or more recognition hypotheses (up to the
       * maximum specified in `max_alternatives`).
       * These alternatives are ordered in terms of accuracy, with the top (first)
       * alternative being the most probable, as ranked by the recognizer.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
       */
      public int getAlternativesCount() {
        if (alternativesBuilder_ == null) {
          return alternatives_.size();
        } else {
          return alternativesBuilder_.getCount();
        }
      }
      /**
       * <pre>
       * May contain one or more recognition hypotheses (up to the
       * maximum specified in `max_alternatives`).
       * These alternatives are ordered in terms of accuracy, with the top (first)
       * alternative being the most probable, as ranked by the recognizer.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
       */
      public nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative getAlternatives(int index) {
        if (alternativesBuilder_ == null) {
          return alternatives_.get(index);
        } else {
          return alternativesBuilder_.getMessage(index);
        }
      }
      /**
       * <pre>
       * May contain one or more recognition hypotheses (up to the
       * maximum specified in `max_alternatives`).
       * These alternatives are ordered in terms of accuracy, with the top (first)
       * alternative being the most probable, as ranked by the recognizer.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
       */
      public Builder setAlternatives(
          int index, nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative value) {
        if (alternativesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureAlternativesIsMutable();
          alternatives_.set(index, value);
          onChanged();
        } else {
          alternativesBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <pre>
       * May contain one or more recognition hypotheses (up to the
       * maximum specified in `max_alternatives`).
       * These alternatives are ordered in terms of accuracy, with the top (first)
       * alternative being the most probable, as ranked by the recognizer.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
       */
      public Builder setAlternatives(
          int index, nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative.Builder builderForValue) {
        if (alternativesBuilder_ == null) {
          ensureAlternativesIsMutable();
          alternatives_.set(index, builderForValue.build());
          onChanged();
        } else {
          alternativesBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       * May contain one or more recognition hypotheses (up to the
       * maximum specified in `max_alternatives`).
       * These alternatives are ordered in terms of accuracy, with the top (first)
       * alternative being the most probable, as ranked by the recognizer.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
       */
      public Builder addAlternatives(nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative value) {
        if (alternativesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureAlternativesIsMutable();
          alternatives_.add(value);
          onChanged();
        } else {
          alternativesBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <pre>
       * May contain one or more recognition hypotheses (up to the
       * maximum specified in `max_alternatives`).
       * These alternatives are ordered in terms of accuracy, with the top (first)
       * alternative being the most probable, as ranked by the recognizer.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
       */
      public Builder addAlternatives(
          int index, nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative value) {
        if (alternativesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureAlternativesIsMutable();
          alternatives_.add(index, value);
          onChanged();
        } else {
          alternativesBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <pre>
       * May contain one or more recognition hypotheses (up to the
       * maximum specified in `max_alternatives`).
       * These alternatives are ordered in terms of accuracy, with the top (first)
       * alternative being the most probable, as ranked by the recognizer.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
       */
      public Builder addAlternatives(
          nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative.Builder builderForValue) {
        if (alternativesBuilder_ == null) {
          ensureAlternativesIsMutable();
          alternatives_.add(builderForValue.build());
          onChanged();
        } else {
          alternativesBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       * May contain one or more recognition hypotheses (up to the
       * maximum specified in `max_alternatives`).
       * These alternatives are ordered in terms of accuracy, with the top (first)
       * alternative being the most probable, as ranked by the recognizer.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
       */
      public Builder addAlternatives(
          int index, nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative.Builder builderForValue) {
        if (alternativesBuilder_ == null) {
          ensureAlternativesIsMutable();
          alternatives_.add(index, builderForValue.build());
          onChanged();
        } else {
          alternativesBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <pre>
       * May contain one or more recognition hypotheses (up to the
       * maximum specified in `max_alternatives`).
       * These alternatives are ordered in terms of accuracy, with the top (first)
       * alternative being the most probable, as ranked by the recognizer.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
       */
      public Builder addAllAlternatives(
          java.lang.Iterable<? extends nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative> values) {
        if (alternativesBuilder_ == null) {
          ensureAlternativesIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, alternatives_);
          onChanged();
        } else {
          alternativesBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <pre>
       * May contain one or more recognition hypotheses (up to the
       * maximum specified in `max_alternatives`).
       * These alternatives are ordered in terms of accuracy, with the top (first)
       * alternative being the most probable, as ranked by the recognizer.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
       */
      public Builder clearAlternatives() {
        if (alternativesBuilder_ == null) {
          alternatives_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          alternativesBuilder_.clear();
        }
        return this;
      }
      /**
       * <pre>
       * May contain one or more recognition hypotheses (up to the
       * maximum specified in `max_alternatives`).
       * These alternatives are ordered in terms of accuracy, with the top (first)
       * alternative being the most probable, as ranked by the recognizer.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
       */
      public Builder removeAlternatives(int index) {
        if (alternativesBuilder_ == null) {
          ensureAlternativesIsMutable();
          alternatives_.remove(index);
          onChanged();
        } else {
          alternativesBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <pre>
       * May contain one or more recognition hypotheses (up to the
       * maximum specified in `max_alternatives`).
       * These alternatives are ordered in terms of accuracy, with the top (first)
       * alternative being the most probable, as ranked by the recognizer.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
       */
      public nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative.Builder getAlternativesBuilder(
          int index) {
        return getAlternativesFieldBuilder().getBuilder(index);
      }
      /**
       * <pre>
       * May contain one or more recognition hypotheses (up to the
       * maximum specified in `max_alternatives`).
       * These alternatives are ordered in terms of accuracy, with the top (first)
       * alternative being the most probable, as ranked by the recognizer.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
       */
      public nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternativeOrBuilder getAlternativesOrBuilder(
          int index) {
        if (alternativesBuilder_ == null) {
          return alternatives_.get(index);  } else {
          return alternativesBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <pre>
       * May contain one or more recognition hypotheses (up to the
       * maximum specified in `max_alternatives`).
       * These alternatives are ordered in terms of accuracy, with the top (first)
       * alternative being the most probable, as ranked by the recognizer.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
       */
      public java.util.List<? extends nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternativeOrBuilder> 
           getAlternativesOrBuilderList() {
        if (alternativesBuilder_ != null) {
          return alternativesBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(alternatives_);
        }
      }
      /**
       * <pre>
       * May contain one or more recognition hypotheses (up to the
       * maximum specified in `max_alternatives`).
       * These alternatives are ordered in terms of accuracy, with the top (first)
       * alternative being the most probable, as ranked by the recognizer.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
       */
      public nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative.Builder addAlternativesBuilder() {
        return getAlternativesFieldBuilder().addBuilder(
            nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative.getDefaultInstance());
      }
      /**
       * <pre>
       * May contain one or more recognition hypotheses (up to the
       * maximum specified in `max_alternatives`).
       * These alternatives are ordered in terms of accuracy, with the top (first)
       * alternative being the most probable, as ranked by the recognizer.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
       */
      public nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative.Builder addAlternativesBuilder(
          int index) {
        return getAlternativesFieldBuilder().addBuilder(
            index, nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative.getDefaultInstance());
      }
      /**
       * <pre>
       * May contain one or more recognition hypotheses (up to the
       * maximum specified in `max_alternatives`).
       * These alternatives are ordered in terms of accuracy, with the top (first)
       * alternative being the most probable, as ranked by the recognizer.
       * </pre>
       *
       * <code>repeated .nvidia.riva.asr.SpeechRecognitionAlternative alternatives = 1;</code>
       */
      public java.util.List<nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative.Builder> 
           getAlternativesBuilderList() {
        return getAlternativesFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative, nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative.Builder, nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternativeOrBuilder> 
          getAlternativesFieldBuilder() {
        if (alternativesBuilder_ == null) {
          alternativesBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative, nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternative.Builder, nvidia.riva.asr.RivaAsr.SpeechRecognitionAlternativeOrBuilder>(
                  alternatives_,
                  ((bitField0_ & 0x00000001) == 0x00000001),
                  getParentForChildren(),
                  isClean());
          alternatives_ = null;
        }
        return alternativesBuilder_;
      }

      private boolean isFinal_ ;
      /**
       * <pre>
       * If `false`, this `StreamingRecognitionResult` represents an
       * interim result that may change. If `true`, this is the final time the
       * speech service will return this particular `StreamingRecognitionResult`,
       * the recognizer will not return any further hypotheses for this portion of
       * the transcript and corresponding audio.
       * </pre>
       *
       * <code>optional bool is_final = 2;</code>
       */
      public boolean getIsFinal() {
        return isFinal_;
      }
      /**
       * <pre>
       * If `false`, this `StreamingRecognitionResult` represents an
       * interim result that may change. If `true`, this is the final time the
       * speech service will return this particular `StreamingRecognitionResult`,
       * the recognizer will not return any further hypotheses for this portion of
       * the transcript and corresponding audio.
       * </pre>
       *
       * <code>optional bool is_final = 2;</code>
       */
      public Builder setIsFinal(boolean value) {
        
        isFinal_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * If `false`, this `StreamingRecognitionResult` represents an
       * interim result that may change. If `true`, this is the final time the
       * speech service will return this particular `StreamingRecognitionResult`,
       * the recognizer will not return any further hypotheses for this portion of
       * the transcript and corresponding audio.
       * </pre>
       *
       * <code>optional bool is_final = 2;</code>
       */
      public Builder clearIsFinal() {
        
        isFinal_ = false;
        onChanged();
        return this;
      }

      private float stability_ ;
      /**
       * <pre>
       * An estimate of the likelihood that the recognizer will not
       * change its guess about this interim result. Values range from 0.0
       * (completely unstable) to 1.0 (completely stable).
       * This field is only provided for interim results (`is_final=false`).
       * The default of 0.0 is a sentinel value indicating `stability` was not set.
       * </pre>
       *
       * <code>optional float stability = 3;</code>
       */
      public float getStability() {
        return stability_;
      }
      /**
       * <pre>
       * An estimate of the likelihood that the recognizer will not
       * change its guess about this interim result. Values range from 0.0
       * (completely unstable) to 1.0 (completely stable).
       * This field is only provided for interim results (`is_final=false`).
       * The default of 0.0 is a sentinel value indicating `stability` was not set.
       * </pre>
       *
       * <code>optional float stability = 3;</code>
       */
      public Builder setStability(float value) {
        
        stability_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * An estimate of the likelihood that the recognizer will not
       * change its guess about this interim result. Values range from 0.0
       * (completely unstable) to 1.0 (completely stable).
       * This field is only provided for interim results (`is_final=false`).
       * The default of 0.0 is a sentinel value indicating `stability` was not set.
       * </pre>
       *
       * <code>optional float stability = 3;</code>
       */
      public Builder clearStability() {
        
        stability_ = 0F;
        onChanged();
        return this;
      }

      private int channelTag_ ;
      /**
       * <pre>
       * For multi-channel audio, this is the channel number corresponding to the
       * recognized result for the audio from that channel.
       * For audio_channel_count = N, its output values can range from '1' to 'N'.
       * </pre>
       *
       * <code>optional int32 channel_tag = 5;</code>
       */
      public int getChannelTag() {
        return channelTag_;
      }
      /**
       * <pre>
       * For multi-channel audio, this is the channel number corresponding to the
       * recognized result for the audio from that channel.
       * For audio_channel_count = N, its output values can range from '1' to 'N'.
       * </pre>
       *
       * <code>optional int32 channel_tag = 5;</code>
       */
      public Builder setChannelTag(int value) {
        
        channelTag_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * For multi-channel audio, this is the channel number corresponding to the
       * recognized result for the audio from that channel.
       * For audio_channel_count = N, its output values can range from '1' to 'N'.
       * </pre>
       *
       * <code>optional int32 channel_tag = 5;</code>
       */
      public Builder clearChannelTag() {
        
        channelTag_ = 0;
        onChanged();
        return this;
      }

      private float audioProcessed_ ;
      /**
       * <pre>
       * Length of audio processed so far in seconds
       * </pre>
       *
       * <code>optional float audio_processed = 6;</code>
       */
      public float getAudioProcessed() {
        return audioProcessed_;
      }
      /**
       * <pre>
       * Length of audio processed so far in seconds
       * </pre>
       *
       * <code>optional float audio_processed = 6;</code>
       */
      public Builder setAudioProcessed(float value) {
        
        audioProcessed_ = value;
        onChanged();
        return this;
      }
      /**
       * <pre>
       * Length of audio processed so far in seconds
       * </pre>
       *
       * <code>optional float audio_processed = 6;</code>
       */
      public Builder clearAudioProcessed() {
        
        audioProcessed_ = 0F;
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return this;
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return this;
      }


      // @@protoc_insertion_point(builder_scope:nvidia.riva.asr.StreamingRecognitionResult)
    }

    // @@protoc_insertion_point(class_scope:nvidia.riva.asr.StreamingRecognitionResult)
    private static final nvidia.riva.asr.RivaAsr.StreamingRecognitionResult DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new nvidia.riva.asr.RivaAsr.StreamingRecognitionResult();
    }

    public static nvidia.riva.asr.RivaAsr.StreamingRecognitionResult getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    private static final com.google.protobuf.Parser<StreamingRecognitionResult>
        PARSER = new com.google.protobuf.AbstractParser<StreamingRecognitionResult>() {
      public StreamingRecognitionResult parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new StreamingRecognitionResult(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<StreamingRecognitionResult> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<StreamingRecognitionResult> getParserForType() {
      return PARSER;
    }

    public nvidia.riva.asr.RivaAsr.StreamingRecognitionResult getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_nvidia_riva_asr_RecognizeRequest_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_nvidia_riva_asr_RecognizeRequest_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_nvidia_riva_asr_StreamingRecognizeRequest_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_nvidia_riva_asr_StreamingRecognizeRequest_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_nvidia_riva_asr_RecognitionConfig_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_nvidia_riva_asr_RecognitionConfig_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_nvidia_riva_asr_RecognitionConfig_CustomConfigurationEntry_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_nvidia_riva_asr_RecognitionConfig_CustomConfigurationEntry_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_nvidia_riva_asr_StreamingRecognitionConfig_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_nvidia_riva_asr_StreamingRecognitionConfig_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_nvidia_riva_asr_RecognizeResponse_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_nvidia_riva_asr_RecognizeResponse_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_nvidia_riva_asr_SpeechRecognitionResult_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_nvidia_riva_asr_SpeechRecognitionResult_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_nvidia_riva_asr_SpeechRecognitionAlternative_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_nvidia_riva_asr_SpeechRecognitionAlternative_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_nvidia_riva_asr_WordInfo_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_nvidia_riva_asr_WordInfo_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_nvidia_riva_asr_StreamingRecognizeResponse_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_nvidia_riva_asr_StreamingRecognizeResponse_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_nvidia_riva_asr_StreamingRecognitionResult_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_nvidia_riva_asr_StreamingRecognitionResult_fieldAccessorTable;

  public static com.google.protobuf.Descriptors.FileDescriptor
      getDescriptor() {
    return descriptor;
  }
  private static  com.google.protobuf.Descriptors.FileDescriptor
      descriptor;
  static {
    java.lang.String[] descriptorData = {
      "\n\016riva_asr.proto\022\017nvidia.riva.asr\032\020riva_" +
      "audio.proto\"U\n\020RecognizeRequest\0222\n\006confi" +
      "g\030\001 \001(\0132\".nvidia.riva.asr.RecognitionCon" +
      "fig\022\r\n\005audio\030\002 \001(\014\"\222\001\n\031StreamingRecogniz" +
      "eRequest\022G\n\020streaming_config\030\001 \001(\0132+.nvi" +
      "dia.riva.asr.StreamingRecognitionConfigH" +
      "\000\022\027\n\raudio_content\030\002 \001(\014H\000B\023\n\021streaming_" +
      "request\"\347\003\n\021RecognitionConfig\022,\n\010encodin" +
      "g\030\001 \001(\0162\032.nvidia.riva.AudioEncoding\022\031\n\021s" +
      "ample_rate_hertz\030\002 \001(\005\022\025\n\rlanguage_code\030",
      "\003 \001(\t\022\030\n\020max_alternatives\030\004 \001(\005\022\033\n\023audio" +
      "_channel_count\030\007 \001(\005\022 \n\030enable_word_time" +
      "_offsets\030\010 \001(\010\022$\n\034enable_automatic_punct" +
      "uation\030\013 \001(\010\022/\n\'enable_separate_recognit" +
      "ion_per_channel\030\014 \001(\010\022\r\n\005model\030\r \001(\t\022\034\n\024" +
      "verbatim_transcripts\030\016 \001(\010\022Y\n\024custom_con" +
      "figuration\030\030 \003(\0132;.nvidia.riva.asr.Recog" +
      "nitionConfig.CustomConfigurationEntry\032:\n" +
      "\030CustomConfigurationEntry\022\013\n\003key\030\001 \001(\t\022\r" +
      "\n\005value\030\002 \001(\t:\0028\001\"i\n\032StreamingRecognitio",
      "nConfig\0222\n\006config\030\001 \001(\0132\".nvidia.riva.as" +
      "r.RecognitionConfig\022\027\n\017interim_results\030\002" +
      " \001(\010\"N\n\021RecognizeResponse\0229\n\007results\030\001 \003" +
      "(\0132(.nvidia.riva.asr.SpeechRecognitionRe" +
      "sult\"\214\001\n\027SpeechRecognitionResult\022C\n\014alte" +
      "rnatives\030\001 \003(\0132-.nvidia.riva.asr.SpeechR" +
      "ecognitionAlternative\022\023\n\013channel_tag\030\002 \001" +
      "(\005\022\027\n\017audio_processed\030\003 \001(\002\"p\n\034SpeechRec" +
      "ognitionAlternative\022\022\n\ntranscript\030\001 \001(\t\022" +
      "\022\n\nconfidence\030\002 \001(\002\022(\n\005words\030\003 \003(\0132\031.nvi",
      "dia.riva.asr.WordInfo\">\n\010WordInfo\022\022\n\nsta" +
      "rt_time\030\001 \001(\005\022\020\n\010end_time\030\002 \001(\005\022\014\n\004word\030" +
      "\003 \001(\t\"Z\n\032StreamingRecognizeResponse\022<\n\007r" +
      "esults\030\001 \003(\0132+.nvidia.riva.asr.Streaming" +
      "RecognitionResult\"\264\001\n\032StreamingRecogniti" +
      "onResult\022C\n\014alternatives\030\001 \003(\0132-.nvidia." +
      "riva.asr.SpeechRecognitionAlternative\022\020\n" +
      "\010is_final\030\002 \001(\010\022\021\n\tstability\030\003 \001(\002\022\023\n\013ch" +
      "annel_tag\030\005 \001(\005\022\027\n\017audio_processed\030\006 \001(\002" +
      "2\342\001\n\025RivaSpeechRecognition\022T\n\tRecognize\022",
      "!.nvidia.riva.asr.RecognizeRequest\032\".nvi" +
      "dia.riva.asr.RecognizeResponse\"\000\022s\n\022Stre" +
      "amingRecognize\022*.nvidia.riva.asr.Streami" +
      "ngRecognizeRequest\032+.nvidia.riva.asr.Str" +
      "eamingRecognizeResponse\"\000(\0010\001B\033Z\026nvidia." +
      "com/riva_speech\370\001\001b\006proto3"
    };
    com.google.protobuf.Descriptors.FileDescriptor.InternalDescriptorAssigner assigner =
        new com.google.protobuf.Descriptors.FileDescriptor.    InternalDescriptorAssigner() {
          public com.google.protobuf.ExtensionRegistry assignDescriptors(
              com.google.protobuf.Descriptors.FileDescriptor root) {
            descriptor = root;
            return null;
          }
        };
    com.google.protobuf.Descriptors.FileDescriptor
      .internalBuildGeneratedFileFrom(descriptorData,
        new com.google.protobuf.Descriptors.FileDescriptor[] {
          nvidia.riva.RivaAudio.getDescriptor(),
        }, assigner);
    internal_static_nvidia_riva_asr_RecognizeRequest_descriptor =
      getDescriptor().getMessageTypes().get(0);
    internal_static_nvidia_riva_asr_RecognizeRequest_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_nvidia_riva_asr_RecognizeRequest_descriptor,
        new java.lang.String[] { "Config", "Audio", });
    internal_static_nvidia_riva_asr_StreamingRecognizeRequest_descriptor =
      getDescriptor().getMessageTypes().get(1);
    internal_static_nvidia_riva_asr_StreamingRecognizeRequest_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_nvidia_riva_asr_StreamingRecognizeRequest_descriptor,
        new java.lang.String[] { "StreamingConfig", "AudioContent", "StreamingRequest", });
    internal_static_nvidia_riva_asr_RecognitionConfig_descriptor =
      getDescriptor().getMessageTypes().get(2);
    internal_static_nvidia_riva_asr_RecognitionConfig_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_nvidia_riva_asr_RecognitionConfig_descriptor,
        new java.lang.String[] { "Encoding", "SampleRateHertz", "LanguageCode", "MaxAlternatives", "AudioChannelCount", "EnableWordTimeOffsets", "EnableAutomaticPunctuation", "EnableSeparateRecognitionPerChannel", "Model", "VerbatimTranscripts", "CustomConfiguration", });
    internal_static_nvidia_riva_asr_RecognitionConfig_CustomConfigurationEntry_descriptor =
      internal_static_nvidia_riva_asr_RecognitionConfig_descriptor.getNestedTypes().get(0);
    internal_static_nvidia_riva_asr_RecognitionConfig_CustomConfigurationEntry_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_nvidia_riva_asr_RecognitionConfig_CustomConfigurationEntry_descriptor,
        new java.lang.String[] { "Key", "Value", });
    internal_static_nvidia_riva_asr_StreamingRecognitionConfig_descriptor =
      getDescriptor().getMessageTypes().get(3);
    internal_static_nvidia_riva_asr_StreamingRecognitionConfig_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_nvidia_riva_asr_StreamingRecognitionConfig_descriptor,
        new java.lang.String[] { "Config", "InterimResults", });
    internal_static_nvidia_riva_asr_RecognizeResponse_descriptor =
      getDescriptor().getMessageTypes().get(4);
    internal_static_nvidia_riva_asr_RecognizeResponse_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_nvidia_riva_asr_RecognizeResponse_descriptor,
        new java.lang.String[] { "Results", });
    internal_static_nvidia_riva_asr_SpeechRecognitionResult_descriptor =
      getDescriptor().getMessageTypes().get(5);
    internal_static_nvidia_riva_asr_SpeechRecognitionResult_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_nvidia_riva_asr_SpeechRecognitionResult_descriptor,
        new java.lang.String[] { "Alternatives", "ChannelTag", "AudioProcessed", });
    internal_static_nvidia_riva_asr_SpeechRecognitionAlternative_descriptor =
      getDescriptor().getMessageTypes().get(6);
    internal_static_nvidia_riva_asr_SpeechRecognitionAlternative_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_nvidia_riva_asr_SpeechRecognitionAlternative_descriptor,
        new java.lang.String[] { "Transcript", "Confidence", "Words", });
    internal_static_nvidia_riva_asr_WordInfo_descriptor =
      getDescriptor().getMessageTypes().get(7);
    internal_static_nvidia_riva_asr_WordInfo_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_nvidia_riva_asr_WordInfo_descriptor,
        new java.lang.String[] { "StartTime", "EndTime", "Word", });
    internal_static_nvidia_riva_asr_StreamingRecognizeResponse_descriptor =
      getDescriptor().getMessageTypes().get(8);
    internal_static_nvidia_riva_asr_StreamingRecognizeResponse_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_nvidia_riva_asr_StreamingRecognizeResponse_descriptor,
        new java.lang.String[] { "Results", });
    internal_static_nvidia_riva_asr_StreamingRecognitionResult_descriptor =
      getDescriptor().getMessageTypes().get(9);
    internal_static_nvidia_riva_asr_StreamingRecognitionResult_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_nvidia_riva_asr_StreamingRecognitionResult_descriptor,
        new java.lang.String[] { "Alternatives", "IsFinal", "Stability", "ChannelTag", "AudioProcessed", });
    nvidia.riva.RivaAudio.getDescriptor();
  }

  // @@protoc_insertion_point(outer_class_scope)
}
